{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.42698149019656734,
  "eval_steps": 500,
  "global_step": 137000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0001558326606556815,
      "grad_norm": 0.8496657013893127,
      "learning_rate": 4.9997506677429514e-05,
      "loss": 1.8663,
      "step": 50
    },
    {
      "epoch": 0.000311665321311363,
      "grad_norm": 0.6794496178627014,
      "learning_rate": 4.999490946641858e-05,
      "loss": 1.5096,
      "step": 100
    },
    {
      "epoch": 0.0004674979819670445,
      "grad_norm": 0.9423673152923584,
      "learning_rate": 4.999231225540765e-05,
      "loss": 1.4533,
      "step": 150
    },
    {
      "epoch": 0.000623330642622726,
      "grad_norm": 0.6413052082061768,
      "learning_rate": 4.998971504439673e-05,
      "loss": 1.3963,
      "step": 200
    },
    {
      "epoch": 0.0007791633032784075,
      "grad_norm": 0.7025055885314941,
      "learning_rate": 4.99871178333858e-05,
      "loss": 1.3862,
      "step": 250
    },
    {
      "epoch": 0.000934995963934089,
      "grad_norm": 0.7646145224571228,
      "learning_rate": 4.998452062237487e-05,
      "loss": 1.386,
      "step": 300
    },
    {
      "epoch": 0.0010908286245897706,
      "grad_norm": 0.6723560094833374,
      "learning_rate": 4.998192341136394e-05,
      "loss": 1.3786,
      "step": 350
    },
    {
      "epoch": 0.001246661285245452,
      "grad_norm": 0.7501801252365112,
      "learning_rate": 4.9979326200353015e-05,
      "loss": 1.4067,
      "step": 400
    },
    {
      "epoch": 0.0014024939459011336,
      "grad_norm": 0.7366626262664795,
      "learning_rate": 4.997672898934209e-05,
      "loss": 1.3414,
      "step": 450
    },
    {
      "epoch": 0.001558326606556815,
      "grad_norm": 0.5664870738983154,
      "learning_rate": 4.997413177833116e-05,
      "loss": 1.3672,
      "step": 500
    },
    {
      "epoch": 0.0017141592672124965,
      "grad_norm": 0.707743763923645,
      "learning_rate": 4.997153456732023e-05,
      "loss": 1.3794,
      "step": 550
    },
    {
      "epoch": 0.001869991927868178,
      "grad_norm": 0.6412230730056763,
      "learning_rate": 4.9968937356309305e-05,
      "loss": 1.4027,
      "step": 600
    },
    {
      "epoch": 0.0020258245885238597,
      "grad_norm": 0.60760498046875,
      "learning_rate": 4.996634014529837e-05,
      "loss": 1.3773,
      "step": 650
    },
    {
      "epoch": 0.002181657249179541,
      "grad_norm": 0.734705924987793,
      "learning_rate": 4.996374293428745e-05,
      "loss": 1.3641,
      "step": 700
    },
    {
      "epoch": 0.0023374899098352227,
      "grad_norm": 0.882408618927002,
      "learning_rate": 4.996114572327652e-05,
      "loss": 1.4109,
      "step": 750
    },
    {
      "epoch": 0.002493322570490904,
      "grad_norm": 0.7095734477043152,
      "learning_rate": 4.995854851226559e-05,
      "loss": 1.3751,
      "step": 800
    },
    {
      "epoch": 0.0026491552311465856,
      "grad_norm": 0.572027325630188,
      "learning_rate": 4.995595130125466e-05,
      "loss": 1.3353,
      "step": 850
    },
    {
      "epoch": 0.002804987891802267,
      "grad_norm": 0.8691175580024719,
      "learning_rate": 4.995335409024374e-05,
      "loss": 1.3831,
      "step": 900
    },
    {
      "epoch": 0.0029608205524579486,
      "grad_norm": 0.7337713241577148,
      "learning_rate": 4.9950756879232806e-05,
      "loss": 1.3527,
      "step": 950
    },
    {
      "epoch": 0.00311665321311363,
      "grad_norm": 0.6690821647644043,
      "learning_rate": 4.994815966822188e-05,
      "loss": 1.4145,
      "step": 1000
    },
    {
      "epoch": 0.0032724858737693116,
      "grad_norm": 0.7521985173225403,
      "learning_rate": 4.994556245721095e-05,
      "loss": 1.3447,
      "step": 1050
    },
    {
      "epoch": 0.003428318534424993,
      "grad_norm": 0.584939181804657,
      "learning_rate": 4.994296524620002e-05,
      "loss": 1.3789,
      "step": 1100
    },
    {
      "epoch": 0.0035841511950806745,
      "grad_norm": 0.7578305602073669,
      "learning_rate": 4.9940368035189096e-05,
      "loss": 1.3915,
      "step": 1150
    },
    {
      "epoch": 0.003739983855736356,
      "grad_norm": 0.7836129069328308,
      "learning_rate": 4.993777082417817e-05,
      "loss": 1.3492,
      "step": 1200
    },
    {
      "epoch": 0.0038958165163920375,
      "grad_norm": 0.6350499391555786,
      "learning_rate": 4.993517361316724e-05,
      "loss": 1.3929,
      "step": 1250
    },
    {
      "epoch": 0.004051649177047719,
      "grad_norm": 0.6463618874549866,
      "learning_rate": 4.993257640215631e-05,
      "loss": 1.3481,
      "step": 1300
    },
    {
      "epoch": 0.0042074818377034005,
      "grad_norm": 0.7150506377220154,
      "learning_rate": 4.992997919114538e-05,
      "loss": 1.3549,
      "step": 1350
    },
    {
      "epoch": 0.004363314498359082,
      "grad_norm": 0.6580155491828918,
      "learning_rate": 4.992738198013445e-05,
      "loss": 1.2908,
      "step": 1400
    },
    {
      "epoch": 0.004519147159014763,
      "grad_norm": 0.73553466796875,
      "learning_rate": 4.992478476912353e-05,
      "loss": 1.3591,
      "step": 1450
    },
    {
      "epoch": 0.004674979819670445,
      "grad_norm": 0.7916200757026672,
      "learning_rate": 4.9922187558112596e-05,
      "loss": 1.3626,
      "step": 1500
    },
    {
      "epoch": 0.004830812480326126,
      "grad_norm": 0.6015838980674744,
      "learning_rate": 4.991959034710167e-05,
      "loss": 1.341,
      "step": 1550
    },
    {
      "epoch": 0.004986645140981808,
      "grad_norm": 0.763563871383667,
      "learning_rate": 4.991699313609075e-05,
      "loss": 1.3246,
      "step": 1600
    },
    {
      "epoch": 0.005142477801637489,
      "grad_norm": 0.5979167222976685,
      "learning_rate": 4.9914395925079814e-05,
      "loss": 1.3547,
      "step": 1650
    },
    {
      "epoch": 0.005298310462293171,
      "grad_norm": 0.6430054903030396,
      "learning_rate": 4.9911798714068886e-05,
      "loss": 1.3338,
      "step": 1700
    },
    {
      "epoch": 0.005454143122948852,
      "grad_norm": 0.6330245733261108,
      "learning_rate": 4.990920150305796e-05,
      "loss": 1.3078,
      "step": 1750
    },
    {
      "epoch": 0.005609975783604534,
      "grad_norm": 0.5595652461051941,
      "learning_rate": 4.990660429204703e-05,
      "loss": 1.2861,
      "step": 1800
    },
    {
      "epoch": 0.005765808444260215,
      "grad_norm": 0.7001324892044067,
      "learning_rate": 4.9904007081036104e-05,
      "loss": 1.3455,
      "step": 1850
    },
    {
      "epoch": 0.005921641104915897,
      "grad_norm": 0.5372718572616577,
      "learning_rate": 4.9901409870025176e-05,
      "loss": 1.3749,
      "step": 1900
    },
    {
      "epoch": 0.006077473765571578,
      "grad_norm": 0.6712771654129028,
      "learning_rate": 4.989881265901425e-05,
      "loss": 1.3327,
      "step": 1950
    },
    {
      "epoch": 0.00623330642622726,
      "grad_norm": 0.5737619400024414,
      "learning_rate": 4.989621544800332e-05,
      "loss": 1.3743,
      "step": 2000
    },
    {
      "epoch": 0.006389139086882941,
      "grad_norm": 0.628946840763092,
      "learning_rate": 4.989361823699239e-05,
      "loss": 1.324,
      "step": 2050
    },
    {
      "epoch": 0.006544971747538623,
      "grad_norm": 0.8023446202278137,
      "learning_rate": 4.989102102598146e-05,
      "loss": 1.3743,
      "step": 2100
    },
    {
      "epoch": 0.006700804408194305,
      "grad_norm": 0.7081485986709595,
      "learning_rate": 4.988842381497054e-05,
      "loss": 1.347,
      "step": 2150
    },
    {
      "epoch": 0.006856637068849986,
      "grad_norm": 0.656901478767395,
      "learning_rate": 4.9885826603959605e-05,
      "loss": 1.3158,
      "step": 2200
    },
    {
      "epoch": 0.007012469729505668,
      "grad_norm": 0.5949526429176331,
      "learning_rate": 4.988322939294868e-05,
      "loss": 1.372,
      "step": 2250
    },
    {
      "epoch": 0.007168302390161349,
      "grad_norm": 0.6408527493476868,
      "learning_rate": 4.9880632181937756e-05,
      "loss": 1.3549,
      "step": 2300
    },
    {
      "epoch": 0.007324135050817031,
      "grad_norm": 0.7067235708236694,
      "learning_rate": 4.987803497092682e-05,
      "loss": 1.4014,
      "step": 2350
    },
    {
      "epoch": 0.007479967711472712,
      "grad_norm": 0.5071877837181091,
      "learning_rate": 4.9875437759915895e-05,
      "loss": 1.374,
      "step": 2400
    },
    {
      "epoch": 0.007635800372128394,
      "grad_norm": 0.630078911781311,
      "learning_rate": 4.987284054890497e-05,
      "loss": 1.3333,
      "step": 2450
    },
    {
      "epoch": 0.007791633032784075,
      "grad_norm": 0.6559736132621765,
      "learning_rate": 4.987024333789404e-05,
      "loss": 1.4038,
      "step": 2500
    },
    {
      "epoch": 0.007947465693439756,
      "grad_norm": 0.5242152810096741,
      "learning_rate": 4.986764612688311e-05,
      "loss": 1.3425,
      "step": 2550
    },
    {
      "epoch": 0.008103298354095439,
      "grad_norm": 0.624191164970398,
      "learning_rate": 4.986504891587218e-05,
      "loss": 1.3939,
      "step": 2600
    },
    {
      "epoch": 0.00825913101475112,
      "grad_norm": 0.6670030951499939,
      "learning_rate": 4.986245170486125e-05,
      "loss": 1.4125,
      "step": 2650
    },
    {
      "epoch": 0.008414963675406801,
      "grad_norm": 0.6846696138381958,
      "learning_rate": 4.985985449385033e-05,
      "loss": 1.3312,
      "step": 2700
    },
    {
      "epoch": 0.008570796336062482,
      "grad_norm": 0.6871005296707153,
      "learning_rate": 4.9857257282839395e-05,
      "loss": 1.2977,
      "step": 2750
    },
    {
      "epoch": 0.008726628996718165,
      "grad_norm": 0.5817345976829529,
      "learning_rate": 4.985466007182847e-05,
      "loss": 1.3353,
      "step": 2800
    },
    {
      "epoch": 0.008882461657373846,
      "grad_norm": 0.6821984648704529,
      "learning_rate": 4.985206286081755e-05,
      "loss": 1.3334,
      "step": 2850
    },
    {
      "epoch": 0.009038294318029527,
      "grad_norm": 0.6328069567680359,
      "learning_rate": 4.984946564980661e-05,
      "loss": 1.3138,
      "step": 2900
    },
    {
      "epoch": 0.009194126978685208,
      "grad_norm": 0.48368072509765625,
      "learning_rate": 4.9846868438795685e-05,
      "loss": 1.3829,
      "step": 2950
    },
    {
      "epoch": 0.00934995963934089,
      "grad_norm": 0.6541323065757751,
      "learning_rate": 4.984427122778476e-05,
      "loss": 1.3269,
      "step": 3000
    },
    {
      "epoch": 0.009505792299996572,
      "grad_norm": 0.5829547047615051,
      "learning_rate": 4.984167401677383e-05,
      "loss": 1.3431,
      "step": 3050
    },
    {
      "epoch": 0.009661624960652253,
      "grad_norm": 0.6509102582931519,
      "learning_rate": 4.98390768057629e-05,
      "loss": 1.3279,
      "step": 3100
    },
    {
      "epoch": 0.009817457621307934,
      "grad_norm": 0.5398967862129211,
      "learning_rate": 4.9836479594751975e-05,
      "loss": 1.3355,
      "step": 3150
    },
    {
      "epoch": 0.009973290281963617,
      "grad_norm": 0.544200599193573,
      "learning_rate": 4.983388238374105e-05,
      "loss": 1.3666,
      "step": 3200
    },
    {
      "epoch": 0.010129122942619298,
      "grad_norm": 0.6693305969238281,
      "learning_rate": 4.983128517273012e-05,
      "loss": 1.3321,
      "step": 3250
    },
    {
      "epoch": 0.010284955603274979,
      "grad_norm": 0.7142634391784668,
      "learning_rate": 4.9828687961719186e-05,
      "loss": 1.3815,
      "step": 3300
    },
    {
      "epoch": 0.010440788263930662,
      "grad_norm": 0.5172840356826782,
      "learning_rate": 4.982609075070826e-05,
      "loss": 1.4016,
      "step": 3350
    },
    {
      "epoch": 0.010596620924586343,
      "grad_norm": 0.6491748094558716,
      "learning_rate": 4.982349353969734e-05,
      "loss": 1.3099,
      "step": 3400
    },
    {
      "epoch": 0.010752453585242024,
      "grad_norm": 0.6466702222824097,
      "learning_rate": 4.9820896328686404e-05,
      "loss": 1.3245,
      "step": 3450
    },
    {
      "epoch": 0.010908286245897705,
      "grad_norm": 0.5479609370231628,
      "learning_rate": 4.9818299117675476e-05,
      "loss": 1.3265,
      "step": 3500
    },
    {
      "epoch": 0.011064118906553387,
      "grad_norm": 0.38946375250816345,
      "learning_rate": 4.9815701906664555e-05,
      "loss": 1.4065,
      "step": 3550
    },
    {
      "epoch": 0.011219951567209068,
      "grad_norm": 0.5250698328018188,
      "learning_rate": 4.981310469565362e-05,
      "loss": 1.3797,
      "step": 3600
    },
    {
      "epoch": 0.01137578422786475,
      "grad_norm": 0.6882994771003723,
      "learning_rate": 4.9810507484642694e-05,
      "loss": 1.283,
      "step": 3650
    },
    {
      "epoch": 0.01153161688852043,
      "grad_norm": 0.6640287041664124,
      "learning_rate": 4.9807910273631766e-05,
      "loss": 1.3442,
      "step": 3700
    },
    {
      "epoch": 0.011687449549176113,
      "grad_norm": 0.5191344618797302,
      "learning_rate": 4.980531306262084e-05,
      "loss": 1.3216,
      "step": 3750
    },
    {
      "epoch": 0.011843282209831794,
      "grad_norm": 0.6437234878540039,
      "learning_rate": 4.980271585160991e-05,
      "loss": 1.3656,
      "step": 3800
    },
    {
      "epoch": 0.011999114870487475,
      "grad_norm": 0.5990815162658691,
      "learning_rate": 4.9800118640598984e-05,
      "loss": 1.3592,
      "step": 3850
    },
    {
      "epoch": 0.012154947531143157,
      "grad_norm": 0.6728096604347229,
      "learning_rate": 4.979757337380827e-05,
      "loss": 1.3533,
      "step": 3900
    },
    {
      "epoch": 0.01231078019179884,
      "grad_norm": 0.5436310768127441,
      "learning_rate": 4.979497616279735e-05,
      "loss": 1.3088,
      "step": 3950
    },
    {
      "epoch": 0.01246661285245452,
      "grad_norm": 0.5493251085281372,
      "learning_rate": 4.9792378951786414e-05,
      "loss": 1.275,
      "step": 4000
    },
    {
      "epoch": 0.012622445513110201,
      "grad_norm": 0.7027632594108582,
      "learning_rate": 4.9789781740775487e-05,
      "loss": 1.3843,
      "step": 4050
    },
    {
      "epoch": 0.012778278173765882,
      "grad_norm": 0.506352961063385,
      "learning_rate": 4.978718452976456e-05,
      "loss": 1.3024,
      "step": 4100
    },
    {
      "epoch": 0.012934110834421565,
      "grad_norm": 0.6514437794685364,
      "learning_rate": 4.978458731875363e-05,
      "loss": 1.3206,
      "step": 4150
    },
    {
      "epoch": 0.013089943495077246,
      "grad_norm": 0.47791898250579834,
      "learning_rate": 4.9781990107742704e-05,
      "loss": 1.3433,
      "step": 4200
    },
    {
      "epoch": 0.013245776155732927,
      "grad_norm": 0.5080920457839966,
      "learning_rate": 4.977939289673178e-05,
      "loss": 1.2898,
      "step": 4250
    },
    {
      "epoch": 0.01340160881638861,
      "grad_norm": 0.5998125076293945,
      "learning_rate": 4.977679568572085e-05,
      "loss": 1.3015,
      "step": 4300
    },
    {
      "epoch": 0.013557441477044291,
      "grad_norm": 0.5779537558555603,
      "learning_rate": 4.977419847470992e-05,
      "loss": 1.3263,
      "step": 4350
    },
    {
      "epoch": 0.013713274137699972,
      "grad_norm": 0.4653300642967224,
      "learning_rate": 4.9771601263698994e-05,
      "loss": 1.3954,
      "step": 4400
    },
    {
      "epoch": 0.013869106798355653,
      "grad_norm": 0.5466722846031189,
      "learning_rate": 4.976900405268806e-05,
      "loss": 1.3449,
      "step": 4450
    },
    {
      "epoch": 0.014024939459011336,
      "grad_norm": 0.5696160197257996,
      "learning_rate": 4.976640684167714e-05,
      "loss": 1.3637,
      "step": 4500
    },
    {
      "epoch": 0.014180772119667017,
      "grad_norm": 0.448036789894104,
      "learning_rate": 4.976380963066621e-05,
      "loss": 1.4011,
      "step": 4550
    },
    {
      "epoch": 0.014336604780322698,
      "grad_norm": 0.522909939289093,
      "learning_rate": 4.976121241965528e-05,
      "loss": 1.3485,
      "step": 4600
    },
    {
      "epoch": 0.01449243744097838,
      "grad_norm": 0.5425151586532593,
      "learning_rate": 4.975861520864435e-05,
      "loss": 1.2897,
      "step": 4650
    },
    {
      "epoch": 0.014648270101634062,
      "grad_norm": 0.5634627342224121,
      "learning_rate": 4.975601799763342e-05,
      "loss": 1.325,
      "step": 4700
    },
    {
      "epoch": 0.014804102762289743,
      "grad_norm": 0.6236270070075989,
      "learning_rate": 4.9753420786622495e-05,
      "loss": 1.3726,
      "step": 4750
    },
    {
      "epoch": 0.014959935422945424,
      "grad_norm": 0.5920132994651794,
      "learning_rate": 4.975082357561157e-05,
      "loss": 1.3234,
      "step": 4800
    },
    {
      "epoch": 0.015115768083601105,
      "grad_norm": 0.6990236639976501,
      "learning_rate": 4.974822636460064e-05,
      "loss": 1.3209,
      "step": 4850
    },
    {
      "epoch": 0.015271600744256788,
      "grad_norm": 0.7027589082717896,
      "learning_rate": 4.974562915358971e-05,
      "loss": 1.384,
      "step": 4900
    },
    {
      "epoch": 0.015427433404912469,
      "grad_norm": 0.6034034490585327,
      "learning_rate": 4.9743031942578785e-05,
      "loss": 1.4062,
      "step": 4950
    },
    {
      "epoch": 0.01558326606556815,
      "grad_norm": 0.695512056350708,
      "learning_rate": 4.974043473156785e-05,
      "loss": 1.3634,
      "step": 5000
    },
    {
      "epoch": 0.01573909872622383,
      "grad_norm": 0.5534629821777344,
      "learning_rate": 4.973783752055693e-05,
      "loss": 1.3631,
      "step": 5050
    },
    {
      "epoch": 0.015894931386879512,
      "grad_norm": 0.6742116212844849,
      "learning_rate": 4.9735240309546e-05,
      "loss": 1.3132,
      "step": 5100
    },
    {
      "epoch": 0.016050764047535193,
      "grad_norm": 0.47502270340919495,
      "learning_rate": 4.973264309853507e-05,
      "loss": 1.3259,
      "step": 5150
    },
    {
      "epoch": 0.016206596708190878,
      "grad_norm": 0.6603335738182068,
      "learning_rate": 4.973004588752415e-05,
      "loss": 1.3334,
      "step": 5200
    },
    {
      "epoch": 0.01636242936884656,
      "grad_norm": 0.6556662917137146,
      "learning_rate": 4.972744867651321e-05,
      "loss": 1.3637,
      "step": 5250
    },
    {
      "epoch": 0.01651826202950224,
      "grad_norm": 0.5195320844650269,
      "learning_rate": 4.9724851465502286e-05,
      "loss": 1.3566,
      "step": 5300
    },
    {
      "epoch": 0.01667409469015792,
      "grad_norm": 0.7432105541229248,
      "learning_rate": 4.972225425449136e-05,
      "loss": 1.3371,
      "step": 5350
    },
    {
      "epoch": 0.016829927350813602,
      "grad_norm": 0.661855936050415,
      "learning_rate": 4.971965704348043e-05,
      "loss": 1.3612,
      "step": 5400
    },
    {
      "epoch": 0.016985760011469283,
      "grad_norm": 0.651515543460846,
      "learning_rate": 4.97170598324695e-05,
      "loss": 1.368,
      "step": 5450
    },
    {
      "epoch": 0.017141592672124964,
      "grad_norm": 0.6595757007598877,
      "learning_rate": 4.9714462621458576e-05,
      "loss": 1.3603,
      "step": 5500
    },
    {
      "epoch": 0.01729742533278065,
      "grad_norm": 0.6546897292137146,
      "learning_rate": 4.971186541044765e-05,
      "loss": 1.3513,
      "step": 5550
    },
    {
      "epoch": 0.01745325799343633,
      "grad_norm": 0.4904356300830841,
      "learning_rate": 4.970926819943672e-05,
      "loss": 1.3867,
      "step": 5600
    },
    {
      "epoch": 0.01760909065409201,
      "grad_norm": 0.5138305425643921,
      "learning_rate": 4.970667098842579e-05,
      "loss": 1.3129,
      "step": 5650
    },
    {
      "epoch": 0.01776492331474769,
      "grad_norm": 0.5181068181991577,
      "learning_rate": 4.970407377741486e-05,
      "loss": 1.3069,
      "step": 5700
    },
    {
      "epoch": 0.017920755975403373,
      "grad_norm": 0.680880606174469,
      "learning_rate": 4.970147656640394e-05,
      "loss": 1.4085,
      "step": 5750
    },
    {
      "epoch": 0.018076588636059054,
      "grad_norm": 0.7555378079414368,
      "learning_rate": 4.969887935539301e-05,
      "loss": 1.3523,
      "step": 5800
    },
    {
      "epoch": 0.018232421296714735,
      "grad_norm": 0.6456076502799988,
      "learning_rate": 4.9696282144382076e-05,
      "loss": 1.3383,
      "step": 5850
    },
    {
      "epoch": 0.018388253957370416,
      "grad_norm": 0.6247308254241943,
      "learning_rate": 4.969368493337115e-05,
      "loss": 1.3328,
      "step": 5900
    },
    {
      "epoch": 0.0185440866180261,
      "grad_norm": 0.5434100031852722,
      "learning_rate": 4.969108772236022e-05,
      "loss": 1.358,
      "step": 5950
    },
    {
      "epoch": 0.01869991927868178,
      "grad_norm": 0.5679662823677063,
      "learning_rate": 4.9688490511349294e-05,
      "loss": 1.3978,
      "step": 6000
    },
    {
      "epoch": 0.018855751939337462,
      "grad_norm": 0.7174541354179382,
      "learning_rate": 4.9685893300338366e-05,
      "loss": 1.3512,
      "step": 6050
    },
    {
      "epoch": 0.019011584599993143,
      "grad_norm": 0.585736095905304,
      "learning_rate": 4.968329608932744e-05,
      "loss": 1.3125,
      "step": 6100
    },
    {
      "epoch": 0.019167417260648825,
      "grad_norm": 0.6771566271781921,
      "learning_rate": 4.968069887831651e-05,
      "loss": 1.3142,
      "step": 6150
    },
    {
      "epoch": 0.019323249921304506,
      "grad_norm": 0.612395703792572,
      "learning_rate": 4.9678101667305584e-05,
      "loss": 1.3732,
      "step": 6200
    },
    {
      "epoch": 0.019479082581960187,
      "grad_norm": 0.6444770097732544,
      "learning_rate": 4.967550445629465e-05,
      "loss": 1.3294,
      "step": 6250
    },
    {
      "epoch": 0.019634915242615868,
      "grad_norm": 0.6375851631164551,
      "learning_rate": 4.967290724528373e-05,
      "loss": 1.3827,
      "step": 6300
    },
    {
      "epoch": 0.019790747903271552,
      "grad_norm": 0.5187817215919495,
      "learning_rate": 4.96703100342728e-05,
      "loss": 1.3439,
      "step": 6350
    },
    {
      "epoch": 0.019946580563927233,
      "grad_norm": 0.6051862239837646,
      "learning_rate": 4.966771282326187e-05,
      "loss": 1.3019,
      "step": 6400
    },
    {
      "epoch": 0.020102413224582914,
      "grad_norm": 0.7398232221603394,
      "learning_rate": 4.9665115612250946e-05,
      "loss": 1.2952,
      "step": 6450
    },
    {
      "epoch": 0.020258245885238595,
      "grad_norm": 0.4449402689933777,
      "learning_rate": 4.966251840124002e-05,
      "loss": 1.3546,
      "step": 6500
    },
    {
      "epoch": 0.020414078545894276,
      "grad_norm": 0.6513887047767639,
      "learning_rate": 4.9659921190229085e-05,
      "loss": 1.2999,
      "step": 6550
    },
    {
      "epoch": 0.020569911206549957,
      "grad_norm": 0.6030101776123047,
      "learning_rate": 4.965732397921816e-05,
      "loss": 1.2881,
      "step": 6600
    },
    {
      "epoch": 0.02072574386720564,
      "grad_norm": 0.8167698383331299,
      "learning_rate": 4.965472676820723e-05,
      "loss": 1.371,
      "step": 6650
    },
    {
      "epoch": 0.020881576527861323,
      "grad_norm": 0.6563253998756409,
      "learning_rate": 4.96521295571963e-05,
      "loss": 1.3727,
      "step": 6700
    },
    {
      "epoch": 0.021037409188517004,
      "grad_norm": 0.6176069974899292,
      "learning_rate": 4.9649532346185375e-05,
      "loss": 1.3038,
      "step": 6750
    },
    {
      "epoch": 0.021193241849172685,
      "grad_norm": 0.7273112535476685,
      "learning_rate": 4.964693513517445e-05,
      "loss": 1.316,
      "step": 6800
    },
    {
      "epoch": 0.021349074509828366,
      "grad_norm": 0.5471296310424805,
      "learning_rate": 4.964433792416352e-05,
      "loss": 1.3615,
      "step": 6850
    },
    {
      "epoch": 0.021504907170484047,
      "grad_norm": 0.5459910035133362,
      "learning_rate": 4.964174071315259e-05,
      "loss": 1.3627,
      "step": 6900
    },
    {
      "epoch": 0.021660739831139728,
      "grad_norm": 0.5495458245277405,
      "learning_rate": 4.963914350214166e-05,
      "loss": 1.3691,
      "step": 6950
    },
    {
      "epoch": 0.02181657249179541,
      "grad_norm": 0.4113849103450775,
      "learning_rate": 4.963654629113074e-05,
      "loss": 1.2805,
      "step": 7000
    },
    {
      "epoch": 0.02197240515245109,
      "grad_norm": 0.5577514171600342,
      "learning_rate": 4.963394908011981e-05,
      "loss": 1.3433,
      "step": 7050
    },
    {
      "epoch": 0.022128237813106775,
      "grad_norm": 0.7519777417182922,
      "learning_rate": 4.9631351869108875e-05,
      "loss": 1.3349,
      "step": 7100
    },
    {
      "epoch": 0.022284070473762456,
      "grad_norm": 0.6392936706542969,
      "learning_rate": 4.962875465809795e-05,
      "loss": 1.3329,
      "step": 7150
    },
    {
      "epoch": 0.022439903134418137,
      "grad_norm": 0.5335951447486877,
      "learning_rate": 4.962615744708703e-05,
      "loss": 1.3683,
      "step": 7200
    },
    {
      "epoch": 0.022595735795073818,
      "grad_norm": 0.7154409885406494,
      "learning_rate": 4.962356023607609e-05,
      "loss": 1.2872,
      "step": 7250
    },
    {
      "epoch": 0.0227515684557295,
      "grad_norm": 0.5882086157798767,
      "learning_rate": 4.9620963025065165e-05,
      "loss": 1.3291,
      "step": 7300
    },
    {
      "epoch": 0.02290740111638518,
      "grad_norm": 0.659472644329071,
      "learning_rate": 4.961836581405424e-05,
      "loss": 1.3084,
      "step": 7350
    },
    {
      "epoch": 0.02306323377704086,
      "grad_norm": 0.6148248314857483,
      "learning_rate": 4.961576860304331e-05,
      "loss": 1.3104,
      "step": 7400
    },
    {
      "epoch": 0.023219066437696542,
      "grad_norm": 0.6387063264846802,
      "learning_rate": 4.961317139203238e-05,
      "loss": 1.3229,
      "step": 7450
    },
    {
      "epoch": 0.023374899098352227,
      "grad_norm": 0.8223085999488831,
      "learning_rate": 4.961057418102145e-05,
      "loss": 1.3595,
      "step": 7500
    },
    {
      "epoch": 0.023530731759007908,
      "grad_norm": 0.5619892477989197,
      "learning_rate": 4.960797697001053e-05,
      "loss": 1.3739,
      "step": 7550
    },
    {
      "epoch": 0.02368656441966359,
      "grad_norm": 0.7208254933357239,
      "learning_rate": 4.96053797589996e-05,
      "loss": 1.3162,
      "step": 7600
    },
    {
      "epoch": 0.02384239708031927,
      "grad_norm": 0.7374066114425659,
      "learning_rate": 4.9602782547988666e-05,
      "loss": 1.3505,
      "step": 7650
    },
    {
      "epoch": 0.02399822974097495,
      "grad_norm": 0.6434023380279541,
      "learning_rate": 4.9600185336977745e-05,
      "loss": 1.36,
      "step": 7700
    },
    {
      "epoch": 0.024154062401630632,
      "grad_norm": 0.48161375522613525,
      "learning_rate": 4.959758812596682e-05,
      "loss": 1.3598,
      "step": 7750
    },
    {
      "epoch": 0.024309895062286313,
      "grad_norm": 0.5243804454803467,
      "learning_rate": 4.9594990914955884e-05,
      "loss": 1.3052,
      "step": 7800
    },
    {
      "epoch": 0.024465727722941998,
      "grad_norm": 0.4795176684856415,
      "learning_rate": 4.9592393703944956e-05,
      "loss": 1.3715,
      "step": 7850
    },
    {
      "epoch": 0.02462156038359768,
      "grad_norm": 0.5532738566398621,
      "learning_rate": 4.958979649293403e-05,
      "loss": 1.3222,
      "step": 7900
    },
    {
      "epoch": 0.02477739304425336,
      "grad_norm": 0.5473823547363281,
      "learning_rate": 4.95871992819231e-05,
      "loss": 1.3154,
      "step": 7950
    },
    {
      "epoch": 0.02493322570490904,
      "grad_norm": 0.7284204959869385,
      "learning_rate": 4.9584602070912174e-05,
      "loss": 1.3519,
      "step": 8000
    },
    {
      "epoch": 0.025089058365564722,
      "grad_norm": 0.6039177179336548,
      "learning_rate": 4.9582004859901246e-05,
      "loss": 1.3519,
      "step": 8050
    },
    {
      "epoch": 0.025244891026220403,
      "grad_norm": 0.5117738246917725,
      "learning_rate": 4.957940764889032e-05,
      "loss": 1.3051,
      "step": 8100
    },
    {
      "epoch": 0.025400723686876084,
      "grad_norm": 0.4897916913032532,
      "learning_rate": 4.957681043787939e-05,
      "loss": 1.316,
      "step": 8150
    },
    {
      "epoch": 0.025556556347531765,
      "grad_norm": 0.5397919416427612,
      "learning_rate": 4.957421322686846e-05,
      "loss": 1.3182,
      "step": 8200
    },
    {
      "epoch": 0.02571238900818745,
      "grad_norm": 0.47112131118774414,
      "learning_rate": 4.9571616015857536e-05,
      "loss": 1.3098,
      "step": 8250
    },
    {
      "epoch": 0.02586822166884313,
      "grad_norm": 0.542188823223114,
      "learning_rate": 4.956901880484661e-05,
      "loss": 1.4004,
      "step": 8300
    },
    {
      "epoch": 0.02602405432949881,
      "grad_norm": 0.5434668660163879,
      "learning_rate": 4.9566421593835674e-05,
      "loss": 1.3534,
      "step": 8350
    },
    {
      "epoch": 0.026179886990154493,
      "grad_norm": 0.5650601983070374,
      "learning_rate": 4.956382438282475e-05,
      "loss": 1.3127,
      "step": 8400
    },
    {
      "epoch": 0.026335719650810174,
      "grad_norm": 0.6570718884468079,
      "learning_rate": 4.9561279116034046e-05,
      "loss": 1.3106,
      "step": 8450
    },
    {
      "epoch": 0.026491552311465855,
      "grad_norm": 0.6367811560630798,
      "learning_rate": 4.955868190502311e-05,
      "loss": 1.3857,
      "step": 8500
    },
    {
      "epoch": 0.026647384972121536,
      "grad_norm": 0.605301022529602,
      "learning_rate": 4.9556084694012184e-05,
      "loss": 1.357,
      "step": 8550
    },
    {
      "epoch": 0.02680321763277722,
      "grad_norm": 0.6133922934532166,
      "learning_rate": 4.9553487483001257e-05,
      "loss": 1.228,
      "step": 8600
    },
    {
      "epoch": 0.0269590502934329,
      "grad_norm": 0.642794668674469,
      "learning_rate": 4.955089027199033e-05,
      "loss": 1.347,
      "step": 8650
    },
    {
      "epoch": 0.027114882954088582,
      "grad_norm": 0.5705519914627075,
      "learning_rate": 4.95482930609794e-05,
      "loss": 1.3545,
      "step": 8700
    },
    {
      "epoch": 0.027270715614744263,
      "grad_norm": 0.553007185459137,
      "learning_rate": 4.9545695849968474e-05,
      "loss": 1.2859,
      "step": 8750
    },
    {
      "epoch": 0.027426548275399944,
      "grad_norm": 0.6529485583305359,
      "learning_rate": 4.9543098638957547e-05,
      "loss": 1.1841,
      "step": 8800
    },
    {
      "epoch": 0.027582380936055625,
      "grad_norm": 0.46758124232292175,
      "learning_rate": 4.954050142794662e-05,
      "loss": 1.309,
      "step": 8850
    },
    {
      "epoch": 0.027738213596711307,
      "grad_norm": 0.8001310229301453,
      "learning_rate": 4.9537904216935685e-05,
      "loss": 1.3346,
      "step": 8900
    },
    {
      "epoch": 0.027894046257366988,
      "grad_norm": 0.7069540023803711,
      "learning_rate": 4.953530700592476e-05,
      "loss": 1.3777,
      "step": 8950
    },
    {
      "epoch": 0.028049878918022672,
      "grad_norm": 0.5484519600868225,
      "learning_rate": 4.9532709794913837e-05,
      "loss": 1.3825,
      "step": 9000
    },
    {
      "epoch": 0.028205711578678353,
      "grad_norm": 0.6357167363166809,
      "learning_rate": 4.95301125839029e-05,
      "loss": 1.3238,
      "step": 9050
    },
    {
      "epoch": 0.028361544239334034,
      "grad_norm": 0.6089522242546082,
      "learning_rate": 4.9527515372891975e-05,
      "loss": 1.3157,
      "step": 9100
    },
    {
      "epoch": 0.028517376899989715,
      "grad_norm": 0.5416909456253052,
      "learning_rate": 4.952491816188105e-05,
      "loss": 1.3556,
      "step": 9150
    },
    {
      "epoch": 0.028673209560645396,
      "grad_norm": 0.5011885762214661,
      "learning_rate": 4.952232095087012e-05,
      "loss": 1.3482,
      "step": 9200
    },
    {
      "epoch": 0.028829042221301077,
      "grad_norm": 0.6984428763389587,
      "learning_rate": 4.951972373985919e-05,
      "loss": 1.3692,
      "step": 9250
    },
    {
      "epoch": 0.02898487488195676,
      "grad_norm": 0.55859375,
      "learning_rate": 4.9517126528848265e-05,
      "loss": 1.3304,
      "step": 9300
    },
    {
      "epoch": 0.02914070754261244,
      "grad_norm": 0.5255328416824341,
      "learning_rate": 4.951452931783734e-05,
      "loss": 1.3821,
      "step": 9350
    },
    {
      "epoch": 0.029296540203268124,
      "grad_norm": 0.7860026359558105,
      "learning_rate": 4.951193210682641e-05,
      "loss": 1.3003,
      "step": 9400
    },
    {
      "epoch": 0.029452372863923805,
      "grad_norm": 0.4465259313583374,
      "learning_rate": 4.950933489581548e-05,
      "loss": 1.3554,
      "step": 9450
    },
    {
      "epoch": 0.029608205524579486,
      "grad_norm": 0.6106611490249634,
      "learning_rate": 4.950673768480455e-05,
      "loss": 1.3289,
      "step": 9500
    },
    {
      "epoch": 0.029764038185235167,
      "grad_norm": 0.621932327747345,
      "learning_rate": 4.950414047379363e-05,
      "loss": 1.2975,
      "step": 9550
    },
    {
      "epoch": 0.029919870845890848,
      "grad_norm": 0.5347567200660706,
      "learning_rate": 4.950154326278269e-05,
      "loss": 1.3218,
      "step": 9600
    },
    {
      "epoch": 0.03007570350654653,
      "grad_norm": 0.5084118843078613,
      "learning_rate": 4.9498946051771766e-05,
      "loss": 1.3533,
      "step": 9650
    },
    {
      "epoch": 0.03023153616720221,
      "grad_norm": 0.56060791015625,
      "learning_rate": 4.9496348840760845e-05,
      "loss": 1.3555,
      "step": 9700
    },
    {
      "epoch": 0.030387368827857895,
      "grad_norm": 0.5590512156486511,
      "learning_rate": 4.949375162974991e-05,
      "loss": 1.3356,
      "step": 9750
    },
    {
      "epoch": 0.030543201488513576,
      "grad_norm": 0.6450424790382385,
      "learning_rate": 4.949115441873898e-05,
      "loss": 1.4093,
      "step": 9800
    },
    {
      "epoch": 0.030699034149169257,
      "grad_norm": 0.661279022693634,
      "learning_rate": 4.9488557207728056e-05,
      "loss": 1.4056,
      "step": 9850
    },
    {
      "epoch": 0.030854866809824938,
      "grad_norm": 0.518473744392395,
      "learning_rate": 4.948595999671713e-05,
      "loss": 1.3452,
      "step": 9900
    },
    {
      "epoch": 0.03101069947048062,
      "grad_norm": 0.5992773771286011,
      "learning_rate": 4.94833627857062e-05,
      "loss": 1.3307,
      "step": 9950
    },
    {
      "epoch": 0.0311665321311363,
      "grad_norm": 0.6271765232086182,
      "learning_rate": 4.948076557469527e-05,
      "loss": 1.3878,
      "step": 10000
    },
    {
      "epoch": 0.031322364791791985,
      "grad_norm": 0.5613080859184265,
      "learning_rate": 4.9478168363684346e-05,
      "loss": 1.3166,
      "step": 10050
    },
    {
      "epoch": 0.03147819745244766,
      "grad_norm": 0.6463966369628906,
      "learning_rate": 4.947557115267342e-05,
      "loss": 1.3602,
      "step": 10100
    },
    {
      "epoch": 0.03163403011310335,
      "grad_norm": 0.538008451461792,
      "learning_rate": 4.9472973941662484e-05,
      "loss": 1.2859,
      "step": 10150
    },
    {
      "epoch": 0.031789862773759024,
      "grad_norm": 0.5980814099311829,
      "learning_rate": 4.9470376730651556e-05,
      "loss": 1.3513,
      "step": 10200
    },
    {
      "epoch": 0.03194569543441471,
      "grad_norm": 0.5692278146743774,
      "learning_rate": 4.9467779519640636e-05,
      "loss": 1.3503,
      "step": 10250
    },
    {
      "epoch": 0.032101528095070386,
      "grad_norm": 0.6212124228477478,
      "learning_rate": 4.94651823086297e-05,
      "loss": 1.3609,
      "step": 10300
    },
    {
      "epoch": 0.03225736075572607,
      "grad_norm": 0.6525622606277466,
      "learning_rate": 4.9462585097618774e-05,
      "loss": 1.3097,
      "step": 10350
    },
    {
      "epoch": 0.032413193416381755,
      "grad_norm": 0.6026220321655273,
      "learning_rate": 4.9459987886607846e-05,
      "loss": 1.3698,
      "step": 10400
    },
    {
      "epoch": 0.03256902607703743,
      "grad_norm": 0.6604406237602234,
      "learning_rate": 4.945739067559692e-05,
      "loss": 1.3371,
      "step": 10450
    },
    {
      "epoch": 0.03272485873769312,
      "grad_norm": 0.5572109222412109,
      "learning_rate": 4.945479346458599e-05,
      "loss": 1.3117,
      "step": 10500
    },
    {
      "epoch": 0.032880691398348795,
      "grad_norm": 0.6909775137901306,
      "learning_rate": 4.9452196253575064e-05,
      "loss": 1.3815,
      "step": 10550
    },
    {
      "epoch": 0.03303652405900448,
      "grad_norm": 0.6230343580245972,
      "learning_rate": 4.9449599042564136e-05,
      "loss": 1.36,
      "step": 10600
    },
    {
      "epoch": 0.03319235671966016,
      "grad_norm": 0.5915206074714661,
      "learning_rate": 4.944700183155321e-05,
      "loss": 1.3198,
      "step": 10650
    },
    {
      "epoch": 0.03334818938031584,
      "grad_norm": 0.6122881770133972,
      "learning_rate": 4.944440462054228e-05,
      "loss": 1.2859,
      "step": 10700
    },
    {
      "epoch": 0.033504022040971526,
      "grad_norm": 0.43910908699035645,
      "learning_rate": 4.944180740953135e-05,
      "loss": 1.3356,
      "step": 10750
    },
    {
      "epoch": 0.033659854701627204,
      "grad_norm": 0.4497618079185486,
      "learning_rate": 4.9439210198520426e-05,
      "loss": 1.3222,
      "step": 10800
    },
    {
      "epoch": 0.03381568736228289,
      "grad_norm": 0.5217254161834717,
      "learning_rate": 4.943661298750949e-05,
      "loss": 1.3407,
      "step": 10850
    },
    {
      "epoch": 0.033971520022938566,
      "grad_norm": 0.4973808228969574,
      "learning_rate": 4.9434015776498565e-05,
      "loss": 1.2809,
      "step": 10900
    },
    {
      "epoch": 0.03412735268359425,
      "grad_norm": 0.6376396417617798,
      "learning_rate": 4.9431418565487644e-05,
      "loss": 1.3312,
      "step": 10950
    },
    {
      "epoch": 0.03428318534424993,
      "grad_norm": 0.5133669972419739,
      "learning_rate": 4.942882135447671e-05,
      "loss": 1.2954,
      "step": 11000
    },
    {
      "epoch": 0.03443901800490561,
      "grad_norm": 0.552364706993103,
      "learning_rate": 4.9426276087686e-05,
      "loss": 1.376,
      "step": 11050
    },
    {
      "epoch": 0.0345948506655613,
      "grad_norm": 0.5814685225486755,
      "learning_rate": 4.9423678876675074e-05,
      "loss": 1.3327,
      "step": 11100
    },
    {
      "epoch": 0.034750683326216975,
      "grad_norm": 0.6514005661010742,
      "learning_rate": 4.942108166566414e-05,
      "loss": 1.3459,
      "step": 11150
    },
    {
      "epoch": 0.03490651598687266,
      "grad_norm": 0.521371066570282,
      "learning_rate": 4.941848445465322e-05,
      "loss": 1.3374,
      "step": 11200
    },
    {
      "epoch": 0.03506234864752834,
      "grad_norm": 0.5665985941886902,
      "learning_rate": 4.941588724364229e-05,
      "loss": 1.3564,
      "step": 11250
    },
    {
      "epoch": 0.03521818130818402,
      "grad_norm": 0.45458582043647766,
      "learning_rate": 4.941329003263136e-05,
      "loss": 1.2821,
      "step": 11300
    },
    {
      "epoch": 0.0353740139688397,
      "grad_norm": 0.585964024066925,
      "learning_rate": 4.941069282162044e-05,
      "loss": 1.3341,
      "step": 11350
    },
    {
      "epoch": 0.03552984662949538,
      "grad_norm": 0.6169666647911072,
      "learning_rate": 4.940809561060951e-05,
      "loss": 1.3536,
      "step": 11400
    },
    {
      "epoch": 0.03568567929015106,
      "grad_norm": 0.6826348900794983,
      "learning_rate": 4.9405498399598575e-05,
      "loss": 1.3513,
      "step": 11450
    },
    {
      "epoch": 0.035841511950806745,
      "grad_norm": 0.6145089864730835,
      "learning_rate": 4.940290118858765e-05,
      "loss": 1.3231,
      "step": 11500
    },
    {
      "epoch": 0.03599734461146243,
      "grad_norm": 0.6278401017189026,
      "learning_rate": 4.940030397757672e-05,
      "loss": 1.3846,
      "step": 11550
    },
    {
      "epoch": 0.03615317727211811,
      "grad_norm": 0.7355685830116272,
      "learning_rate": 4.939770676656579e-05,
      "loss": 1.32,
      "step": 11600
    },
    {
      "epoch": 0.03630900993277379,
      "grad_norm": 0.6501304507255554,
      "learning_rate": 4.9395109555554865e-05,
      "loss": 1.3614,
      "step": 11650
    },
    {
      "epoch": 0.03646484259342947,
      "grad_norm": 0.6337055563926697,
      "learning_rate": 4.939251234454394e-05,
      "loss": 1.301,
      "step": 11700
    },
    {
      "epoch": 0.036620675254085154,
      "grad_norm": 0.41295114159584045,
      "learning_rate": 4.938991513353301e-05,
      "loss": 1.3173,
      "step": 11750
    },
    {
      "epoch": 0.03677650791474083,
      "grad_norm": 0.5521849989891052,
      "learning_rate": 4.938731792252208e-05,
      "loss": 1.3033,
      "step": 11800
    },
    {
      "epoch": 0.036932340575396516,
      "grad_norm": 0.6295973658561707,
      "learning_rate": 4.938472071151115e-05,
      "loss": 1.3176,
      "step": 11850
    },
    {
      "epoch": 0.0370881732360522,
      "grad_norm": 0.6295578479766846,
      "learning_rate": 4.938212350050023e-05,
      "loss": 1.3094,
      "step": 11900
    },
    {
      "epoch": 0.03724400589670788,
      "grad_norm": 0.5667539834976196,
      "learning_rate": 4.93795262894893e-05,
      "loss": 1.2738,
      "step": 11950
    },
    {
      "epoch": 0.03739983855736356,
      "grad_norm": 0.4580700397491455,
      "learning_rate": 4.9376929078478366e-05,
      "loss": 1.3188,
      "step": 12000
    },
    {
      "epoch": 0.03755567121801924,
      "grad_norm": 0.5771214365959167,
      "learning_rate": 4.9374331867467445e-05,
      "loss": 1.4024,
      "step": 12050
    },
    {
      "epoch": 0.037711503878674925,
      "grad_norm": 0.5450723767280579,
      "learning_rate": 4.937173465645652e-05,
      "loss": 1.3214,
      "step": 12100
    },
    {
      "epoch": 0.0378673365393306,
      "grad_norm": 0.5245606303215027,
      "learning_rate": 4.936913744544558e-05,
      "loss": 1.3502,
      "step": 12150
    },
    {
      "epoch": 0.03802316919998629,
      "grad_norm": 0.5243322849273682,
      "learning_rate": 4.9366540234434656e-05,
      "loss": 1.2793,
      "step": 12200
    },
    {
      "epoch": 0.03817900186064197,
      "grad_norm": 0.6634674668312073,
      "learning_rate": 4.936394302342373e-05,
      "loss": 1.2964,
      "step": 12250
    },
    {
      "epoch": 0.03833483452129765,
      "grad_norm": 0.6987941861152649,
      "learning_rate": 4.93613458124128e-05,
      "loss": 1.3196,
      "step": 12300
    },
    {
      "epoch": 0.038490667181953334,
      "grad_norm": 0.6231584548950195,
      "learning_rate": 4.935874860140187e-05,
      "loss": 1.3387,
      "step": 12350
    },
    {
      "epoch": 0.03864649984260901,
      "grad_norm": 0.5934983491897583,
      "learning_rate": 4.935615139039094e-05,
      "loss": 1.3363,
      "step": 12400
    },
    {
      "epoch": 0.038802332503264696,
      "grad_norm": 0.6165801882743835,
      "learning_rate": 4.935355417938002e-05,
      "loss": 1.2793,
      "step": 12450
    },
    {
      "epoch": 0.03895816516392037,
      "grad_norm": 0.5420882701873779,
      "learning_rate": 4.935095696836909e-05,
      "loss": 1.3474,
      "step": 12500
    },
    {
      "epoch": 0.03911399782457606,
      "grad_norm": 0.73361736536026,
      "learning_rate": 4.9348359757358157e-05,
      "loss": 1.2829,
      "step": 12550
    },
    {
      "epoch": 0.039269830485231735,
      "grad_norm": 0.6302063465118408,
      "learning_rate": 4.9345762546347236e-05,
      "loss": 1.3381,
      "step": 12600
    },
    {
      "epoch": 0.03942566314588742,
      "grad_norm": 0.5337669253349304,
      "learning_rate": 4.934316533533631e-05,
      "loss": 1.3625,
      "step": 12650
    },
    {
      "epoch": 0.039581495806543104,
      "grad_norm": 0.6561464071273804,
      "learning_rate": 4.9340568124325374e-05,
      "loss": 1.2956,
      "step": 12700
    },
    {
      "epoch": 0.03973732846719878,
      "grad_norm": 0.6201326251029968,
      "learning_rate": 4.9337970913314447e-05,
      "loss": 1.3199,
      "step": 12750
    },
    {
      "epoch": 0.039893161127854466,
      "grad_norm": 0.5381652116775513,
      "learning_rate": 4.933537370230352e-05,
      "loss": 1.2778,
      "step": 12800
    },
    {
      "epoch": 0.040048993788510144,
      "grad_norm": 0.4777800440788269,
      "learning_rate": 4.933277649129259e-05,
      "loss": 1.314,
      "step": 12850
    },
    {
      "epoch": 0.04020482644916583,
      "grad_norm": 0.6574421525001526,
      "learning_rate": 4.9330179280281664e-05,
      "loss": 1.3168,
      "step": 12900
    },
    {
      "epoch": 0.040360659109821506,
      "grad_norm": 0.6006549596786499,
      "learning_rate": 4.9327582069270737e-05,
      "loss": 1.3104,
      "step": 12950
    },
    {
      "epoch": 0.04051649177047719,
      "grad_norm": 0.47469907999038696,
      "learning_rate": 4.932498485825981e-05,
      "loss": 1.3135,
      "step": 13000
    },
    {
      "epoch": 0.040672324431132875,
      "grad_norm": 0.6917524933815002,
      "learning_rate": 4.932238764724888e-05,
      "loss": 1.3433,
      "step": 13050
    },
    {
      "epoch": 0.04082815709178855,
      "grad_norm": 0.5787776708602905,
      "learning_rate": 4.931979043623795e-05,
      "loss": 1.2815,
      "step": 13100
    },
    {
      "epoch": 0.04098398975244424,
      "grad_norm": 0.47281724214553833,
      "learning_rate": 4.9317193225227027e-05,
      "loss": 1.3527,
      "step": 13150
    },
    {
      "epoch": 0.041139822413099915,
      "grad_norm": 0.47664567828178406,
      "learning_rate": 4.93145960142161e-05,
      "loss": 1.3975,
      "step": 13200
    },
    {
      "epoch": 0.0412956550737556,
      "grad_norm": 0.4908343553543091,
      "learning_rate": 4.9311998803205165e-05,
      "loss": 1.3468,
      "step": 13250
    },
    {
      "epoch": 0.04145148773441128,
      "grad_norm": 0.721848726272583,
      "learning_rate": 4.9309401592194244e-05,
      "loss": 1.3437,
      "step": 13300
    },
    {
      "epoch": 0.04160732039506696,
      "grad_norm": 0.5941927433013916,
      "learning_rate": 4.9306804381183317e-05,
      "loss": 1.2906,
      "step": 13350
    },
    {
      "epoch": 0.041763153055722646,
      "grad_norm": 0.6098179817199707,
      "learning_rate": 4.930420717017238e-05,
      "loss": 1.3365,
      "step": 13400
    },
    {
      "epoch": 0.041918985716378324,
      "grad_norm": 0.4796716570854187,
      "learning_rate": 4.9301609959161455e-05,
      "loss": 1.3181,
      "step": 13450
    },
    {
      "epoch": 0.04207481837703401,
      "grad_norm": 0.6073000431060791,
      "learning_rate": 4.929901274815053e-05,
      "loss": 1.355,
      "step": 13500
    },
    {
      "epoch": 0.042230651037689686,
      "grad_norm": 0.6920226812362671,
      "learning_rate": 4.92964155371396e-05,
      "loss": 1.3006,
      "step": 13550
    },
    {
      "epoch": 0.04238648369834537,
      "grad_norm": 0.6108245849609375,
      "learning_rate": 4.929381832612867e-05,
      "loss": 1.3726,
      "step": 13600
    },
    {
      "epoch": 0.04254231635900105,
      "grad_norm": 0.6233474016189575,
      "learning_rate": 4.9291221115117745e-05,
      "loss": 1.2834,
      "step": 13650
    },
    {
      "epoch": 0.04269814901965673,
      "grad_norm": 0.7085373997688293,
      "learning_rate": 4.928862390410682e-05,
      "loss": 1.2549,
      "step": 13700
    },
    {
      "epoch": 0.04285398168031241,
      "grad_norm": 0.5703209042549133,
      "learning_rate": 4.928602669309589e-05,
      "loss": 1.3308,
      "step": 13750
    },
    {
      "epoch": 0.043009814340968094,
      "grad_norm": 0.4790760278701782,
      "learning_rate": 4.9283429482084956e-05,
      "loss": 1.3281,
      "step": 13800
    },
    {
      "epoch": 0.04316564700162378,
      "grad_norm": 0.6729546189308167,
      "learning_rate": 4.9280832271074035e-05,
      "loss": 1.3309,
      "step": 13850
    },
    {
      "epoch": 0.043321479662279457,
      "grad_norm": 0.6412696242332458,
      "learning_rate": 4.927823506006311e-05,
      "loss": 1.3094,
      "step": 13900
    },
    {
      "epoch": 0.04347731232293514,
      "grad_norm": 0.6497218608856201,
      "learning_rate": 4.927563784905217e-05,
      "loss": 1.3233,
      "step": 13950
    },
    {
      "epoch": 0.04363314498359082,
      "grad_norm": 0.5260319709777832,
      "learning_rate": 4.9273040638041246e-05,
      "loss": 1.3158,
      "step": 14000
    },
    {
      "epoch": 0.0437889776442465,
      "grad_norm": 0.5534887909889221,
      "learning_rate": 4.9270443427030325e-05,
      "loss": 1.3589,
      "step": 14050
    },
    {
      "epoch": 0.04394481030490218,
      "grad_norm": 0.6038696765899658,
      "learning_rate": 4.926784621601939e-05,
      "loss": 1.3196,
      "step": 14100
    },
    {
      "epoch": 0.044100642965557865,
      "grad_norm": 0.7177510857582092,
      "learning_rate": 4.926524900500846e-05,
      "loss": 1.3298,
      "step": 14150
    },
    {
      "epoch": 0.04425647562621355,
      "grad_norm": 0.7040425539016724,
      "learning_rate": 4.9262651793997536e-05,
      "loss": 1.3082,
      "step": 14200
    },
    {
      "epoch": 0.04441230828686923,
      "grad_norm": 0.5971282720565796,
      "learning_rate": 4.926005458298661e-05,
      "loss": 1.3539,
      "step": 14250
    },
    {
      "epoch": 0.04456814094752491,
      "grad_norm": 0.5138790011405945,
      "learning_rate": 4.925745737197568e-05,
      "loss": 1.3127,
      "step": 14300
    },
    {
      "epoch": 0.04472397360818059,
      "grad_norm": 0.5469639301300049,
      "learning_rate": 4.925486016096475e-05,
      "loss": 1.3652,
      "step": 14350
    },
    {
      "epoch": 0.044879806268836274,
      "grad_norm": 0.5001862049102783,
      "learning_rate": 4.9252262949953826e-05,
      "loss": 1.3055,
      "step": 14400
    },
    {
      "epoch": 0.04503563892949195,
      "grad_norm": 0.7014634013175964,
      "learning_rate": 4.92496657389429e-05,
      "loss": 1.3256,
      "step": 14450
    },
    {
      "epoch": 0.045191471590147636,
      "grad_norm": 0.473521888256073,
      "learning_rate": 4.9247068527931964e-05,
      "loss": 1.2734,
      "step": 14500
    },
    {
      "epoch": 0.04534730425080332,
      "grad_norm": 0.5744761824607849,
      "learning_rate": 4.924447131692104e-05,
      "loss": 1.3287,
      "step": 14550
    },
    {
      "epoch": 0.045503136911459,
      "grad_norm": 0.5863804221153259,
      "learning_rate": 4.9241874105910116e-05,
      "loss": 1.3037,
      "step": 14600
    },
    {
      "epoch": 0.04565896957211468,
      "grad_norm": 0.5033121109008789,
      "learning_rate": 4.923927689489918e-05,
      "loss": 1.3028,
      "step": 14650
    },
    {
      "epoch": 0.04581480223277036,
      "grad_norm": 0.5229918360710144,
      "learning_rate": 4.9236679683888254e-05,
      "loss": 1.2957,
      "step": 14700
    },
    {
      "epoch": 0.045970634893426045,
      "grad_norm": 0.6024394631385803,
      "learning_rate": 4.923408247287733e-05,
      "loss": 1.3955,
      "step": 14750
    },
    {
      "epoch": 0.04612646755408172,
      "grad_norm": 0.5664291381835938,
      "learning_rate": 4.92314852618664e-05,
      "loss": 1.3453,
      "step": 14800
    },
    {
      "epoch": 0.04628230021473741,
      "grad_norm": 0.707773745059967,
      "learning_rate": 4.922893999507569e-05,
      "loss": 1.3015,
      "step": 14850
    },
    {
      "epoch": 0.046438132875393084,
      "grad_norm": 0.6748160123825073,
      "learning_rate": 4.9226342784064763e-05,
      "loss": 1.3255,
      "step": 14900
    },
    {
      "epoch": 0.04659396553604877,
      "grad_norm": 0.5577136278152466,
      "learning_rate": 4.9223745573053836e-05,
      "loss": 1.3657,
      "step": 14950
    },
    {
      "epoch": 0.04674979819670445,
      "grad_norm": 0.6500369310379028,
      "learning_rate": 4.922114836204291e-05,
      "loss": 1.3015,
      "step": 15000
    },
    {
      "epoch": 0.04690563085736013,
      "grad_norm": 0.6255702972412109,
      "learning_rate": 4.9218551151031974e-05,
      "loss": 1.2758,
      "step": 15050
    },
    {
      "epoch": 0.047061463518015816,
      "grad_norm": 0.6593366861343384,
      "learning_rate": 4.921595394002105e-05,
      "loss": 1.2773,
      "step": 15100
    },
    {
      "epoch": 0.04721729617867149,
      "grad_norm": 0.5971003174781799,
      "learning_rate": 4.9213356729010126e-05,
      "loss": 1.2887,
      "step": 15150
    },
    {
      "epoch": 0.04737312883932718,
      "grad_norm": 0.5243743658065796,
      "learning_rate": 4.921075951799919e-05,
      "loss": 1.3119,
      "step": 15200
    },
    {
      "epoch": 0.047528961499982855,
      "grad_norm": 0.5865691900253296,
      "learning_rate": 4.9208162306988264e-05,
      "loss": 1.2678,
      "step": 15250
    },
    {
      "epoch": 0.04768479416063854,
      "grad_norm": 0.5299168229103088,
      "learning_rate": 4.9205565095977343e-05,
      "loss": 1.3204,
      "step": 15300
    },
    {
      "epoch": 0.047840626821294224,
      "grad_norm": 0.6551268696784973,
      "learning_rate": 4.920296788496641e-05,
      "loss": 1.3388,
      "step": 15350
    },
    {
      "epoch": 0.0479964594819499,
      "grad_norm": 0.5958969593048096,
      "learning_rate": 4.920037067395548e-05,
      "loss": 1.2684,
      "step": 15400
    },
    {
      "epoch": 0.048152292142605586,
      "grad_norm": 0.6927958726882935,
      "learning_rate": 4.9197773462944554e-05,
      "loss": 1.3014,
      "step": 15450
    },
    {
      "epoch": 0.048308124803261264,
      "grad_norm": 0.636989951133728,
      "learning_rate": 4.919517625193363e-05,
      "loss": 1.3207,
      "step": 15500
    },
    {
      "epoch": 0.04846395746391695,
      "grad_norm": 0.5205816030502319,
      "learning_rate": 4.91925790409227e-05,
      "loss": 1.2947,
      "step": 15550
    },
    {
      "epoch": 0.048619790124572626,
      "grad_norm": 0.6730199456214905,
      "learning_rate": 4.918998182991177e-05,
      "loss": 1.3285,
      "step": 15600
    },
    {
      "epoch": 0.04877562278522831,
      "grad_norm": 0.6243571639060974,
      "learning_rate": 4.918738461890084e-05,
      "loss": 1.3069,
      "step": 15650
    },
    {
      "epoch": 0.048931455445883995,
      "grad_norm": 0.7028855085372925,
      "learning_rate": 4.918478740788992e-05,
      "loss": 1.3349,
      "step": 15700
    },
    {
      "epoch": 0.04908728810653967,
      "grad_norm": 0.4967229664325714,
      "learning_rate": 4.918219019687898e-05,
      "loss": 1.312,
      "step": 15750
    },
    {
      "epoch": 0.04924312076719536,
      "grad_norm": 0.6167621612548828,
      "learning_rate": 4.9179592985868055e-05,
      "loss": 1.3329,
      "step": 15800
    },
    {
      "epoch": 0.049398953427851035,
      "grad_norm": 0.6000052690505981,
      "learning_rate": 4.9176995774857134e-05,
      "loss": 1.3614,
      "step": 15850
    },
    {
      "epoch": 0.04955478608850672,
      "grad_norm": 0.5442448258399963,
      "learning_rate": 4.91743985638462e-05,
      "loss": 1.2987,
      "step": 15900
    },
    {
      "epoch": 0.0497106187491624,
      "grad_norm": 0.6132346391677856,
      "learning_rate": 4.917180135283527e-05,
      "loss": 1.3538,
      "step": 15950
    },
    {
      "epoch": 0.04986645140981808,
      "grad_norm": 0.5367105007171631,
      "learning_rate": 4.9169204141824345e-05,
      "loss": 1.3374,
      "step": 16000
    },
    {
      "epoch": 0.050022284070473766,
      "grad_norm": 0.6514263153076172,
      "learning_rate": 4.916660693081342e-05,
      "loss": 1.2956,
      "step": 16050
    },
    {
      "epoch": 0.050178116731129443,
      "grad_norm": 0.4962891936302185,
      "learning_rate": 4.916400971980249e-05,
      "loss": 1.2984,
      "step": 16100
    },
    {
      "epoch": 0.05033394939178513,
      "grad_norm": 0.546183705329895,
      "learning_rate": 4.916141250879156e-05,
      "loss": 1.2724,
      "step": 16150
    },
    {
      "epoch": 0.050489782052440806,
      "grad_norm": 0.6512373089790344,
      "learning_rate": 4.9158815297780635e-05,
      "loss": 1.2927,
      "step": 16200
    },
    {
      "epoch": 0.05064561471309649,
      "grad_norm": 0.5714925527572632,
      "learning_rate": 4.915621808676971e-05,
      "loss": 1.2953,
      "step": 16250
    },
    {
      "epoch": 0.05080144737375217,
      "grad_norm": 0.569648802280426,
      "learning_rate": 4.915362087575878e-05,
      "loss": 1.3459,
      "step": 16300
    },
    {
      "epoch": 0.05095728003440785,
      "grad_norm": 0.571098804473877,
      "learning_rate": 4.9151023664747846e-05,
      "loss": 1.3769,
      "step": 16350
    },
    {
      "epoch": 0.05111311269506353,
      "grad_norm": 0.5413248538970947,
      "learning_rate": 4.9148426453736925e-05,
      "loss": 1.3174,
      "step": 16400
    },
    {
      "epoch": 0.051268945355719214,
      "grad_norm": 0.41414687037467957,
      "learning_rate": 4.914582924272599e-05,
      "loss": 1.3615,
      "step": 16450
    },
    {
      "epoch": 0.0514247780163749,
      "grad_norm": 0.5618326663970947,
      "learning_rate": 4.914323203171506e-05,
      "loss": 1.2907,
      "step": 16500
    },
    {
      "epoch": 0.051580610677030576,
      "grad_norm": 0.6484780311584473,
      "learning_rate": 4.914063482070414e-05,
      "loss": 1.3312,
      "step": 16550
    },
    {
      "epoch": 0.05173644333768626,
      "grad_norm": 0.7405387759208679,
      "learning_rate": 4.913803760969321e-05,
      "loss": 1.393,
      "step": 16600
    },
    {
      "epoch": 0.05189227599834194,
      "grad_norm": 0.5075403451919556,
      "learning_rate": 4.913544039868228e-05,
      "loss": 1.3467,
      "step": 16650
    },
    {
      "epoch": 0.05204810865899762,
      "grad_norm": 0.604575514793396,
      "learning_rate": 4.913284318767135e-05,
      "loss": 1.2855,
      "step": 16700
    },
    {
      "epoch": 0.0522039413196533,
      "grad_norm": 0.6261927485466003,
      "learning_rate": 4.9130245976660426e-05,
      "loss": 1.3134,
      "step": 16750
    },
    {
      "epoch": 0.052359773980308985,
      "grad_norm": 0.5492614507675171,
      "learning_rate": 4.91276487656495e-05,
      "loss": 1.2947,
      "step": 16800
    },
    {
      "epoch": 0.05251560664096467,
      "grad_norm": 0.6490501165390015,
      "learning_rate": 4.912505155463857e-05,
      "loss": 1.3131,
      "step": 16850
    },
    {
      "epoch": 0.05267143930162035,
      "grad_norm": 0.7340015769004822,
      "learning_rate": 4.9122454343627636e-05,
      "loss": 1.2876,
      "step": 16900
    },
    {
      "epoch": 0.05282727196227603,
      "grad_norm": 0.6413069367408752,
      "learning_rate": 4.9119857132616716e-05,
      "loss": 1.3271,
      "step": 16950
    },
    {
      "epoch": 0.05298310462293171,
      "grad_norm": 0.5778433680534363,
      "learning_rate": 4.911725992160579e-05,
      "loss": 1.2708,
      "step": 17000
    },
    {
      "epoch": 0.053138937283587394,
      "grad_norm": 0.5903887152671814,
      "learning_rate": 4.9114662710594854e-05,
      "loss": 1.2893,
      "step": 17050
    },
    {
      "epoch": 0.05329476994424307,
      "grad_norm": 0.6623691916465759,
      "learning_rate": 4.911206549958393e-05,
      "loss": 1.2756,
      "step": 17100
    },
    {
      "epoch": 0.053450602604898756,
      "grad_norm": 0.5450072884559631,
      "learning_rate": 4.9109468288573e-05,
      "loss": 1.3285,
      "step": 17150
    },
    {
      "epoch": 0.05360643526555444,
      "grad_norm": 0.6721314787864685,
      "learning_rate": 4.910687107756207e-05,
      "loss": 1.3641,
      "step": 17200
    },
    {
      "epoch": 0.05376226792621012,
      "grad_norm": 0.7195709943771362,
      "learning_rate": 4.9104273866551144e-05,
      "loss": 1.3405,
      "step": 17250
    },
    {
      "epoch": 0.0539181005868658,
      "grad_norm": 0.6551278233528137,
      "learning_rate": 4.9101676655540216e-05,
      "loss": 1.3339,
      "step": 17300
    },
    {
      "epoch": 0.05407393324752148,
      "grad_norm": 0.5622365474700928,
      "learning_rate": 4.909907944452929e-05,
      "loss": 1.3244,
      "step": 17350
    },
    {
      "epoch": 0.054229765908177165,
      "grad_norm": 0.5875991582870483,
      "learning_rate": 4.909648223351836e-05,
      "loss": 1.2706,
      "step": 17400
    },
    {
      "epoch": 0.05438559856883284,
      "grad_norm": 0.6812454462051392,
      "learning_rate": 4.9093885022507434e-05,
      "loss": 1.2863,
      "step": 17450
    },
    {
      "epoch": 0.05454143122948853,
      "grad_norm": 0.6270332336425781,
      "learning_rate": 4.9091287811496506e-05,
      "loss": 1.3164,
      "step": 17500
    },
    {
      "epoch": 0.054697263890144204,
      "grad_norm": 0.6896236538887024,
      "learning_rate": 4.908869060048558e-05,
      "loss": 1.3069,
      "step": 17550
    },
    {
      "epoch": 0.05485309655079989,
      "grad_norm": 0.5506631731987,
      "learning_rate": 4.9086093389474645e-05,
      "loss": 1.2963,
      "step": 17600
    },
    {
      "epoch": 0.05500892921145557,
      "grad_norm": 0.6167387366294861,
      "learning_rate": 4.9083496178463724e-05,
      "loss": 1.3244,
      "step": 17650
    },
    {
      "epoch": 0.05516476187211125,
      "grad_norm": 0.6447786092758179,
      "learning_rate": 4.908089896745279e-05,
      "loss": 1.3085,
      "step": 17700
    },
    {
      "epoch": 0.055320594532766935,
      "grad_norm": 0.7191133499145508,
      "learning_rate": 4.907830175644186e-05,
      "loss": 1.3436,
      "step": 17750
    },
    {
      "epoch": 0.05547642719342261,
      "grad_norm": 0.5406160950660706,
      "learning_rate": 4.907570454543094e-05,
      "loss": 1.3204,
      "step": 17800
    },
    {
      "epoch": 0.0556322598540783,
      "grad_norm": 0.4558112621307373,
      "learning_rate": 4.907310733442001e-05,
      "loss": 1.3339,
      "step": 17850
    },
    {
      "epoch": 0.055788092514733975,
      "grad_norm": 0.5859459042549133,
      "learning_rate": 4.907051012340908e-05,
      "loss": 1.3761,
      "step": 17900
    },
    {
      "epoch": 0.05594392517538966,
      "grad_norm": 0.6202095746994019,
      "learning_rate": 4.906791291239815e-05,
      "loss": 1.3178,
      "step": 17950
    },
    {
      "epoch": 0.056099757836045344,
      "grad_norm": 0.689379096031189,
      "learning_rate": 4.9065315701387225e-05,
      "loss": 1.3302,
      "step": 18000
    },
    {
      "epoch": 0.05625559049670102,
      "grad_norm": 0.5299913883209229,
      "learning_rate": 4.90627184903763e-05,
      "loss": 1.3465,
      "step": 18050
    },
    {
      "epoch": 0.056411423157356706,
      "grad_norm": 0.5098860263824463,
      "learning_rate": 4.906012127936537e-05,
      "loss": 1.3622,
      "step": 18100
    },
    {
      "epoch": 0.056567255818012384,
      "grad_norm": 0.5675342679023743,
      "learning_rate": 4.9057524068354435e-05,
      "loss": 1.3201,
      "step": 18150
    },
    {
      "epoch": 0.05672308847866807,
      "grad_norm": 0.5817385911941528,
      "learning_rate": 4.9054926857343515e-05,
      "loss": 1.3284,
      "step": 18200
    },
    {
      "epoch": 0.056878921139323746,
      "grad_norm": 0.6674662828445435,
      "learning_rate": 4.905238159055281e-05,
      "loss": 1.3009,
      "step": 18250
    },
    {
      "epoch": 0.05703475379997943,
      "grad_norm": 0.5713239908218384,
      "learning_rate": 4.904978437954187e-05,
      "loss": 1.3294,
      "step": 18300
    },
    {
      "epoch": 0.057190586460635115,
      "grad_norm": 0.6600815057754517,
      "learning_rate": 4.9047187168530945e-05,
      "loss": 1.2839,
      "step": 18350
    },
    {
      "epoch": 0.05734641912129079,
      "grad_norm": 0.5996883511543274,
      "learning_rate": 4.904458995752002e-05,
      "loss": 1.3043,
      "step": 18400
    },
    {
      "epoch": 0.05750225178194648,
      "grad_norm": 0.6518127918243408,
      "learning_rate": 4.904199274650909e-05,
      "loss": 1.3164,
      "step": 18450
    },
    {
      "epoch": 0.057658084442602155,
      "grad_norm": 0.5598846077919006,
      "learning_rate": 4.903939553549816e-05,
      "loss": 1.3695,
      "step": 18500
    },
    {
      "epoch": 0.05781391710325784,
      "grad_norm": 0.6593405604362488,
      "learning_rate": 4.9036798324487235e-05,
      "loss": 1.2691,
      "step": 18550
    },
    {
      "epoch": 0.05796974976391352,
      "grad_norm": 0.743005633354187,
      "learning_rate": 4.903420111347631e-05,
      "loss": 1.301,
      "step": 18600
    },
    {
      "epoch": 0.0581255824245692,
      "grad_norm": 0.5752042531967163,
      "learning_rate": 4.903160390246538e-05,
      "loss": 1.3439,
      "step": 18650
    },
    {
      "epoch": 0.05828141508522488,
      "grad_norm": 0.5409443974494934,
      "learning_rate": 4.9029006691454446e-05,
      "loss": 1.3284,
      "step": 18700
    },
    {
      "epoch": 0.05843724774588056,
      "grad_norm": 0.6798097491264343,
      "learning_rate": 4.9026409480443525e-05,
      "loss": 1.304,
      "step": 18750
    },
    {
      "epoch": 0.05859308040653625,
      "grad_norm": 0.5730852484703064,
      "learning_rate": 4.90238122694326e-05,
      "loss": 1.3731,
      "step": 18800
    },
    {
      "epoch": 0.058748913067191925,
      "grad_norm": 0.4426526129245758,
      "learning_rate": 4.902121505842166e-05,
      "loss": 1.279,
      "step": 18850
    },
    {
      "epoch": 0.05890474572784761,
      "grad_norm": 0.4902353286743164,
      "learning_rate": 4.9018617847410736e-05,
      "loss": 1.3224,
      "step": 18900
    },
    {
      "epoch": 0.05906057838850329,
      "grad_norm": 0.6324201822280884,
      "learning_rate": 4.9016020636399815e-05,
      "loss": 1.2755,
      "step": 18950
    },
    {
      "epoch": 0.05921641104915897,
      "grad_norm": 0.6180155277252197,
      "learning_rate": 4.901342342538888e-05,
      "loss": 1.3294,
      "step": 19000
    },
    {
      "epoch": 0.05937224370981465,
      "grad_norm": 0.5692262053489685,
      "learning_rate": 4.9010826214377953e-05,
      "loss": 1.3096,
      "step": 19050
    },
    {
      "epoch": 0.059528076370470334,
      "grad_norm": 0.5690851807594299,
      "learning_rate": 4.9008229003367026e-05,
      "loss": 1.3216,
      "step": 19100
    },
    {
      "epoch": 0.05968390903112602,
      "grad_norm": 0.5450013279914856,
      "learning_rate": 4.90056317923561e-05,
      "loss": 1.3329,
      "step": 19150
    },
    {
      "epoch": 0.059839741691781696,
      "grad_norm": 0.7321640849113464,
      "learning_rate": 4.900303458134517e-05,
      "loss": 1.2952,
      "step": 19200
    },
    {
      "epoch": 0.05999557435243738,
      "grad_norm": 0.5724133849143982,
      "learning_rate": 4.9000437370334243e-05,
      "loss": 1.3218,
      "step": 19250
    },
    {
      "epoch": 0.06015140701309306,
      "grad_norm": 0.6162165403366089,
      "learning_rate": 4.8997840159323316e-05,
      "loss": 1.3889,
      "step": 19300
    },
    {
      "epoch": 0.06030723967374874,
      "grad_norm": 0.5620720982551575,
      "learning_rate": 4.899529489253261e-05,
      "loss": 1.313,
      "step": 19350
    },
    {
      "epoch": 0.06046307233440442,
      "grad_norm": 0.6020556092262268,
      "learning_rate": 4.8992697681521674e-05,
      "loss": 1.2723,
      "step": 19400
    },
    {
      "epoch": 0.060618904995060105,
      "grad_norm": 0.5881445407867432,
      "learning_rate": 4.8990100470510746e-05,
      "loss": 1.3593,
      "step": 19450
    },
    {
      "epoch": 0.06077473765571579,
      "grad_norm": 0.5690835118293762,
      "learning_rate": 4.8987503259499826e-05,
      "loss": 1.3196,
      "step": 19500
    },
    {
      "epoch": 0.06093057031637147,
      "grad_norm": 0.5006747245788574,
      "learning_rate": 4.898490604848889e-05,
      "loss": 1.3004,
      "step": 19550
    },
    {
      "epoch": 0.06108640297702715,
      "grad_norm": 0.6575213670730591,
      "learning_rate": 4.8982308837477964e-05,
      "loss": 1.3203,
      "step": 19600
    },
    {
      "epoch": 0.06124223563768283,
      "grad_norm": 0.4860774278640747,
      "learning_rate": 4.897971162646704e-05,
      "loss": 1.3231,
      "step": 19650
    },
    {
      "epoch": 0.061398068298338514,
      "grad_norm": 0.6008149981498718,
      "learning_rate": 4.897711441545611e-05,
      "loss": 1.3628,
      "step": 19700
    },
    {
      "epoch": 0.06155390095899419,
      "grad_norm": 0.4796428084373474,
      "learning_rate": 4.897451720444518e-05,
      "loss": 1.3454,
      "step": 19750
    },
    {
      "epoch": 0.061709733619649876,
      "grad_norm": 0.5289350748062134,
      "learning_rate": 4.8971919993434254e-05,
      "loss": 1.3141,
      "step": 19800
    },
    {
      "epoch": 0.06186556628030555,
      "grad_norm": 0.5922225117683411,
      "learning_rate": 4.8969322782423326e-05,
      "loss": 1.286,
      "step": 19850
    },
    {
      "epoch": 0.06202139894096124,
      "grad_norm": 0.501168429851532,
      "learning_rate": 4.89667255714124e-05,
      "loss": 1.3518,
      "step": 19900
    },
    {
      "epoch": 0.06217723160161692,
      "grad_norm": 0.4977298676967621,
      "learning_rate": 4.8964128360401465e-05,
      "loss": 1.3765,
      "step": 19950
    },
    {
      "epoch": 0.0623330642622726,
      "grad_norm": 0.5489521622657776,
      "learning_rate": 4.896153114939054e-05,
      "loss": 1.2961,
      "step": 20000
    },
    {
      "epoch": 0.062488896922928285,
      "grad_norm": 0.5225569009780884,
      "learning_rate": 4.8958933938379616e-05,
      "loss": 1.3535,
      "step": 20050
    },
    {
      "epoch": 0.06264472958358397,
      "grad_norm": 0.5628852844238281,
      "learning_rate": 4.895633672736868e-05,
      "loss": 1.3331,
      "step": 20100
    },
    {
      "epoch": 0.06280056224423965,
      "grad_norm": 0.6725828647613525,
      "learning_rate": 4.8953739516357755e-05,
      "loss": 1.2977,
      "step": 20150
    },
    {
      "epoch": 0.06295639490489532,
      "grad_norm": 0.5704392194747925,
      "learning_rate": 4.8951142305346834e-05,
      "loss": 1.2599,
      "step": 20200
    },
    {
      "epoch": 0.063112227565551,
      "grad_norm": 0.44948986172676086,
      "learning_rate": 4.89485450943359e-05,
      "loss": 1.3113,
      "step": 20250
    },
    {
      "epoch": 0.0632680602262067,
      "grad_norm": 0.7019140124320984,
      "learning_rate": 4.894594788332497e-05,
      "loss": 1.3302,
      "step": 20300
    },
    {
      "epoch": 0.06342389288686237,
      "grad_norm": 0.5210559368133545,
      "learning_rate": 4.8943350672314045e-05,
      "loss": 1.2972,
      "step": 20350
    },
    {
      "epoch": 0.06357972554751805,
      "grad_norm": 0.7642370462417603,
      "learning_rate": 4.894075346130312e-05,
      "loss": 1.321,
      "step": 20400
    },
    {
      "epoch": 0.06373555820817374,
      "grad_norm": 0.5920374393463135,
      "learning_rate": 4.893815625029219e-05,
      "loss": 1.2618,
      "step": 20450
    },
    {
      "epoch": 0.06389139086882942,
      "grad_norm": 0.5976455211639404,
      "learning_rate": 4.893555903928126e-05,
      "loss": 1.3206,
      "step": 20500
    },
    {
      "epoch": 0.0640472235294851,
      "grad_norm": 0.6907004117965698,
      "learning_rate": 4.8932961828270335e-05,
      "loss": 1.321,
      "step": 20550
    },
    {
      "epoch": 0.06420305619014077,
      "grad_norm": 0.5480582118034363,
      "learning_rate": 4.893036461725941e-05,
      "loss": 1.3481,
      "step": 20600
    },
    {
      "epoch": 0.06435888885079646,
      "grad_norm": 0.44297078251838684,
      "learning_rate": 4.892776740624847e-05,
      "loss": 1.3043,
      "step": 20650
    },
    {
      "epoch": 0.06451472151145214,
      "grad_norm": 0.574670135974884,
      "learning_rate": 4.8925170195237545e-05,
      "loss": 1.3462,
      "step": 20700
    },
    {
      "epoch": 0.06467055417210782,
      "grad_norm": 0.5024979114532471,
      "learning_rate": 4.8922572984226625e-05,
      "loss": 1.3528,
      "step": 20750
    },
    {
      "epoch": 0.06482638683276351,
      "grad_norm": 0.557810366153717,
      "learning_rate": 4.891997577321569e-05,
      "loss": 1.3051,
      "step": 20800
    },
    {
      "epoch": 0.06498221949341919,
      "grad_norm": 0.6091673374176025,
      "learning_rate": 4.891737856220476e-05,
      "loss": 1.3088,
      "step": 20850
    },
    {
      "epoch": 0.06513805215407487,
      "grad_norm": 0.6039398312568665,
      "learning_rate": 4.891478135119384e-05,
      "loss": 1.2198,
      "step": 20900
    },
    {
      "epoch": 0.06529388481473054,
      "grad_norm": 0.6169371008872986,
      "learning_rate": 4.891218414018291e-05,
      "loss": 1.3189,
      "step": 20950
    },
    {
      "epoch": 0.06544971747538623,
      "grad_norm": 0.6271533370018005,
      "learning_rate": 4.890958692917198e-05,
      "loss": 1.2992,
      "step": 21000
    },
    {
      "epoch": 0.06560555013604191,
      "grad_norm": 0.4997614026069641,
      "learning_rate": 4.890698971816105e-05,
      "loss": 1.3626,
      "step": 21050
    },
    {
      "epoch": 0.06576138279669759,
      "grad_norm": 0.5651363730430603,
      "learning_rate": 4.8904392507150125e-05,
      "loss": 1.3593,
      "step": 21100
    },
    {
      "epoch": 0.06591721545735328,
      "grad_norm": 0.5678090453147888,
      "learning_rate": 4.89017952961392e-05,
      "loss": 1.3216,
      "step": 21150
    },
    {
      "epoch": 0.06607304811800896,
      "grad_norm": 0.6098047494888306,
      "learning_rate": 4.889919808512827e-05,
      "loss": 1.3337,
      "step": 21200
    },
    {
      "epoch": 0.06622888077866464,
      "grad_norm": 0.5465180277824402,
      "learning_rate": 4.8896600874117336e-05,
      "loss": 1.3683,
      "step": 21250
    },
    {
      "epoch": 0.06638471343932031,
      "grad_norm": 0.7699115872383118,
      "learning_rate": 4.8894003663106415e-05,
      "loss": 1.3562,
      "step": 21300
    },
    {
      "epoch": 0.066540546099976,
      "grad_norm": 0.5809499621391296,
      "learning_rate": 4.889140645209548e-05,
      "loss": 1.3,
      "step": 21350
    },
    {
      "epoch": 0.06669637876063168,
      "grad_norm": 0.5701432228088379,
      "learning_rate": 4.8888809241084554e-05,
      "loss": 1.2709,
      "step": 21400
    },
    {
      "epoch": 0.06685221142128736,
      "grad_norm": 0.758977472782135,
      "learning_rate": 4.8886263974293846e-05,
      "loss": 1.3257,
      "step": 21450
    },
    {
      "epoch": 0.06700804408194305,
      "grad_norm": 0.6445344090461731,
      "learning_rate": 4.888366676328292e-05,
      "loss": 1.2743,
      "step": 21500
    },
    {
      "epoch": 0.06716387674259873,
      "grad_norm": 0.555061936378479,
      "learning_rate": 4.888106955227199e-05,
      "loss": 1.3595,
      "step": 21550
    },
    {
      "epoch": 0.06731970940325441,
      "grad_norm": 0.5705407857894897,
      "learning_rate": 4.887847234126106e-05,
      "loss": 1.3765,
      "step": 21600
    },
    {
      "epoch": 0.06747554206391009,
      "grad_norm": 0.6184156537055969,
      "learning_rate": 4.8875875130250136e-05,
      "loss": 1.286,
      "step": 21650
    },
    {
      "epoch": 0.06763137472456578,
      "grad_norm": 0.6059477925300598,
      "learning_rate": 4.887327791923921e-05,
      "loss": 1.3143,
      "step": 21700
    },
    {
      "epoch": 0.06778720738522145,
      "grad_norm": 0.5727159976959229,
      "learning_rate": 4.887068070822828e-05,
      "loss": 1.3399,
      "step": 21750
    },
    {
      "epoch": 0.06794304004587713,
      "grad_norm": 0.5234657526016235,
      "learning_rate": 4.8868083497217346e-05,
      "loss": 1.3489,
      "step": 21800
    },
    {
      "epoch": 0.06809887270653282,
      "grad_norm": 0.6317455768585205,
      "learning_rate": 4.8865486286206426e-05,
      "loss": 1.3089,
      "step": 21850
    },
    {
      "epoch": 0.0682547053671885,
      "grad_norm": 0.5059946179389954,
      "learning_rate": 4.88628890751955e-05,
      "loss": 1.3558,
      "step": 21900
    },
    {
      "epoch": 0.06841053802784418,
      "grad_norm": 0.6959717273712158,
      "learning_rate": 4.8860291864184564e-05,
      "loss": 1.3109,
      "step": 21950
    },
    {
      "epoch": 0.06856637068849986,
      "grad_norm": 0.49464496970176697,
      "learning_rate": 4.8857694653173636e-05,
      "loss": 1.3246,
      "step": 22000
    },
    {
      "epoch": 0.06872220334915555,
      "grad_norm": 0.625086784362793,
      "learning_rate": 4.885509744216271e-05,
      "loss": 1.3414,
      "step": 22050
    },
    {
      "epoch": 0.06887803600981122,
      "grad_norm": 0.47617632150650024,
      "learning_rate": 4.885250023115178e-05,
      "loss": 1.2982,
      "step": 22100
    },
    {
      "epoch": 0.0690338686704669,
      "grad_norm": 0.6678531169891357,
      "learning_rate": 4.8849903020140854e-05,
      "loss": 1.3273,
      "step": 22150
    },
    {
      "epoch": 0.0691897013311226,
      "grad_norm": 0.7217774987220764,
      "learning_rate": 4.8847305809129926e-05,
      "loss": 1.3316,
      "step": 22200
    },
    {
      "epoch": 0.06934553399177827,
      "grad_norm": 0.6119312644004822,
      "learning_rate": 4.8844708598119e-05,
      "loss": 1.2744,
      "step": 22250
    },
    {
      "epoch": 0.06950136665243395,
      "grad_norm": 0.6433269381523132,
      "learning_rate": 4.884211138710807e-05,
      "loss": 1.3378,
      "step": 22300
    },
    {
      "epoch": 0.06965719931308963,
      "grad_norm": 0.490968257188797,
      "learning_rate": 4.883951417609714e-05,
      "loss": 1.2953,
      "step": 22350
    },
    {
      "epoch": 0.06981303197374532,
      "grad_norm": 0.6703467965126038,
      "learning_rate": 4.8836916965086216e-05,
      "loss": 1.3439,
      "step": 22400
    },
    {
      "epoch": 0.069968864634401,
      "grad_norm": 0.56235271692276,
      "learning_rate": 4.883431975407529e-05,
      "loss": 1.2425,
      "step": 22450
    },
    {
      "epoch": 0.07012469729505667,
      "grad_norm": 0.609748363494873,
      "learning_rate": 4.8831722543064355e-05,
      "loss": 1.3285,
      "step": 22500
    },
    {
      "epoch": 0.07028052995571236,
      "grad_norm": 0.6493157148361206,
      "learning_rate": 4.8829125332053434e-05,
      "loss": 1.349,
      "step": 22550
    },
    {
      "epoch": 0.07043636261636804,
      "grad_norm": 0.604738712310791,
      "learning_rate": 4.88265281210425e-05,
      "loss": 1.3572,
      "step": 22600
    },
    {
      "epoch": 0.07059219527702372,
      "grad_norm": 0.8235921859741211,
      "learning_rate": 4.882393091003157e-05,
      "loss": 1.2884,
      "step": 22650
    },
    {
      "epoch": 0.0707480279376794,
      "grad_norm": 0.5615694522857666,
      "learning_rate": 4.8821333699020645e-05,
      "loss": 1.2759,
      "step": 22700
    },
    {
      "epoch": 0.07090386059833509,
      "grad_norm": 0.48990097641944885,
      "learning_rate": 4.881873648800972e-05,
      "loss": 1.3041,
      "step": 22750
    },
    {
      "epoch": 0.07105969325899077,
      "grad_norm": 0.5821700692176819,
      "learning_rate": 4.881613927699879e-05,
      "loss": 1.3166,
      "step": 22800
    },
    {
      "epoch": 0.07121552591964644,
      "grad_norm": 0.5834290981292725,
      "learning_rate": 4.881354206598786e-05,
      "loss": 1.3873,
      "step": 22850
    },
    {
      "epoch": 0.07137135858030212,
      "grad_norm": 0.6749212145805359,
      "learning_rate": 4.8810944854976935e-05,
      "loss": 1.3138,
      "step": 22900
    },
    {
      "epoch": 0.07152719124095781,
      "grad_norm": 0.6298218965530396,
      "learning_rate": 4.880834764396601e-05,
      "loss": 1.3097,
      "step": 22950
    },
    {
      "epoch": 0.07168302390161349,
      "grad_norm": 0.6802829504013062,
      "learning_rate": 4.880575043295508e-05,
      "loss": 1.3189,
      "step": 23000
    },
    {
      "epoch": 0.07183885656226917,
      "grad_norm": 0.5389738082885742,
      "learning_rate": 4.8803153221944145e-05,
      "loss": 1.3235,
      "step": 23050
    },
    {
      "epoch": 0.07199468922292486,
      "grad_norm": 0.5327343344688416,
      "learning_rate": 4.8800556010933225e-05,
      "loss": 1.3033,
      "step": 23100
    },
    {
      "epoch": 0.07215052188358054,
      "grad_norm": 0.5894644260406494,
      "learning_rate": 4.87979587999223e-05,
      "loss": 1.3107,
      "step": 23150
    },
    {
      "epoch": 0.07230635454423621,
      "grad_norm": 0.44949355721473694,
      "learning_rate": 4.879536158891136e-05,
      "loss": 1.3812,
      "step": 23200
    },
    {
      "epoch": 0.07246218720489189,
      "grad_norm": 0.5796131491661072,
      "learning_rate": 4.8792764377900435e-05,
      "loss": 1.3049,
      "step": 23250
    },
    {
      "epoch": 0.07261801986554758,
      "grad_norm": 0.6458222270011902,
      "learning_rate": 4.879016716688951e-05,
      "loss": 1.2745,
      "step": 23300
    },
    {
      "epoch": 0.07277385252620326,
      "grad_norm": 0.7238809466362,
      "learning_rate": 4.878756995587858e-05,
      "loss": 1.2985,
      "step": 23350
    },
    {
      "epoch": 0.07292968518685894,
      "grad_norm": 0.6198951005935669,
      "learning_rate": 4.878497274486765e-05,
      "loss": 1.2667,
      "step": 23400
    },
    {
      "epoch": 0.07308551784751463,
      "grad_norm": 0.5496981739997864,
      "learning_rate": 4.8782375533856725e-05,
      "loss": 1.2791,
      "step": 23450
    },
    {
      "epoch": 0.07324135050817031,
      "grad_norm": 0.6416502594947815,
      "learning_rate": 4.87797783228458e-05,
      "loss": 1.3842,
      "step": 23500
    },
    {
      "epoch": 0.07339718316882599,
      "grad_norm": 0.5842108130455017,
      "learning_rate": 4.877718111183487e-05,
      "loss": 1.3241,
      "step": 23550
    },
    {
      "epoch": 0.07355301582948166,
      "grad_norm": 0.6848686337471008,
      "learning_rate": 4.8774583900823936e-05,
      "loss": 1.3133,
      "step": 23600
    },
    {
      "epoch": 0.07370884849013735,
      "grad_norm": 1.0583744049072266,
      "learning_rate": 4.8771986689813015e-05,
      "loss": 1.3289,
      "step": 23650
    },
    {
      "epoch": 0.07386468115079303,
      "grad_norm": 0.7801441550254822,
      "learning_rate": 4.876938947880209e-05,
      "loss": 1.2918,
      "step": 23700
    },
    {
      "epoch": 0.07402051381144871,
      "grad_norm": 0.45920199155807495,
      "learning_rate": 4.8766792267791154e-05,
      "loss": 1.3642,
      "step": 23750
    },
    {
      "epoch": 0.0741763464721044,
      "grad_norm": 0.7062236666679382,
      "learning_rate": 4.876419505678023e-05,
      "loss": 1.3213,
      "step": 23800
    },
    {
      "epoch": 0.07433217913276008,
      "grad_norm": 0.7822418212890625,
      "learning_rate": 4.8761597845769306e-05,
      "loss": 1.327,
      "step": 23850
    },
    {
      "epoch": 0.07448801179341576,
      "grad_norm": 0.667065441608429,
      "learning_rate": 4.875900063475837e-05,
      "loss": 1.3143,
      "step": 23900
    },
    {
      "epoch": 0.07464384445407143,
      "grad_norm": 0.631476104259491,
      "learning_rate": 4.8756403423747444e-05,
      "loss": 1.2901,
      "step": 23950
    },
    {
      "epoch": 0.07479967711472713,
      "grad_norm": 0.5849165320396423,
      "learning_rate": 4.8753806212736516e-05,
      "loss": 1.3239,
      "step": 24000
    },
    {
      "epoch": 0.0749555097753828,
      "grad_norm": 0.5540856122970581,
      "learning_rate": 4.875120900172559e-05,
      "loss": 1.288,
      "step": 24050
    },
    {
      "epoch": 0.07511134243603848,
      "grad_norm": 0.6739856004714966,
      "learning_rate": 4.874861179071466e-05,
      "loss": 1.302,
      "step": 24100
    },
    {
      "epoch": 0.07526717509669417,
      "grad_norm": 0.4955354630947113,
      "learning_rate": 4.8746014579703734e-05,
      "loss": 1.2983,
      "step": 24150
    },
    {
      "epoch": 0.07542300775734985,
      "grad_norm": 0.6656898856163025,
      "learning_rate": 4.8743417368692806e-05,
      "loss": 1.3576,
      "step": 24200
    },
    {
      "epoch": 0.07557884041800553,
      "grad_norm": 0.5592969655990601,
      "learning_rate": 4.874082015768188e-05,
      "loss": 1.3123,
      "step": 24250
    },
    {
      "epoch": 0.0757346730786612,
      "grad_norm": 0.5264102816581726,
      "learning_rate": 4.8738222946670944e-05,
      "loss": 1.3005,
      "step": 24300
    },
    {
      "epoch": 0.0758905057393169,
      "grad_norm": 0.7291808724403381,
      "learning_rate": 4.8735625735660024e-05,
      "loss": 1.3282,
      "step": 24350
    },
    {
      "epoch": 0.07604633839997257,
      "grad_norm": 0.45666784048080444,
      "learning_rate": 4.8733028524649096e-05,
      "loss": 1.342,
      "step": 24400
    },
    {
      "epoch": 0.07620217106062825,
      "grad_norm": 0.6577968597412109,
      "learning_rate": 4.873043131363816e-05,
      "loss": 1.3268,
      "step": 24450
    },
    {
      "epoch": 0.07635800372128394,
      "grad_norm": 0.5946276783943176,
      "learning_rate": 4.8727834102627234e-05,
      "loss": 1.345,
      "step": 24500
    },
    {
      "epoch": 0.07651383638193962,
      "grad_norm": 0.6477664709091187,
      "learning_rate": 4.8725236891616314e-05,
      "loss": 1.3052,
      "step": 24550
    },
    {
      "epoch": 0.0766696690425953,
      "grad_norm": 0.668798565864563,
      "learning_rate": 4.872263968060538e-05,
      "loss": 1.3234,
      "step": 24600
    },
    {
      "epoch": 0.07682550170325098,
      "grad_norm": 0.5122951865196228,
      "learning_rate": 4.872004246959445e-05,
      "loss": 1.3431,
      "step": 24650
    },
    {
      "epoch": 0.07698133436390667,
      "grad_norm": 0.5365049242973328,
      "learning_rate": 4.8717445258583525e-05,
      "loss": 1.3337,
      "step": 24700
    },
    {
      "epoch": 0.07713716702456234,
      "grad_norm": 0.6942126750946045,
      "learning_rate": 4.87148480475726e-05,
      "loss": 1.3485,
      "step": 24750
    },
    {
      "epoch": 0.07729299968521802,
      "grad_norm": 0.5132336616516113,
      "learning_rate": 4.871225083656167e-05,
      "loss": 1.2878,
      "step": 24800
    },
    {
      "epoch": 0.07744883234587371,
      "grad_norm": 0.6851671934127808,
      "learning_rate": 4.8709653625550735e-05,
      "loss": 1.3406,
      "step": 24850
    },
    {
      "epoch": 0.07760466500652939,
      "grad_norm": 0.6723471283912659,
      "learning_rate": 4.8707056414539815e-05,
      "loss": 1.3033,
      "step": 24900
    },
    {
      "epoch": 0.07776049766718507,
      "grad_norm": 0.6415911316871643,
      "learning_rate": 4.870445920352889e-05,
      "loss": 1.3112,
      "step": 24950
    },
    {
      "epoch": 0.07791633032784075,
      "grad_norm": 0.6979864239692688,
      "learning_rate": 4.870186199251795e-05,
      "loss": 1.3454,
      "step": 25000
    },
    {
      "epoch": 0.07807216298849644,
      "grad_norm": 0.6185047626495361,
      "learning_rate": 4.869926478150703e-05,
      "loss": 1.2904,
      "step": 25050
    },
    {
      "epoch": 0.07822799564915212,
      "grad_norm": 0.6900172829627991,
      "learning_rate": 4.8696667570496105e-05,
      "loss": 1.2874,
      "step": 25100
    },
    {
      "epoch": 0.0783838283098078,
      "grad_norm": 0.673552930355072,
      "learning_rate": 4.869407035948517e-05,
      "loss": 1.2543,
      "step": 25150
    },
    {
      "epoch": 0.07853966097046347,
      "grad_norm": 0.5815678238868713,
      "learning_rate": 4.869147314847424e-05,
      "loss": 1.3205,
      "step": 25200
    },
    {
      "epoch": 0.07869549363111916,
      "grad_norm": 0.5036421418190002,
      "learning_rate": 4.8688875937463315e-05,
      "loss": 1.2586,
      "step": 25250
    },
    {
      "epoch": 0.07885132629177484,
      "grad_norm": 0.5760003924369812,
      "learning_rate": 4.868627872645239e-05,
      "loss": 1.3012,
      "step": 25300
    },
    {
      "epoch": 0.07900715895243052,
      "grad_norm": 0.6121105551719666,
      "learning_rate": 4.868368151544146e-05,
      "loss": 1.3072,
      "step": 25350
    },
    {
      "epoch": 0.07916299161308621,
      "grad_norm": 0.5517157316207886,
      "learning_rate": 4.868108430443053e-05,
      "loss": 1.2943,
      "step": 25400
    },
    {
      "epoch": 0.07931882427374189,
      "grad_norm": 0.5097983479499817,
      "learning_rate": 4.8678487093419605e-05,
      "loss": 1.2294,
      "step": 25450
    },
    {
      "epoch": 0.07947465693439756,
      "grad_norm": 0.543792724609375,
      "learning_rate": 4.867588988240868e-05,
      "loss": 1.362,
      "step": 25500
    },
    {
      "epoch": 0.07963048959505324,
      "grad_norm": 0.5806373357772827,
      "learning_rate": 4.8673292671397743e-05,
      "loss": 1.3715,
      "step": 25550
    },
    {
      "epoch": 0.07978632225570893,
      "grad_norm": 0.5713666081428528,
      "learning_rate": 4.867069546038682e-05,
      "loss": 1.3047,
      "step": 25600
    },
    {
      "epoch": 0.07994215491636461,
      "grad_norm": 0.6790603399276733,
      "learning_rate": 4.8668098249375895e-05,
      "loss": 1.3286,
      "step": 25650
    },
    {
      "epoch": 0.08009798757702029,
      "grad_norm": 0.6284769773483276,
      "learning_rate": 4.866550103836496e-05,
      "loss": 1.3309,
      "step": 25700
    },
    {
      "epoch": 0.08025382023767598,
      "grad_norm": 0.543469250202179,
      "learning_rate": 4.8662903827354034e-05,
      "loss": 1.3061,
      "step": 25750
    },
    {
      "epoch": 0.08040965289833166,
      "grad_norm": 0.6739099621772766,
      "learning_rate": 4.866035856056333e-05,
      "loss": 1.283,
      "step": 25800
    },
    {
      "epoch": 0.08056548555898733,
      "grad_norm": 0.675101101398468,
      "learning_rate": 4.86577613495524e-05,
      "loss": 1.3333,
      "step": 25850
    },
    {
      "epoch": 0.08072131821964301,
      "grad_norm": 0.7747710347175598,
      "learning_rate": 4.865516413854147e-05,
      "loss": 1.314,
      "step": 25900
    },
    {
      "epoch": 0.0808771508802987,
      "grad_norm": 0.7223939895629883,
      "learning_rate": 4.865256692753054e-05,
      "loss": 1.3309,
      "step": 25950
    },
    {
      "epoch": 0.08103298354095438,
      "grad_norm": 0.59212327003479,
      "learning_rate": 4.8649969716519616e-05,
      "loss": 1.3182,
      "step": 26000
    },
    {
      "epoch": 0.08118881620161006,
      "grad_norm": 0.5804698467254639,
      "learning_rate": 4.864737250550869e-05,
      "loss": 1.3078,
      "step": 26050
    },
    {
      "epoch": 0.08134464886226575,
      "grad_norm": 0.5777401328086853,
      "learning_rate": 4.864477529449776e-05,
      "loss": 1.2909,
      "step": 26100
    },
    {
      "epoch": 0.08150048152292143,
      "grad_norm": 0.5187009572982788,
      "learning_rate": 4.864217808348683e-05,
      "loss": 1.3015,
      "step": 26150
    },
    {
      "epoch": 0.0816563141835771,
      "grad_norm": 0.5848783254623413,
      "learning_rate": 4.8639580872475906e-05,
      "loss": 1.2547,
      "step": 26200
    },
    {
      "epoch": 0.08181214684423278,
      "grad_norm": 0.5879573225975037,
      "learning_rate": 4.863698366146497e-05,
      "loss": 1.3055,
      "step": 26250
    },
    {
      "epoch": 0.08196797950488847,
      "grad_norm": 0.6756590008735657,
      "learning_rate": 4.8634386450454044e-05,
      "loss": 1.3036,
      "step": 26300
    },
    {
      "epoch": 0.08212381216554415,
      "grad_norm": 0.5728438496589661,
      "learning_rate": 4.863178923944312e-05,
      "loss": 1.2937,
      "step": 26350
    },
    {
      "epoch": 0.08227964482619983,
      "grad_norm": 1.0252790451049805,
      "learning_rate": 4.862919202843219e-05,
      "loss": 1.3057,
      "step": 26400
    },
    {
      "epoch": 0.08243547748685552,
      "grad_norm": 0.6106794476509094,
      "learning_rate": 4.862659481742126e-05,
      "loss": 1.2939,
      "step": 26450
    },
    {
      "epoch": 0.0825913101475112,
      "grad_norm": 0.6229058504104614,
      "learning_rate": 4.8623997606410334e-05,
      "loss": 1.371,
      "step": 26500
    },
    {
      "epoch": 0.08274714280816688,
      "grad_norm": 0.60804283618927,
      "learning_rate": 4.8621400395399406e-05,
      "loss": 1.3505,
      "step": 26550
    },
    {
      "epoch": 0.08290297546882255,
      "grad_norm": 0.4263008236885071,
      "learning_rate": 4.861880318438848e-05,
      "loss": 1.2995,
      "step": 26600
    },
    {
      "epoch": 0.08305880812947825,
      "grad_norm": 0.589276909828186,
      "learning_rate": 4.861620597337755e-05,
      "loss": 1.2985,
      "step": 26650
    },
    {
      "epoch": 0.08321464079013392,
      "grad_norm": 0.6521909236907959,
      "learning_rate": 4.8613608762366624e-05,
      "loss": 1.2953,
      "step": 26700
    },
    {
      "epoch": 0.0833704734507896,
      "grad_norm": 0.5743646025657654,
      "learning_rate": 4.8611011551355696e-05,
      "loss": 1.3062,
      "step": 26750
    },
    {
      "epoch": 0.08352630611144529,
      "grad_norm": 0.44747593998908997,
      "learning_rate": 4.860841434034477e-05,
      "loss": 1.3363,
      "step": 26800
    },
    {
      "epoch": 0.08368213877210097,
      "grad_norm": 0.5838092565536499,
      "learning_rate": 4.8605817129333835e-05,
      "loss": 1.2979,
      "step": 26850
    },
    {
      "epoch": 0.08383797143275665,
      "grad_norm": 0.6615011096000671,
      "learning_rate": 4.8603271862543134e-05,
      "loss": 1.2849,
      "step": 26900
    },
    {
      "epoch": 0.08399380409341232,
      "grad_norm": 0.6520996689796448,
      "learning_rate": 4.86006746515322e-05,
      "loss": 1.3914,
      "step": 26950
    },
    {
      "epoch": 0.08414963675406802,
      "grad_norm": 0.7245404720306396,
      "learning_rate": 4.859807744052127e-05,
      "loss": 1.2696,
      "step": 27000
    },
    {
      "epoch": 0.0843054694147237,
      "grad_norm": 0.6013381481170654,
      "learning_rate": 4.8595480229510344e-05,
      "loss": 1.2848,
      "step": 27050
    },
    {
      "epoch": 0.08446130207537937,
      "grad_norm": 0.5838293433189392,
      "learning_rate": 4.859288301849942e-05,
      "loss": 1.3175,
      "step": 27100
    },
    {
      "epoch": 0.08461713473603506,
      "grad_norm": 0.6606952548027039,
      "learning_rate": 4.859028580748849e-05,
      "loss": 1.331,
      "step": 27150
    },
    {
      "epoch": 0.08477296739669074,
      "grad_norm": 0.5730252265930176,
      "learning_rate": 4.858768859647756e-05,
      "loss": 1.2974,
      "step": 27200
    },
    {
      "epoch": 0.08492880005734642,
      "grad_norm": 0.7196479439735413,
      "learning_rate": 4.858509138546663e-05,
      "loss": 1.3651,
      "step": 27250
    },
    {
      "epoch": 0.0850846327180021,
      "grad_norm": 0.6210955381393433,
      "learning_rate": 4.858249417445571e-05,
      "loss": 1.3465,
      "step": 27300
    },
    {
      "epoch": 0.08524046537865779,
      "grad_norm": 0.6250020265579224,
      "learning_rate": 4.857989696344478e-05,
      "loss": 1.3093,
      "step": 27350
    },
    {
      "epoch": 0.08539629803931346,
      "grad_norm": 0.5691606402397156,
      "learning_rate": 4.8577299752433845e-05,
      "loss": 1.319,
      "step": 27400
    },
    {
      "epoch": 0.08555213069996914,
      "grad_norm": 0.5642447471618652,
      "learning_rate": 4.8574702541422924e-05,
      "loss": 1.2774,
      "step": 27450
    },
    {
      "epoch": 0.08570796336062482,
      "grad_norm": 0.4889324903488159,
      "learning_rate": 4.857210533041199e-05,
      "loss": 1.3399,
      "step": 27500
    },
    {
      "epoch": 0.08586379602128051,
      "grad_norm": 0.5687410235404968,
      "learning_rate": 4.856950811940106e-05,
      "loss": 1.3352,
      "step": 27550
    },
    {
      "epoch": 0.08601962868193619,
      "grad_norm": 0.6841719746589661,
      "learning_rate": 4.8566910908390135e-05,
      "loss": 1.3415,
      "step": 27600
    },
    {
      "epoch": 0.08617546134259187,
      "grad_norm": 0.5788951516151428,
      "learning_rate": 4.856431369737921e-05,
      "loss": 1.3495,
      "step": 27650
    },
    {
      "epoch": 0.08633129400324756,
      "grad_norm": 0.6272716522216797,
      "learning_rate": 4.856171648636828e-05,
      "loss": 1.3136,
      "step": 27700
    },
    {
      "epoch": 0.08648712666390324,
      "grad_norm": 0.6443812847137451,
      "learning_rate": 4.855911927535735e-05,
      "loss": 1.2993,
      "step": 27750
    },
    {
      "epoch": 0.08664295932455891,
      "grad_norm": 0.5322339534759521,
      "learning_rate": 4.8556522064346425e-05,
      "loss": 1.4067,
      "step": 27800
    },
    {
      "epoch": 0.08679879198521459,
      "grad_norm": 0.5557043552398682,
      "learning_rate": 4.85539248533355e-05,
      "loss": 1.3156,
      "step": 27850
    },
    {
      "epoch": 0.08695462464587028,
      "grad_norm": 0.5964245796203613,
      "learning_rate": 4.855132764232457e-05,
      "loss": 1.3394,
      "step": 27900
    },
    {
      "epoch": 0.08711045730652596,
      "grad_norm": 0.47169971466064453,
      "learning_rate": 4.8548730431313636e-05,
      "loss": 1.2855,
      "step": 27950
    },
    {
      "epoch": 0.08726628996718164,
      "grad_norm": 0.5035881400108337,
      "learning_rate": 4.8546133220302715e-05,
      "loss": 1.2851,
      "step": 28000
    },
    {
      "epoch": 0.08742212262783733,
      "grad_norm": 0.5847326517105103,
      "learning_rate": 4.854353600929179e-05,
      "loss": 1.305,
      "step": 28050
    },
    {
      "epoch": 0.087577955288493,
      "grad_norm": 0.58565753698349,
      "learning_rate": 4.854093879828085e-05,
      "loss": 1.3296,
      "step": 28100
    },
    {
      "epoch": 0.08773378794914868,
      "grad_norm": 0.7690196633338928,
      "learning_rate": 4.853834158726993e-05,
      "loss": 1.3273,
      "step": 28150
    },
    {
      "epoch": 0.08788962060980436,
      "grad_norm": 0.6867075562477112,
      "learning_rate": 4.8535744376259e-05,
      "loss": 1.3355,
      "step": 28200
    },
    {
      "epoch": 0.08804545327046005,
      "grad_norm": 0.6657630801200867,
      "learning_rate": 4.853314716524807e-05,
      "loss": 1.3064,
      "step": 28250
    },
    {
      "epoch": 0.08820128593111573,
      "grad_norm": 0.639108419418335,
      "learning_rate": 4.853054995423714e-05,
      "loss": 1.2596,
      "step": 28300
    },
    {
      "epoch": 0.08835711859177141,
      "grad_norm": 0.7092931270599365,
      "learning_rate": 4.8527952743226216e-05,
      "loss": 1.3412,
      "step": 28350
    },
    {
      "epoch": 0.0885129512524271,
      "grad_norm": 0.7189709544181824,
      "learning_rate": 4.852535553221529e-05,
      "loss": 1.3589,
      "step": 28400
    },
    {
      "epoch": 0.08866878391308278,
      "grad_norm": 0.6375130414962769,
      "learning_rate": 4.852275832120436e-05,
      "loss": 1.2475,
      "step": 28450
    },
    {
      "epoch": 0.08882461657373845,
      "grad_norm": 0.5045791864395142,
      "learning_rate": 4.8520161110193427e-05,
      "loss": 1.3512,
      "step": 28500
    },
    {
      "epoch": 0.08898044923439413,
      "grad_norm": 0.5924463868141174,
      "learning_rate": 4.8517563899182506e-05,
      "loss": 1.3154,
      "step": 28550
    },
    {
      "epoch": 0.08913628189504982,
      "grad_norm": 0.5922365784645081,
      "learning_rate": 4.851496668817158e-05,
      "loss": 1.369,
      "step": 28600
    },
    {
      "epoch": 0.0892921145557055,
      "grad_norm": 0.5737619400024414,
      "learning_rate": 4.8512369477160644e-05,
      "loss": 1.3245,
      "step": 28650
    },
    {
      "epoch": 0.08944794721636118,
      "grad_norm": 0.6110926866531372,
      "learning_rate": 4.850977226614972e-05,
      "loss": 1.2792,
      "step": 28700
    },
    {
      "epoch": 0.08960377987701687,
      "grad_norm": 0.7110636830329895,
      "learning_rate": 4.8507175055138796e-05,
      "loss": 1.3757,
      "step": 28750
    },
    {
      "epoch": 0.08975961253767255,
      "grad_norm": 0.5630603432655334,
      "learning_rate": 4.850457784412786e-05,
      "loss": 1.253,
      "step": 28800
    },
    {
      "epoch": 0.08991544519832823,
      "grad_norm": 0.48793330788612366,
      "learning_rate": 4.8501980633116934e-05,
      "loss": 1.2487,
      "step": 28850
    },
    {
      "epoch": 0.0900712778589839,
      "grad_norm": 0.6111130118370056,
      "learning_rate": 4.8499383422106007e-05,
      "loss": 1.2961,
      "step": 28900
    },
    {
      "epoch": 0.0902271105196396,
      "grad_norm": 0.6781116127967834,
      "learning_rate": 4.849678621109508e-05,
      "loss": 1.2819,
      "step": 28950
    },
    {
      "epoch": 0.09038294318029527,
      "grad_norm": 0.5462363362312317,
      "learning_rate": 4.849418900008415e-05,
      "loss": 1.2619,
      "step": 29000
    },
    {
      "epoch": 0.09053877584095095,
      "grad_norm": 0.6337351202964783,
      "learning_rate": 4.8491591789073224e-05,
      "loss": 1.3435,
      "step": 29050
    },
    {
      "epoch": 0.09069460850160664,
      "grad_norm": 0.5700948238372803,
      "learning_rate": 4.8488994578062297e-05,
      "loss": 1.3488,
      "step": 29100
    },
    {
      "epoch": 0.09085044116226232,
      "grad_norm": 0.6760162711143494,
      "learning_rate": 4.848639736705137e-05,
      "loss": 1.3072,
      "step": 29150
    },
    {
      "epoch": 0.091006273822918,
      "grad_norm": 0.6979495882987976,
      "learning_rate": 4.8483800156040435e-05,
      "loss": 1.3451,
      "step": 29200
    },
    {
      "epoch": 0.09116210648357367,
      "grad_norm": 0.5887072682380676,
      "learning_rate": 4.8481202945029514e-05,
      "loss": 1.3197,
      "step": 29250
    },
    {
      "epoch": 0.09131793914422937,
      "grad_norm": 0.5707601308822632,
      "learning_rate": 4.8478605734018587e-05,
      "loss": 1.2965,
      "step": 29300
    },
    {
      "epoch": 0.09147377180488504,
      "grad_norm": 0.6921617388725281,
      "learning_rate": 4.847600852300765e-05,
      "loss": 1.3195,
      "step": 29350
    },
    {
      "epoch": 0.09162960446554072,
      "grad_norm": 0.5937468409538269,
      "learning_rate": 4.847341131199673e-05,
      "loss": 1.274,
      "step": 29400
    },
    {
      "epoch": 0.09178543712619641,
      "grad_norm": 0.7560850381851196,
      "learning_rate": 4.8470814100985804e-05,
      "loss": 1.285,
      "step": 29450
    },
    {
      "epoch": 0.09194126978685209,
      "grad_norm": 0.6644518375396729,
      "learning_rate": 4.846821688997487e-05,
      "loss": 1.3182,
      "step": 29500
    },
    {
      "epoch": 0.09209710244750777,
      "grad_norm": 0.5182138085365295,
      "learning_rate": 4.846561967896394e-05,
      "loss": 1.328,
      "step": 29550
    },
    {
      "epoch": 0.09225293510816344,
      "grad_norm": 0.580568790435791,
      "learning_rate": 4.8463022467953015e-05,
      "loss": 1.3349,
      "step": 29600
    },
    {
      "epoch": 0.09240876776881914,
      "grad_norm": 0.7215962409973145,
      "learning_rate": 4.846042525694209e-05,
      "loss": 1.3256,
      "step": 29650
    },
    {
      "epoch": 0.09256460042947481,
      "grad_norm": 0.5717561841011047,
      "learning_rate": 4.845782804593116e-05,
      "loss": 1.3353,
      "step": 29700
    },
    {
      "epoch": 0.09272043309013049,
      "grad_norm": 0.7208356857299805,
      "learning_rate": 4.8455230834920226e-05,
      "loss": 1.3124,
      "step": 29750
    },
    {
      "epoch": 0.09287626575078617,
      "grad_norm": 0.5762004256248474,
      "learning_rate": 4.8452633623909305e-05,
      "loss": 1.2875,
      "step": 29800
    },
    {
      "epoch": 0.09303209841144186,
      "grad_norm": 0.6728041768074036,
      "learning_rate": 4.845003641289838e-05,
      "loss": 1.3319,
      "step": 29850
    },
    {
      "epoch": 0.09318793107209754,
      "grad_norm": 0.5460833311080933,
      "learning_rate": 4.844743920188744e-05,
      "loss": 1.2729,
      "step": 29900
    },
    {
      "epoch": 0.09334376373275322,
      "grad_norm": 0.7213008403778076,
      "learning_rate": 4.844484199087652e-05,
      "loss": 1.3078,
      "step": 29950
    },
    {
      "epoch": 0.0934995963934089,
      "grad_norm": 0.6473243832588196,
      "learning_rate": 4.8442244779865595e-05,
      "loss": 1.314,
      "step": 30000
    },
    {
      "epoch": 0.09365542905406458,
      "grad_norm": 0.5441765189170837,
      "learning_rate": 4.843964756885466e-05,
      "loss": 1.3227,
      "step": 30050
    },
    {
      "epoch": 0.09381126171472026,
      "grad_norm": 0.5184540152549744,
      "learning_rate": 4.843705035784373e-05,
      "loss": 1.3302,
      "step": 30100
    },
    {
      "epoch": 0.09396709437537594,
      "grad_norm": 0.7708337903022766,
      "learning_rate": 4.8434453146832806e-05,
      "loss": 1.2945,
      "step": 30150
    },
    {
      "epoch": 0.09412292703603163,
      "grad_norm": 0.6713712215423584,
      "learning_rate": 4.843185593582188e-05,
      "loss": 1.2931,
      "step": 30200
    },
    {
      "epoch": 0.09427875969668731,
      "grad_norm": 0.6589187383651733,
      "learning_rate": 4.842925872481095e-05,
      "loss": 1.3589,
      "step": 30250
    },
    {
      "epoch": 0.09443459235734299,
      "grad_norm": 0.7123727798461914,
      "learning_rate": 4.842666151380002e-05,
      "loss": 1.3498,
      "step": 30300
    },
    {
      "epoch": 0.09459042501799868,
      "grad_norm": 0.6041285991668701,
      "learning_rate": 4.8424064302789096e-05,
      "loss": 1.355,
      "step": 30350
    },
    {
      "epoch": 0.09474625767865436,
      "grad_norm": 0.6531980633735657,
      "learning_rate": 4.842146709177817e-05,
      "loss": 1.3322,
      "step": 30400
    },
    {
      "epoch": 0.09490209033931003,
      "grad_norm": 0.6043731570243835,
      "learning_rate": 4.8418869880767234e-05,
      "loss": 1.3165,
      "step": 30450
    },
    {
      "epoch": 0.09505792299996571,
      "grad_norm": 0.609575092792511,
      "learning_rate": 4.841627266975631e-05,
      "loss": 1.2803,
      "step": 30500
    },
    {
      "epoch": 0.0952137556606214,
      "grad_norm": 0.5066163539886475,
      "learning_rate": 4.8413675458745386e-05,
      "loss": 1.2885,
      "step": 30550
    },
    {
      "epoch": 0.09536958832127708,
      "grad_norm": 0.545536994934082,
      "learning_rate": 4.841107824773445e-05,
      "loss": 1.3191,
      "step": 30600
    },
    {
      "epoch": 0.09552542098193276,
      "grad_norm": 0.6939616203308105,
      "learning_rate": 4.840848103672353e-05,
      "loss": 1.2908,
      "step": 30650
    },
    {
      "epoch": 0.09568125364258845,
      "grad_norm": 0.4374024569988251,
      "learning_rate": 4.84058838257126e-05,
      "loss": 1.306,
      "step": 30700
    },
    {
      "epoch": 0.09583708630324413,
      "grad_norm": 0.527031421661377,
      "learning_rate": 4.840328661470167e-05,
      "loss": 1.3422,
      "step": 30750
    },
    {
      "epoch": 0.0959929189638998,
      "grad_norm": 0.5746809840202332,
      "learning_rate": 4.840068940369074e-05,
      "loss": 1.3062,
      "step": 30800
    },
    {
      "epoch": 0.09614875162455548,
      "grad_norm": 0.5726195573806763,
      "learning_rate": 4.8398092192679814e-05,
      "loss": 1.3166,
      "step": 30850
    },
    {
      "epoch": 0.09630458428521117,
      "grad_norm": 0.5534207224845886,
      "learning_rate": 4.8395494981668886e-05,
      "loss": 1.3172,
      "step": 30900
    },
    {
      "epoch": 0.09646041694586685,
      "grad_norm": 0.5792598128318787,
      "learning_rate": 4.839289777065796e-05,
      "loss": 1.3117,
      "step": 30950
    },
    {
      "epoch": 0.09661624960652253,
      "grad_norm": 0.620458722114563,
      "learning_rate": 4.839030055964703e-05,
      "loss": 1.2681,
      "step": 31000
    },
    {
      "epoch": 0.09677208226717822,
      "grad_norm": 0.6190546751022339,
      "learning_rate": 4.8387703348636104e-05,
      "loss": 1.3065,
      "step": 31050
    },
    {
      "epoch": 0.0969279149278339,
      "grad_norm": 0.6716495752334595,
      "learning_rate": 4.8385106137625176e-05,
      "loss": 1.2888,
      "step": 31100
    },
    {
      "epoch": 0.09708374758848957,
      "grad_norm": 0.660619854927063,
      "learning_rate": 4.838250892661424e-05,
      "loss": 1.3128,
      "step": 31150
    },
    {
      "epoch": 0.09723958024914525,
      "grad_norm": 0.6048681735992432,
      "learning_rate": 4.837991171560332e-05,
      "loss": 1.2794,
      "step": 31200
    },
    {
      "epoch": 0.09739541290980094,
      "grad_norm": 0.7884244918823242,
      "learning_rate": 4.8377314504592394e-05,
      "loss": 1.3108,
      "step": 31250
    },
    {
      "epoch": 0.09755124557045662,
      "grad_norm": 0.568787157535553,
      "learning_rate": 4.837471729358146e-05,
      "loss": 1.2872,
      "step": 31300
    },
    {
      "epoch": 0.0977070782311123,
      "grad_norm": 0.5467450618743896,
      "learning_rate": 4.837212008257053e-05,
      "loss": 1.3512,
      "step": 31350
    },
    {
      "epoch": 0.09786291089176799,
      "grad_norm": 0.5566503405570984,
      "learning_rate": 4.836952287155961e-05,
      "loss": 1.3166,
      "step": 31400
    },
    {
      "epoch": 0.09801874355242367,
      "grad_norm": 0.6660345196723938,
      "learning_rate": 4.836692566054868e-05,
      "loss": 1.2875,
      "step": 31450
    },
    {
      "epoch": 0.09817457621307935,
      "grad_norm": 0.6394785642623901,
      "learning_rate": 4.836432844953775e-05,
      "loss": 1.3256,
      "step": 31500
    },
    {
      "epoch": 0.09833040887373502,
      "grad_norm": 0.519582986831665,
      "learning_rate": 4.836173123852682e-05,
      "loss": 1.3096,
      "step": 31550
    },
    {
      "epoch": 0.09848624153439071,
      "grad_norm": 0.48336130380630493,
      "learning_rate": 4.8359134027515895e-05,
      "loss": 1.288,
      "step": 31600
    },
    {
      "epoch": 0.09864207419504639,
      "grad_norm": 0.6389699578285217,
      "learning_rate": 4.835653681650497e-05,
      "loss": 1.3037,
      "step": 31650
    },
    {
      "epoch": 0.09879790685570207,
      "grad_norm": 0.6254711151123047,
      "learning_rate": 4.835393960549404e-05,
      "loss": 1.3147,
      "step": 31700
    },
    {
      "epoch": 0.09895373951635776,
      "grad_norm": 0.6716580390930176,
      "learning_rate": 4.835134239448311e-05,
      "loss": 1.3356,
      "step": 31750
    },
    {
      "epoch": 0.09910957217701344,
      "grad_norm": 0.522241473197937,
      "learning_rate": 4.8348745183472185e-05,
      "loss": 1.2809,
      "step": 31800
    },
    {
      "epoch": 0.09926540483766912,
      "grad_norm": 0.6442894339561462,
      "learning_rate": 4.834614797246125e-05,
      "loss": 1.2725,
      "step": 31850
    },
    {
      "epoch": 0.0994212374983248,
      "grad_norm": 0.5778121948242188,
      "learning_rate": 4.834355076145033e-05,
      "loss": 1.3021,
      "step": 31900
    },
    {
      "epoch": 0.09957707015898049,
      "grad_norm": 0.45215466618537903,
      "learning_rate": 4.83409535504394e-05,
      "loss": 1.3506,
      "step": 31950
    },
    {
      "epoch": 0.09973290281963616,
      "grad_norm": 0.5922526717185974,
      "learning_rate": 4.833835633942847e-05,
      "loss": 1.3121,
      "step": 32000
    },
    {
      "epoch": 0.09988873548029184,
      "grad_norm": 0.7810489535331726,
      "learning_rate": 4.833575912841754e-05,
      "loss": 1.3259,
      "step": 32050
    },
    {
      "epoch": 0.10004456814094753,
      "grad_norm": 0.6372601389884949,
      "learning_rate": 4.833316191740662e-05,
      "loss": 1.2568,
      "step": 32100
    },
    {
      "epoch": 0.10020040080160321,
      "grad_norm": 0.6752703785896301,
      "learning_rate": 4.8330564706395685e-05,
      "loss": 1.2793,
      "step": 32150
    },
    {
      "epoch": 0.10035623346225889,
      "grad_norm": 0.6448495984077454,
      "learning_rate": 4.832796749538476e-05,
      "loss": 1.2854,
      "step": 32200
    },
    {
      "epoch": 0.10051206612291456,
      "grad_norm": 0.6271458268165588,
      "learning_rate": 4.832537028437383e-05,
      "loss": 1.3319,
      "step": 32250
    },
    {
      "epoch": 0.10066789878357026,
      "grad_norm": 0.5990386009216309,
      "learning_rate": 4.83227730733629e-05,
      "loss": 1.2997,
      "step": 32300
    },
    {
      "epoch": 0.10082373144422593,
      "grad_norm": 0.7323005199432373,
      "learning_rate": 4.8320175862351975e-05,
      "loss": 1.2957,
      "step": 32350
    },
    {
      "epoch": 0.10097956410488161,
      "grad_norm": 0.5498114228248596,
      "learning_rate": 4.831757865134104e-05,
      "loss": 1.3127,
      "step": 32400
    },
    {
      "epoch": 0.10113539676553729,
      "grad_norm": 0.5603175163269043,
      "learning_rate": 4.831498144033012e-05,
      "loss": 1.3446,
      "step": 32450
    },
    {
      "epoch": 0.10129122942619298,
      "grad_norm": 0.7006092667579651,
      "learning_rate": 4.831238422931919e-05,
      "loss": 1.316,
      "step": 32500
    },
    {
      "epoch": 0.10144706208684866,
      "grad_norm": 0.6053645610809326,
      "learning_rate": 4.830978701830826e-05,
      "loss": 1.3087,
      "step": 32550
    },
    {
      "epoch": 0.10160289474750434,
      "grad_norm": 0.5856729745864868,
      "learning_rate": 4.830718980729733e-05,
      "loss": 1.2513,
      "step": 32600
    },
    {
      "epoch": 0.10175872740816003,
      "grad_norm": 0.6290066838264465,
      "learning_rate": 4.830459259628641e-05,
      "loss": 1.3177,
      "step": 32650
    },
    {
      "epoch": 0.1019145600688157,
      "grad_norm": 0.6063239574432373,
      "learning_rate": 4.8301995385275476e-05,
      "loss": 1.2919,
      "step": 32700
    },
    {
      "epoch": 0.10207039272947138,
      "grad_norm": 0.6281803250312805,
      "learning_rate": 4.829939817426455e-05,
      "loss": 1.2575,
      "step": 32750
    },
    {
      "epoch": 0.10222622539012706,
      "grad_norm": 0.6185901761054993,
      "learning_rate": 4.829680096325362e-05,
      "loss": 1.3389,
      "step": 32800
    },
    {
      "epoch": 0.10238205805078275,
      "grad_norm": 0.5265676379203796,
      "learning_rate": 4.8294203752242694e-05,
      "loss": 1.3009,
      "step": 32850
    },
    {
      "epoch": 0.10253789071143843,
      "grad_norm": 0.7399351596832275,
      "learning_rate": 4.8291658485451986e-05,
      "loss": 1.3322,
      "step": 32900
    },
    {
      "epoch": 0.1026937233720941,
      "grad_norm": 0.7405065894126892,
      "learning_rate": 4.828906127444106e-05,
      "loss": 1.2711,
      "step": 32950
    },
    {
      "epoch": 0.1028495560327498,
      "grad_norm": 1.237826943397522,
      "learning_rate": 4.8286464063430124e-05,
      "loss": 1.2937,
      "step": 33000
    },
    {
      "epoch": 0.10300538869340548,
      "grad_norm": 0.607592761516571,
      "learning_rate": 4.82838668524192e-05,
      "loss": 1.2742,
      "step": 33050
    },
    {
      "epoch": 0.10316122135406115,
      "grad_norm": 0.604324221611023,
      "learning_rate": 4.828126964140827e-05,
      "loss": 1.2735,
      "step": 33100
    },
    {
      "epoch": 0.10331705401471683,
      "grad_norm": 0.4758050739765167,
      "learning_rate": 4.827867243039734e-05,
      "loss": 1.3064,
      "step": 33150
    },
    {
      "epoch": 0.10347288667537252,
      "grad_norm": 0.6848807334899902,
      "learning_rate": 4.827607521938642e-05,
      "loss": 1.2605,
      "step": 33200
    },
    {
      "epoch": 0.1036287193360282,
      "grad_norm": 0.6704609990119934,
      "learning_rate": 4.8273478008375487e-05,
      "loss": 1.282,
      "step": 33250
    },
    {
      "epoch": 0.10378455199668388,
      "grad_norm": 0.7627711296081543,
      "learning_rate": 4.827088079736456e-05,
      "loss": 1.2346,
      "step": 33300
    },
    {
      "epoch": 0.10394038465733957,
      "grad_norm": 0.5919960141181946,
      "learning_rate": 4.826828358635363e-05,
      "loss": 1.2679,
      "step": 33350
    },
    {
      "epoch": 0.10409621731799525,
      "grad_norm": 0.6013283729553223,
      "learning_rate": 4.8265686375342704e-05,
      "loss": 1.2776,
      "step": 33400
    },
    {
      "epoch": 0.10425204997865092,
      "grad_norm": 0.4607877731323242,
      "learning_rate": 4.8263089164331777e-05,
      "loss": 1.347,
      "step": 33450
    },
    {
      "epoch": 0.1044078826393066,
      "grad_norm": 0.5587279200553894,
      "learning_rate": 4.826049195332085e-05,
      "loss": 1.303,
      "step": 33500
    },
    {
      "epoch": 0.10456371529996229,
      "grad_norm": 0.5672995448112488,
      "learning_rate": 4.825789474230992e-05,
      "loss": 1.3452,
      "step": 33550
    },
    {
      "epoch": 0.10471954796061797,
      "grad_norm": 0.7008445858955383,
      "learning_rate": 4.8255297531298994e-05,
      "loss": 1.3274,
      "step": 33600
    },
    {
      "epoch": 0.10487538062127365,
      "grad_norm": 1.1993765830993652,
      "learning_rate": 4.8252700320288067e-05,
      "loss": 1.3349,
      "step": 33650
    },
    {
      "epoch": 0.10503121328192934,
      "grad_norm": 0.5641416907310486,
      "learning_rate": 4.825010310927713e-05,
      "loss": 1.3087,
      "step": 33700
    },
    {
      "epoch": 0.10518704594258502,
      "grad_norm": 0.6554998755455017,
      "learning_rate": 4.824750589826621e-05,
      "loss": 1.3109,
      "step": 33750
    },
    {
      "epoch": 0.1053428786032407,
      "grad_norm": 0.6819440722465515,
      "learning_rate": 4.824490868725528e-05,
      "loss": 1.3133,
      "step": 33800
    },
    {
      "epoch": 0.10549871126389637,
      "grad_norm": 0.5821626782417297,
      "learning_rate": 4.824231147624435e-05,
      "loss": 1.3177,
      "step": 33850
    },
    {
      "epoch": 0.10565454392455206,
      "grad_norm": 0.6140492558479309,
      "learning_rate": 4.823971426523343e-05,
      "loss": 1.2768,
      "step": 33900
    },
    {
      "epoch": 0.10581037658520774,
      "grad_norm": 0.6448777914047241,
      "learning_rate": 4.8237117054222495e-05,
      "loss": 1.3052,
      "step": 33950
    },
    {
      "epoch": 0.10596620924586342,
      "grad_norm": 0.5951988697052002,
      "learning_rate": 4.823451984321157e-05,
      "loss": 1.2747,
      "step": 34000
    },
    {
      "epoch": 0.10612204190651911,
      "grad_norm": 0.600569486618042,
      "learning_rate": 4.823192263220064e-05,
      "loss": 1.2833,
      "step": 34050
    },
    {
      "epoch": 0.10627787456717479,
      "grad_norm": 0.6354680061340332,
      "learning_rate": 4.822932542118971e-05,
      "loss": 1.3122,
      "step": 34100
    },
    {
      "epoch": 0.10643370722783047,
      "grad_norm": 0.7064590454101562,
      "learning_rate": 4.8226728210178785e-05,
      "loss": 1.3248,
      "step": 34150
    },
    {
      "epoch": 0.10658953988848614,
      "grad_norm": 0.609530508518219,
      "learning_rate": 4.822413099916786e-05,
      "loss": 1.2965,
      "step": 34200
    },
    {
      "epoch": 0.10674537254914183,
      "grad_norm": 0.6773823499679565,
      "learning_rate": 4.822153378815692e-05,
      "loss": 1.2743,
      "step": 34250
    },
    {
      "epoch": 0.10690120520979751,
      "grad_norm": 0.5117906332015991,
      "learning_rate": 4.8218936577146e-05,
      "loss": 1.3022,
      "step": 34300
    },
    {
      "epoch": 0.10705703787045319,
      "grad_norm": 0.5690749287605286,
      "learning_rate": 4.8216339366135075e-05,
      "loss": 1.2871,
      "step": 34350
    },
    {
      "epoch": 0.10721287053110888,
      "grad_norm": 0.6989483833312988,
      "learning_rate": 4.821374215512414e-05,
      "loss": 1.3626,
      "step": 34400
    },
    {
      "epoch": 0.10736870319176456,
      "grad_norm": 0.7673261761665344,
      "learning_rate": 4.821114494411322e-05,
      "loss": 1.3209,
      "step": 34450
    },
    {
      "epoch": 0.10752453585242024,
      "grad_norm": 0.5640439391136169,
      "learning_rate": 4.8208547733102286e-05,
      "loss": 1.3024,
      "step": 34500
    },
    {
      "epoch": 0.10768036851307591,
      "grad_norm": 0.5638662576675415,
      "learning_rate": 4.820595052209136e-05,
      "loss": 1.2448,
      "step": 34550
    },
    {
      "epoch": 0.1078362011737316,
      "grad_norm": 0.7025564312934875,
      "learning_rate": 4.820335331108043e-05,
      "loss": 1.3207,
      "step": 34600
    },
    {
      "epoch": 0.10799203383438728,
      "grad_norm": 0.5030674934387207,
      "learning_rate": 4.82007561000695e-05,
      "loss": 1.3153,
      "step": 34650
    },
    {
      "epoch": 0.10814786649504296,
      "grad_norm": 0.7745028138160706,
      "learning_rate": 4.8198158889058576e-05,
      "loss": 1.2773,
      "step": 34700
    },
    {
      "epoch": 0.10830369915569864,
      "grad_norm": 0.68645840883255,
      "learning_rate": 4.819556167804765e-05,
      "loss": 1.3051,
      "step": 34750
    },
    {
      "epoch": 0.10845953181635433,
      "grad_norm": 0.596472442150116,
      "learning_rate": 4.819296446703672e-05,
      "loss": 1.3545,
      "step": 34800
    },
    {
      "epoch": 0.10861536447701,
      "grad_norm": 0.6518841981887817,
      "learning_rate": 4.819036725602579e-05,
      "loss": 1.3201,
      "step": 34850
    },
    {
      "epoch": 0.10877119713766568,
      "grad_norm": 0.5931610465049744,
      "learning_rate": 4.8187770045014866e-05,
      "loss": 1.3203,
      "step": 34900
    },
    {
      "epoch": 0.10892702979832138,
      "grad_norm": 0.6665224432945251,
      "learning_rate": 4.818517283400393e-05,
      "loss": 1.2707,
      "step": 34950
    },
    {
      "epoch": 0.10908286245897705,
      "grad_norm": 0.5224091410636902,
      "learning_rate": 4.818257562299301e-05,
      "loss": 1.3082,
      "step": 35000
    },
    {
      "epoch": 0.10923869511963273,
      "grad_norm": 0.5619295835494995,
      "learning_rate": 4.8179978411982076e-05,
      "loss": 1.3352,
      "step": 35050
    },
    {
      "epoch": 0.10939452778028841,
      "grad_norm": 0.5159406661987305,
      "learning_rate": 4.817738120097115e-05,
      "loss": 1.335,
      "step": 35100
    },
    {
      "epoch": 0.1095503604409441,
      "grad_norm": 0.6865335702896118,
      "learning_rate": 4.817478398996023e-05,
      "loss": 1.279,
      "step": 35150
    },
    {
      "epoch": 0.10970619310159978,
      "grad_norm": 0.8152860999107361,
      "learning_rate": 4.8172186778949294e-05,
      "loss": 1.3077,
      "step": 35200
    },
    {
      "epoch": 0.10986202576225546,
      "grad_norm": 0.6178269982337952,
      "learning_rate": 4.8169589567938366e-05,
      "loss": 1.2582,
      "step": 35250
    },
    {
      "epoch": 0.11001785842291115,
      "grad_norm": 0.6713851094245911,
      "learning_rate": 4.816699235692744e-05,
      "loss": 1.3354,
      "step": 35300
    },
    {
      "epoch": 0.11017369108356682,
      "grad_norm": 0.48045849800109863,
      "learning_rate": 4.816439514591651e-05,
      "loss": 1.3417,
      "step": 35350
    },
    {
      "epoch": 0.1103295237442225,
      "grad_norm": 0.5223333239555359,
      "learning_rate": 4.8161797934905584e-05,
      "loss": 1.3391,
      "step": 35400
    },
    {
      "epoch": 0.11048535640487818,
      "grad_norm": 0.6113173961639404,
      "learning_rate": 4.8159200723894656e-05,
      "loss": 1.3117,
      "step": 35450
    },
    {
      "epoch": 0.11064118906553387,
      "grad_norm": 0.6141672730445862,
      "learning_rate": 4.815660351288372e-05,
      "loss": 1.2732,
      "step": 35500
    },
    {
      "epoch": 0.11079702172618955,
      "grad_norm": 0.5782865881919861,
      "learning_rate": 4.81540063018728e-05,
      "loss": 1.314,
      "step": 35550
    },
    {
      "epoch": 0.11095285438684523,
      "grad_norm": 0.642562747001648,
      "learning_rate": 4.8151409090861874e-05,
      "loss": 1.3028,
      "step": 35600
    },
    {
      "epoch": 0.11110868704750092,
      "grad_norm": 0.6634269952774048,
      "learning_rate": 4.814881187985094e-05,
      "loss": 1.2821,
      "step": 35650
    },
    {
      "epoch": 0.1112645197081566,
      "grad_norm": 0.5801329612731934,
      "learning_rate": 4.814621466884002e-05,
      "loss": 1.3377,
      "step": 35700
    },
    {
      "epoch": 0.11142035236881227,
      "grad_norm": 0.6966496706008911,
      "learning_rate": 4.8143617457829085e-05,
      "loss": 1.3436,
      "step": 35750
    },
    {
      "epoch": 0.11157618502946795,
      "grad_norm": 0.5621349215507507,
      "learning_rate": 4.814102024681816e-05,
      "loss": 1.2695,
      "step": 35800
    },
    {
      "epoch": 0.11173201769012364,
      "grad_norm": 0.7216249108314514,
      "learning_rate": 4.813842303580723e-05,
      "loss": 1.2801,
      "step": 35850
    },
    {
      "epoch": 0.11188785035077932,
      "grad_norm": 0.4429109990596771,
      "learning_rate": 4.81358258247963e-05,
      "loss": 1.2925,
      "step": 35900
    },
    {
      "epoch": 0.112043683011435,
      "grad_norm": 0.7279146909713745,
      "learning_rate": 4.8133228613785375e-05,
      "loss": 1.2854,
      "step": 35950
    },
    {
      "epoch": 0.11219951567209069,
      "grad_norm": 0.6892352104187012,
      "learning_rate": 4.813063140277445e-05,
      "loss": 1.2998,
      "step": 36000
    },
    {
      "epoch": 0.11235534833274637,
      "grad_norm": 0.5421904921531677,
      "learning_rate": 4.812803419176352e-05,
      "loss": 1.336,
      "step": 36050
    },
    {
      "epoch": 0.11251118099340204,
      "grad_norm": 0.6102074384689331,
      "learning_rate": 4.812543698075259e-05,
      "loss": 1.3253,
      "step": 36100
    },
    {
      "epoch": 0.11266701365405772,
      "grad_norm": 0.6387940049171448,
      "learning_rate": 4.8122839769741665e-05,
      "loss": 1.2908,
      "step": 36150
    },
    {
      "epoch": 0.11282284631471341,
      "grad_norm": 0.5687815546989441,
      "learning_rate": 4.812024255873073e-05,
      "loss": 1.3258,
      "step": 36200
    },
    {
      "epoch": 0.11297867897536909,
      "grad_norm": 0.6267993450164795,
      "learning_rate": 4.811764534771981e-05,
      "loss": 1.3195,
      "step": 36250
    },
    {
      "epoch": 0.11313451163602477,
      "grad_norm": 0.542776882648468,
      "learning_rate": 4.811504813670888e-05,
      "loss": 1.2904,
      "step": 36300
    },
    {
      "epoch": 0.11329034429668046,
      "grad_norm": 0.7760037183761597,
      "learning_rate": 4.811245092569795e-05,
      "loss": 1.2871,
      "step": 36350
    },
    {
      "epoch": 0.11344617695733614,
      "grad_norm": 0.6195964813232422,
      "learning_rate": 4.810985371468703e-05,
      "loss": 1.3082,
      "step": 36400
    },
    {
      "epoch": 0.11360200961799181,
      "grad_norm": 0.7235004901885986,
      "learning_rate": 4.810725650367609e-05,
      "loss": 1.3091,
      "step": 36450
    },
    {
      "epoch": 0.11375784227864749,
      "grad_norm": 0.618630588054657,
      "learning_rate": 4.8104659292665165e-05,
      "loss": 1.3053,
      "step": 36500
    },
    {
      "epoch": 0.11391367493930318,
      "grad_norm": 0.5345221757888794,
      "learning_rate": 4.810206208165424e-05,
      "loss": 1.2734,
      "step": 36550
    },
    {
      "epoch": 0.11406950759995886,
      "grad_norm": 0.5118734836578369,
      "learning_rate": 4.809946487064331e-05,
      "loss": 1.2871,
      "step": 36600
    },
    {
      "epoch": 0.11422534026061454,
      "grad_norm": 0.7908303737640381,
      "learning_rate": 4.809686765963238e-05,
      "loss": 1.2945,
      "step": 36650
    },
    {
      "epoch": 0.11438117292127023,
      "grad_norm": 0.5498906970024109,
      "learning_rate": 4.8094270448621455e-05,
      "loss": 1.234,
      "step": 36700
    },
    {
      "epoch": 0.11453700558192591,
      "grad_norm": 0.6774536371231079,
      "learning_rate": 4.809167323761052e-05,
      "loss": 1.2747,
      "step": 36750
    },
    {
      "epoch": 0.11469283824258159,
      "grad_norm": 0.6534583568572998,
      "learning_rate": 4.80890760265996e-05,
      "loss": 1.3055,
      "step": 36800
    },
    {
      "epoch": 0.11484867090323726,
      "grad_norm": 0.7130045294761658,
      "learning_rate": 4.808647881558867e-05,
      "loss": 1.3014,
      "step": 36850
    },
    {
      "epoch": 0.11500450356389295,
      "grad_norm": 0.6176275014877319,
      "learning_rate": 4.808388160457774e-05,
      "loss": 1.3135,
      "step": 36900
    },
    {
      "epoch": 0.11516033622454863,
      "grad_norm": 0.5602632761001587,
      "learning_rate": 4.808128439356682e-05,
      "loss": 1.3118,
      "step": 36950
    },
    {
      "epoch": 0.11531616888520431,
      "grad_norm": 0.5282571315765381,
      "learning_rate": 4.807868718255589e-05,
      "loss": 1.3323,
      "step": 37000
    },
    {
      "epoch": 0.11547200154585999,
      "grad_norm": 0.5654685497283936,
      "learning_rate": 4.8076089971544956e-05,
      "loss": 1.303,
      "step": 37050
    },
    {
      "epoch": 0.11562783420651568,
      "grad_norm": 0.5661150217056274,
      "learning_rate": 4.807349276053403e-05,
      "loss": 1.3374,
      "step": 37100
    },
    {
      "epoch": 0.11578366686717136,
      "grad_norm": 0.6020643711090088,
      "learning_rate": 4.80708955495231e-05,
      "loss": 1.2701,
      "step": 37150
    },
    {
      "epoch": 0.11593949952782703,
      "grad_norm": 0.6891269683837891,
      "learning_rate": 4.8068298338512174e-05,
      "loss": 1.3087,
      "step": 37200
    },
    {
      "epoch": 0.11609533218848272,
      "grad_norm": 0.666938841342926,
      "learning_rate": 4.8065701127501246e-05,
      "loss": 1.294,
      "step": 37250
    },
    {
      "epoch": 0.1162511648491384,
      "grad_norm": 0.7183475494384766,
      "learning_rate": 4.806310391649032e-05,
      "loss": 1.2727,
      "step": 37300
    },
    {
      "epoch": 0.11640699750979408,
      "grad_norm": 0.62204909324646,
      "learning_rate": 4.806050670547939e-05,
      "loss": 1.3147,
      "step": 37350
    },
    {
      "epoch": 0.11656283017044976,
      "grad_norm": 0.5770717263221741,
      "learning_rate": 4.8057909494468464e-05,
      "loss": 1.3205,
      "step": 37400
    },
    {
      "epoch": 0.11671866283110545,
      "grad_norm": 0.7261562347412109,
      "learning_rate": 4.805531228345753e-05,
      "loss": 1.3426,
      "step": 37450
    },
    {
      "epoch": 0.11687449549176113,
      "grad_norm": 0.6893677711486816,
      "learning_rate": 4.805276701666683e-05,
      "loss": 1.2651,
      "step": 37500
    },
    {
      "epoch": 0.1170303281524168,
      "grad_norm": 0.6405282020568848,
      "learning_rate": 4.80501698056559e-05,
      "loss": 1.2545,
      "step": 37550
    },
    {
      "epoch": 0.1171861608130725,
      "grad_norm": 0.5758815407752991,
      "learning_rate": 4.8047572594644966e-05,
      "loss": 1.3105,
      "step": 37600
    },
    {
      "epoch": 0.11734199347372817,
      "grad_norm": 0.5582353472709656,
      "learning_rate": 4.804497538363404e-05,
      "loss": 1.2543,
      "step": 37650
    },
    {
      "epoch": 0.11749782613438385,
      "grad_norm": 0.45709720253944397,
      "learning_rate": 4.804237817262311e-05,
      "loss": 1.2736,
      "step": 37700
    },
    {
      "epoch": 0.11765365879503953,
      "grad_norm": 0.5566271543502808,
      "learning_rate": 4.8039780961612184e-05,
      "loss": 1.2852,
      "step": 37750
    },
    {
      "epoch": 0.11780949145569522,
      "grad_norm": 0.6098825335502625,
      "learning_rate": 4.8037183750601257e-05,
      "loss": 1.2848,
      "step": 37800
    },
    {
      "epoch": 0.1179653241163509,
      "grad_norm": 0.6571801900863647,
      "learning_rate": 4.803458653959033e-05,
      "loss": 1.2786,
      "step": 37850
    },
    {
      "epoch": 0.11812115677700658,
      "grad_norm": 0.5777910947799683,
      "learning_rate": 4.80319893285794e-05,
      "loss": 1.2962,
      "step": 37900
    },
    {
      "epoch": 0.11827698943766227,
      "grad_norm": 0.9396817684173584,
      "learning_rate": 4.8029392117568474e-05,
      "loss": 1.3003,
      "step": 37950
    },
    {
      "epoch": 0.11843282209831794,
      "grad_norm": 0.6254543662071228,
      "learning_rate": 4.802679490655754e-05,
      "loss": 1.3428,
      "step": 38000
    },
    {
      "epoch": 0.11858865475897362,
      "grad_norm": 0.6974159479141235,
      "learning_rate": 4.802419769554662e-05,
      "loss": 1.2912,
      "step": 38050
    },
    {
      "epoch": 0.1187444874196293,
      "grad_norm": 0.6924845576286316,
      "learning_rate": 4.802160048453569e-05,
      "loss": 1.3808,
      "step": 38100
    },
    {
      "epoch": 0.11890032008028499,
      "grad_norm": 0.47615769505500793,
      "learning_rate": 4.801900327352476e-05,
      "loss": 1.2885,
      "step": 38150
    },
    {
      "epoch": 0.11905615274094067,
      "grad_norm": 0.6110733151435852,
      "learning_rate": 4.801640606251383e-05,
      "loss": 1.3132,
      "step": 38200
    },
    {
      "epoch": 0.11921198540159635,
      "grad_norm": 0.5641067028045654,
      "learning_rate": 4.801380885150291e-05,
      "loss": 1.2955,
      "step": 38250
    },
    {
      "epoch": 0.11936781806225204,
      "grad_norm": 0.6146008968353271,
      "learning_rate": 4.8011211640491975e-05,
      "loss": 1.3437,
      "step": 38300
    },
    {
      "epoch": 0.11952365072290771,
      "grad_norm": 0.6478571891784668,
      "learning_rate": 4.800861442948105e-05,
      "loss": 1.2836,
      "step": 38350
    },
    {
      "epoch": 0.11967948338356339,
      "grad_norm": 0.7837452292442322,
      "learning_rate": 4.800601721847012e-05,
      "loss": 1.3256,
      "step": 38400
    },
    {
      "epoch": 0.11983531604421907,
      "grad_norm": 0.5896023511886597,
      "learning_rate": 4.800342000745919e-05,
      "loss": 1.253,
      "step": 38450
    },
    {
      "epoch": 0.11999114870487476,
      "grad_norm": 0.5360631942749023,
      "learning_rate": 4.8000822796448265e-05,
      "loss": 1.3111,
      "step": 38500
    },
    {
      "epoch": 0.12014698136553044,
      "grad_norm": 0.583428144454956,
      "learning_rate": 4.799822558543734e-05,
      "loss": 1.3257,
      "step": 38550
    },
    {
      "epoch": 0.12030281402618612,
      "grad_norm": 0.48544856905937195,
      "learning_rate": 4.799562837442641e-05,
      "loss": 1.3161,
      "step": 38600
    },
    {
      "epoch": 0.12045864668684181,
      "grad_norm": 0.6622384190559387,
      "learning_rate": 4.799303116341548e-05,
      "loss": 1.3258,
      "step": 38650
    },
    {
      "epoch": 0.12061447934749749,
      "grad_norm": 0.6809834241867065,
      "learning_rate": 4.799043395240455e-05,
      "loss": 1.306,
      "step": 38700
    },
    {
      "epoch": 0.12077031200815316,
      "grad_norm": 0.6607571840286255,
      "learning_rate": 4.798783674139362e-05,
      "loss": 1.3095,
      "step": 38750
    },
    {
      "epoch": 0.12092614466880884,
      "grad_norm": 0.6357582211494446,
      "learning_rate": 4.79852395303827e-05,
      "loss": 1.3349,
      "step": 38800
    },
    {
      "epoch": 0.12108197732946453,
      "grad_norm": 0.6992290019989014,
      "learning_rate": 4.7982642319371766e-05,
      "loss": 1.3099,
      "step": 38850
    },
    {
      "epoch": 0.12123780999012021,
      "grad_norm": 0.7286826968193054,
      "learning_rate": 4.798004510836084e-05,
      "loss": 1.3105,
      "step": 38900
    },
    {
      "epoch": 0.12139364265077589,
      "grad_norm": 0.5787908434867859,
      "learning_rate": 4.797744789734992e-05,
      "loss": 1.3318,
      "step": 38950
    },
    {
      "epoch": 0.12154947531143158,
      "grad_norm": 0.5071535110473633,
      "learning_rate": 4.797485068633898e-05,
      "loss": 1.3426,
      "step": 39000
    },
    {
      "epoch": 0.12170530797208726,
      "grad_norm": 0.679426372051239,
      "learning_rate": 4.7972253475328056e-05,
      "loss": 1.3095,
      "step": 39050
    },
    {
      "epoch": 0.12186114063274293,
      "grad_norm": 0.5976461172103882,
      "learning_rate": 4.796965626431713e-05,
      "loss": 1.3135,
      "step": 39100
    },
    {
      "epoch": 0.12201697329339861,
      "grad_norm": 0.6141932606697083,
      "learning_rate": 4.79670590533062e-05,
      "loss": 1.3331,
      "step": 39150
    },
    {
      "epoch": 0.1221728059540543,
      "grad_norm": 0.6228541135787964,
      "learning_rate": 4.796451378651549e-05,
      "loss": 1.2762,
      "step": 39200
    },
    {
      "epoch": 0.12232863861470998,
      "grad_norm": 0.6197887659072876,
      "learning_rate": 4.7961916575504565e-05,
      "loss": 1.3103,
      "step": 39250
    },
    {
      "epoch": 0.12248447127536566,
      "grad_norm": 0.6343642473220825,
      "learning_rate": 4.795931936449363e-05,
      "loss": 1.3408,
      "step": 39300
    },
    {
      "epoch": 0.12264030393602134,
      "grad_norm": 0.6833229660987854,
      "learning_rate": 4.795672215348271e-05,
      "loss": 1.3265,
      "step": 39350
    },
    {
      "epoch": 0.12279613659667703,
      "grad_norm": 0.4940321743488312,
      "learning_rate": 4.7954124942471776e-05,
      "loss": 1.298,
      "step": 39400
    },
    {
      "epoch": 0.1229519692573327,
      "grad_norm": 0.6605017185211182,
      "learning_rate": 4.795152773146085e-05,
      "loss": 1.3137,
      "step": 39450
    },
    {
      "epoch": 0.12310780191798838,
      "grad_norm": 0.5250045657157898,
      "learning_rate": 4.794893052044993e-05,
      "loss": 1.3596,
      "step": 39500
    },
    {
      "epoch": 0.12326363457864407,
      "grad_norm": 0.6672757863998413,
      "learning_rate": 4.7946333309438993e-05,
      "loss": 1.3054,
      "step": 39550
    },
    {
      "epoch": 0.12341946723929975,
      "grad_norm": 0.6032199859619141,
      "learning_rate": 4.7943736098428066e-05,
      "loss": 1.3034,
      "step": 39600
    },
    {
      "epoch": 0.12357529989995543,
      "grad_norm": 0.49301764369010925,
      "learning_rate": 4.794113888741714e-05,
      "loss": 1.3207,
      "step": 39650
    },
    {
      "epoch": 0.1237311325606111,
      "grad_norm": 0.6685217022895813,
      "learning_rate": 4.793854167640621e-05,
      "loss": 1.3246,
      "step": 39700
    },
    {
      "epoch": 0.1238869652212668,
      "grad_norm": 0.5751984119415283,
      "learning_rate": 4.7935944465395283e-05,
      "loss": 1.3289,
      "step": 39750
    },
    {
      "epoch": 0.12404279788192248,
      "grad_norm": 0.5758429169654846,
      "learning_rate": 4.7933347254384356e-05,
      "loss": 1.3439,
      "step": 39800
    },
    {
      "epoch": 0.12419863054257815,
      "grad_norm": 0.7467831373214722,
      "learning_rate": 4.793075004337342e-05,
      "loss": 1.2799,
      "step": 39850
    },
    {
      "epoch": 0.12435446320323384,
      "grad_norm": 0.6555393934249878,
      "learning_rate": 4.79281528323625e-05,
      "loss": 1.3146,
      "step": 39900
    },
    {
      "epoch": 0.12451029586388952,
      "grad_norm": 0.6441541910171509,
      "learning_rate": 4.792555562135157e-05,
      "loss": 1.3121,
      "step": 39950
    },
    {
      "epoch": 0.1246661285245452,
      "grad_norm": 0.6305166482925415,
      "learning_rate": 4.792295841034064e-05,
      "loss": 1.3029,
      "step": 40000
    },
    {
      "epoch": 0.12482196118520088,
      "grad_norm": 0.8011161088943481,
      "learning_rate": 4.792036119932972e-05,
      "loss": 1.3883,
      "step": 40050
    },
    {
      "epoch": 0.12497779384585657,
      "grad_norm": 0.5882392525672913,
      "learning_rate": 4.7917763988318784e-05,
      "loss": 1.2985,
      "step": 40100
    },
    {
      "epoch": 0.12513362650651225,
      "grad_norm": 0.5609350204467773,
      "learning_rate": 4.791516677730786e-05,
      "loss": 1.2476,
      "step": 40150
    },
    {
      "epoch": 0.12528945916716794,
      "grad_norm": 0.622124195098877,
      "learning_rate": 4.791256956629693e-05,
      "loss": 1.3238,
      "step": 40200
    },
    {
      "epoch": 0.1254452918278236,
      "grad_norm": 0.6311288475990295,
      "learning_rate": 4.7909972355286e-05,
      "loss": 1.372,
      "step": 40250
    },
    {
      "epoch": 0.1256011244884793,
      "grad_norm": 0.594477653503418,
      "learning_rate": 4.7907375144275074e-05,
      "loss": 1.2927,
      "step": 40300
    },
    {
      "epoch": 0.12575695714913498,
      "grad_norm": 0.6637527942657471,
      "learning_rate": 4.790477793326415e-05,
      "loss": 1.2839,
      "step": 40350
    },
    {
      "epoch": 0.12591278980979065,
      "grad_norm": 0.5592416524887085,
      "learning_rate": 4.790218072225322e-05,
      "loss": 1.2559,
      "step": 40400
    },
    {
      "epoch": 0.12606862247044634,
      "grad_norm": 0.5094160437583923,
      "learning_rate": 4.789958351124229e-05,
      "loss": 1.2733,
      "step": 40450
    },
    {
      "epoch": 0.126224455131102,
      "grad_norm": 0.5733274221420288,
      "learning_rate": 4.7896986300231364e-05,
      "loss": 1.2305,
      "step": 40500
    },
    {
      "epoch": 0.1263802877917577,
      "grad_norm": 0.8550841808319092,
      "learning_rate": 4.789438908922043e-05,
      "loss": 1.3029,
      "step": 40550
    },
    {
      "epoch": 0.1265361204524134,
      "grad_norm": 0.7201706767082214,
      "learning_rate": 4.789179187820951e-05,
      "loss": 1.2904,
      "step": 40600
    },
    {
      "epoch": 0.12669195311306905,
      "grad_norm": 0.7317982316017151,
      "learning_rate": 4.7889194667198575e-05,
      "loss": 1.2636,
      "step": 40650
    },
    {
      "epoch": 0.12684778577372474,
      "grad_norm": 0.695854127407074,
      "learning_rate": 4.788659745618765e-05,
      "loss": 1.2735,
      "step": 40700
    },
    {
      "epoch": 0.12700361843438043,
      "grad_norm": 0.637054979801178,
      "learning_rate": 4.788400024517673e-05,
      "loss": 1.3367,
      "step": 40750
    },
    {
      "epoch": 0.1271594510950361,
      "grad_norm": 0.5099891424179077,
      "learning_rate": 4.788140303416579e-05,
      "loss": 1.3128,
      "step": 40800
    },
    {
      "epoch": 0.1273152837556918,
      "grad_norm": 0.8625943064689636,
      "learning_rate": 4.7878805823154865e-05,
      "loss": 1.305,
      "step": 40850
    },
    {
      "epoch": 0.12747111641634748,
      "grad_norm": 0.5268903970718384,
      "learning_rate": 4.787620861214394e-05,
      "loss": 1.2943,
      "step": 40900
    },
    {
      "epoch": 0.12762694907700314,
      "grad_norm": 0.5531526803970337,
      "learning_rate": 4.787361140113301e-05,
      "loss": 1.275,
      "step": 40950
    },
    {
      "epoch": 0.12778278173765883,
      "grad_norm": 0.5226430892944336,
      "learning_rate": 4.787101419012208e-05,
      "loss": 1.2725,
      "step": 41000
    },
    {
      "epoch": 0.12793861439831453,
      "grad_norm": 0.5908145308494568,
      "learning_rate": 4.7868416979111155e-05,
      "loss": 1.3492,
      "step": 41050
    },
    {
      "epoch": 0.1280944470589702,
      "grad_norm": 0.4799811840057373,
      "learning_rate": 4.786581976810022e-05,
      "loss": 1.2759,
      "step": 41100
    },
    {
      "epoch": 0.12825027971962588,
      "grad_norm": 0.49830639362335205,
      "learning_rate": 4.78632225570893e-05,
      "loss": 1.2931,
      "step": 41150
    },
    {
      "epoch": 0.12840611238028155,
      "grad_norm": 0.642104983329773,
      "learning_rate": 4.786062534607837e-05,
      "loss": 1.285,
      "step": 41200
    },
    {
      "epoch": 0.12856194504093724,
      "grad_norm": 0.7594215273857117,
      "learning_rate": 4.785802813506744e-05,
      "loss": 1.2428,
      "step": 41250
    },
    {
      "epoch": 0.12871777770159293,
      "grad_norm": 0.661133348941803,
      "learning_rate": 4.785543092405652e-05,
      "loss": 1.3163,
      "step": 41300
    },
    {
      "epoch": 0.1288736103622486,
      "grad_norm": 0.591550350189209,
      "learning_rate": 4.785283371304558e-05,
      "loss": 1.2864,
      "step": 41350
    },
    {
      "epoch": 0.12902944302290428,
      "grad_norm": 0.494907945394516,
      "learning_rate": 4.7850236502034656e-05,
      "loss": 1.2782,
      "step": 41400
    },
    {
      "epoch": 0.12918527568355997,
      "grad_norm": 0.6424683332443237,
      "learning_rate": 4.784763929102373e-05,
      "loss": 1.3288,
      "step": 41450
    },
    {
      "epoch": 0.12934110834421564,
      "grad_norm": 0.6834307909011841,
      "learning_rate": 4.78450420800128e-05,
      "loss": 1.2702,
      "step": 41500
    },
    {
      "epoch": 0.12949694100487133,
      "grad_norm": 0.6448318362236023,
      "learning_rate": 4.784244486900187e-05,
      "loss": 1.3224,
      "step": 41550
    },
    {
      "epoch": 0.12965277366552702,
      "grad_norm": 0.7109874486923218,
      "learning_rate": 4.7839847657990946e-05,
      "loss": 1.3016,
      "step": 41600
    },
    {
      "epoch": 0.12980860632618269,
      "grad_norm": 0.5444416403770447,
      "learning_rate": 4.783725044698002e-05,
      "loss": 1.2113,
      "step": 41650
    },
    {
      "epoch": 0.12996443898683838,
      "grad_norm": 0.5855161547660828,
      "learning_rate": 4.783465323596909e-05,
      "loss": 1.3364,
      "step": 41700
    },
    {
      "epoch": 0.13012027164749407,
      "grad_norm": 0.6828435659408569,
      "learning_rate": 4.783205602495816e-05,
      "loss": 1.3315,
      "step": 41750
    },
    {
      "epoch": 0.13027610430814973,
      "grad_norm": 0.6214451789855957,
      "learning_rate": 4.782945881394723e-05,
      "loss": 1.2882,
      "step": 41800
    },
    {
      "epoch": 0.13043193696880542,
      "grad_norm": 0.6646784543991089,
      "learning_rate": 4.782686160293631e-05,
      "loss": 1.2959,
      "step": 41850
    },
    {
      "epoch": 0.1305877696294611,
      "grad_norm": 0.6028434634208679,
      "learning_rate": 4.782426439192538e-05,
      "loss": 1.2547,
      "step": 41900
    },
    {
      "epoch": 0.13074360229011678,
      "grad_norm": 0.7210351228713989,
      "learning_rate": 4.7821667180914446e-05,
      "loss": 1.2832,
      "step": 41950
    },
    {
      "epoch": 0.13089943495077247,
      "grad_norm": 0.6228259205818176,
      "learning_rate": 4.7819069969903526e-05,
      "loss": 1.312,
      "step": 42000
    },
    {
      "epoch": 0.13105526761142813,
      "grad_norm": 0.5069441199302673,
      "learning_rate": 4.781647275889259e-05,
      "loss": 1.3074,
      "step": 42050
    },
    {
      "epoch": 0.13121110027208382,
      "grad_norm": 0.45655709505081177,
      "learning_rate": 4.7813875547881664e-05,
      "loss": 1.3005,
      "step": 42100
    },
    {
      "epoch": 0.13136693293273952,
      "grad_norm": 0.8035102486610413,
      "learning_rate": 4.7811278336870736e-05,
      "loss": 1.3398,
      "step": 42150
    },
    {
      "epoch": 0.13152276559339518,
      "grad_norm": 0.5357477068901062,
      "learning_rate": 4.780868112585981e-05,
      "loss": 1.3246,
      "step": 42200
    },
    {
      "epoch": 0.13167859825405087,
      "grad_norm": 0.4984484910964966,
      "learning_rate": 4.780608391484888e-05,
      "loss": 1.305,
      "step": 42250
    },
    {
      "epoch": 0.13183443091470656,
      "grad_norm": 0.5974494814872742,
      "learning_rate": 4.7803486703837954e-05,
      "loss": 1.2888,
      "step": 42300
    },
    {
      "epoch": 0.13199026357536223,
      "grad_norm": 0.6469826102256775,
      "learning_rate": 4.780088949282702e-05,
      "loss": 1.2738,
      "step": 42350
    },
    {
      "epoch": 0.13214609623601792,
      "grad_norm": 0.6579638123512268,
      "learning_rate": 4.77982922818161e-05,
      "loss": 1.2759,
      "step": 42400
    },
    {
      "epoch": 0.1323019288966736,
      "grad_norm": 0.7683864235877991,
      "learning_rate": 4.779569507080517e-05,
      "loss": 1.2895,
      "step": 42450
    },
    {
      "epoch": 0.13245776155732927,
      "grad_norm": 0.6605919599533081,
      "learning_rate": 4.779309785979424e-05,
      "loss": 1.3028,
      "step": 42500
    },
    {
      "epoch": 0.13261359421798496,
      "grad_norm": 0.9098865389823914,
      "learning_rate": 4.7790500648783316e-05,
      "loss": 1.3026,
      "step": 42550
    },
    {
      "epoch": 0.13276942687864063,
      "grad_norm": 0.5549512505531311,
      "learning_rate": 4.778790343777238e-05,
      "loss": 1.2849,
      "step": 42600
    },
    {
      "epoch": 0.13292525953929632,
      "grad_norm": 0.6708370447158813,
      "learning_rate": 4.7785306226761455e-05,
      "loss": 1.3095,
      "step": 42650
    },
    {
      "epoch": 0.133081092199952,
      "grad_norm": 0.6053194999694824,
      "learning_rate": 4.778270901575053e-05,
      "loss": 1.25,
      "step": 42700
    },
    {
      "epoch": 0.13323692486060768,
      "grad_norm": 0.5775591731071472,
      "learning_rate": 4.77801118047396e-05,
      "loss": 1.2985,
      "step": 42750
    },
    {
      "epoch": 0.13339275752126337,
      "grad_norm": 1.0243196487426758,
      "learning_rate": 4.777751459372867e-05,
      "loss": 1.3086,
      "step": 42800
    },
    {
      "epoch": 0.13354859018191906,
      "grad_norm": 0.7350090742111206,
      "learning_rate": 4.7774917382717745e-05,
      "loss": 1.3137,
      "step": 42850
    },
    {
      "epoch": 0.13370442284257472,
      "grad_norm": 0.732199490070343,
      "learning_rate": 4.777232017170682e-05,
      "loss": 1.3172,
      "step": 42900
    },
    {
      "epoch": 0.1338602555032304,
      "grad_norm": 0.5910337567329407,
      "learning_rate": 4.776972296069589e-05,
      "loss": 1.251,
      "step": 42950
    },
    {
      "epoch": 0.1340160881638861,
      "grad_norm": 0.6084860563278198,
      "learning_rate": 4.776717769390518e-05,
      "loss": 1.2369,
      "step": 43000
    },
    {
      "epoch": 0.13417192082454177,
      "grad_norm": 0.6138707399368286,
      "learning_rate": 4.776458048289425e-05,
      "loss": 1.3068,
      "step": 43050
    },
    {
      "epoch": 0.13432775348519746,
      "grad_norm": 0.5429355502128601,
      "learning_rate": 4.776198327188332e-05,
      "loss": 1.282,
      "step": 43100
    },
    {
      "epoch": 0.13448358614585312,
      "grad_norm": 0.626960039138794,
      "learning_rate": 4.77593860608724e-05,
      "loss": 1.2671,
      "step": 43150
    },
    {
      "epoch": 0.13463941880650881,
      "grad_norm": 0.7030003666877747,
      "learning_rate": 4.7756788849861465e-05,
      "loss": 1.2787,
      "step": 43200
    },
    {
      "epoch": 0.1347952514671645,
      "grad_norm": 0.5922453999519348,
      "learning_rate": 4.775419163885054e-05,
      "loss": 1.2614,
      "step": 43250
    },
    {
      "epoch": 0.13495108412782017,
      "grad_norm": 0.7580147981643677,
      "learning_rate": 4.775159442783961e-05,
      "loss": 1.2837,
      "step": 43300
    },
    {
      "epoch": 0.13510691678847586,
      "grad_norm": 0.5236717462539673,
      "learning_rate": 4.774899721682868e-05,
      "loss": 1.2952,
      "step": 43350
    },
    {
      "epoch": 0.13526274944913155,
      "grad_norm": 0.6583983302116394,
      "learning_rate": 4.7746400005817755e-05,
      "loss": 1.3854,
      "step": 43400
    },
    {
      "epoch": 0.13541858210978722,
      "grad_norm": 0.4796546995639801,
      "learning_rate": 4.774380279480683e-05,
      "loss": 1.238,
      "step": 43450
    },
    {
      "epoch": 0.1355744147704429,
      "grad_norm": 0.5967694520950317,
      "learning_rate": 4.77412055837959e-05,
      "loss": 1.308,
      "step": 43500
    },
    {
      "epoch": 0.1357302474310986,
      "grad_norm": 0.6152626276016235,
      "learning_rate": 4.773860837278497e-05,
      "loss": 1.2835,
      "step": 43550
    },
    {
      "epoch": 0.13588608009175426,
      "grad_norm": 0.562749981880188,
      "learning_rate": 4.773601116177404e-05,
      "loss": 1.3484,
      "step": 43600
    },
    {
      "epoch": 0.13604191275240995,
      "grad_norm": 0.5785967707633972,
      "learning_rate": 4.773341395076312e-05,
      "loss": 1.2886,
      "step": 43650
    },
    {
      "epoch": 0.13619774541306565,
      "grad_norm": 0.7335153222084045,
      "learning_rate": 4.773081673975219e-05,
      "loss": 1.2703,
      "step": 43700
    },
    {
      "epoch": 0.1363535780737213,
      "grad_norm": 0.7303630709648132,
      "learning_rate": 4.7728219528741256e-05,
      "loss": 1.2925,
      "step": 43750
    },
    {
      "epoch": 0.136509410734377,
      "grad_norm": 0.4848690330982208,
      "learning_rate": 4.772562231773033e-05,
      "loss": 1.275,
      "step": 43800
    },
    {
      "epoch": 0.13666524339503267,
      "grad_norm": 0.6308820247650146,
      "learning_rate": 4.772302510671941e-05,
      "loss": 1.3131,
      "step": 43850
    },
    {
      "epoch": 0.13682107605568836,
      "grad_norm": 0.6194983124732971,
      "learning_rate": 4.772042789570847e-05,
      "loss": 1.2833,
      "step": 43900
    },
    {
      "epoch": 0.13697690871634405,
      "grad_norm": 0.5377551913261414,
      "learning_rate": 4.7717830684697546e-05,
      "loss": 1.3128,
      "step": 43950
    },
    {
      "epoch": 0.1371327413769997,
      "grad_norm": 0.7132671475410461,
      "learning_rate": 4.771523347368662e-05,
      "loss": 1.3163,
      "step": 44000
    },
    {
      "epoch": 0.1372885740376554,
      "grad_norm": 0.648773193359375,
      "learning_rate": 4.771263626267569e-05,
      "loss": 1.3471,
      "step": 44050
    },
    {
      "epoch": 0.1374444066983111,
      "grad_norm": 0.5465928912162781,
      "learning_rate": 4.771003905166476e-05,
      "loss": 1.322,
      "step": 44100
    },
    {
      "epoch": 0.13760023935896676,
      "grad_norm": 0.6114341616630554,
      "learning_rate": 4.7707441840653836e-05,
      "loss": 1.2783,
      "step": 44150
    },
    {
      "epoch": 0.13775607201962245,
      "grad_norm": 0.7200212478637695,
      "learning_rate": 4.770484462964291e-05,
      "loss": 1.3512,
      "step": 44200
    },
    {
      "epoch": 0.13791190468027814,
      "grad_norm": 0.6343104243278503,
      "learning_rate": 4.770224741863198e-05,
      "loss": 1.2732,
      "step": 44250
    },
    {
      "epoch": 0.1380677373409338,
      "grad_norm": 0.5095133185386658,
      "learning_rate": 4.769965020762105e-05,
      "loss": 1.3404,
      "step": 44300
    },
    {
      "epoch": 0.1382235700015895,
      "grad_norm": 0.6715269088745117,
      "learning_rate": 4.769705299661012e-05,
      "loss": 1.2858,
      "step": 44350
    },
    {
      "epoch": 0.1383794026622452,
      "grad_norm": 0.7005615234375,
      "learning_rate": 4.76944557855992e-05,
      "loss": 1.3115,
      "step": 44400
    },
    {
      "epoch": 0.13853523532290085,
      "grad_norm": 0.6152716279029846,
      "learning_rate": 4.7691858574588264e-05,
      "loss": 1.2708,
      "step": 44450
    },
    {
      "epoch": 0.13869106798355654,
      "grad_norm": 0.48650383949279785,
      "learning_rate": 4.768926136357734e-05,
      "loss": 1.2827,
      "step": 44500
    },
    {
      "epoch": 0.1388469006442122,
      "grad_norm": 0.5549106001853943,
      "learning_rate": 4.7686664152566416e-05,
      "loss": 1.3089,
      "step": 44550
    },
    {
      "epoch": 0.1390027333048679,
      "grad_norm": 0.527289867401123,
      "learning_rate": 4.768406694155548e-05,
      "loss": 1.3186,
      "step": 44600
    },
    {
      "epoch": 0.1391585659655236,
      "grad_norm": 0.5855532884597778,
      "learning_rate": 4.7681469730544554e-05,
      "loss": 1.2571,
      "step": 44650
    },
    {
      "epoch": 0.13931439862617925,
      "grad_norm": 0.6664409041404724,
      "learning_rate": 4.767887251953363e-05,
      "loss": 1.3079,
      "step": 44700
    },
    {
      "epoch": 0.13947023128683494,
      "grad_norm": 0.6634602546691895,
      "learning_rate": 4.76762753085227e-05,
      "loss": 1.2909,
      "step": 44750
    },
    {
      "epoch": 0.13962606394749064,
      "grad_norm": 0.6854048371315002,
      "learning_rate": 4.767367809751177e-05,
      "loss": 1.2783,
      "step": 44800
    },
    {
      "epoch": 0.1397818966081463,
      "grad_norm": 0.7053347229957581,
      "learning_rate": 4.767108088650084e-05,
      "loss": 1.2984,
      "step": 44850
    },
    {
      "epoch": 0.139937729268802,
      "grad_norm": 0.6066932082176208,
      "learning_rate": 4.766848367548992e-05,
      "loss": 1.2631,
      "step": 44900
    },
    {
      "epoch": 0.14009356192945768,
      "grad_norm": 0.7622117400169373,
      "learning_rate": 4.766588646447899e-05,
      "loss": 1.3384,
      "step": 44950
    },
    {
      "epoch": 0.14024939459011335,
      "grad_norm": 0.7526707649230957,
      "learning_rate": 4.7663289253468055e-05,
      "loss": 1.3255,
      "step": 45000
    },
    {
      "epoch": 0.14040522725076904,
      "grad_norm": 0.5595806241035461,
      "learning_rate": 4.766069204245713e-05,
      "loss": 1.2993,
      "step": 45050
    },
    {
      "epoch": 0.14056105991142473,
      "grad_norm": 0.5261533260345459,
      "learning_rate": 4.765809483144621e-05,
      "loss": 1.2996,
      "step": 45100
    },
    {
      "epoch": 0.1407168925720804,
      "grad_norm": 0.5121748447418213,
      "learning_rate": 4.765549762043527e-05,
      "loss": 1.27,
      "step": 45150
    },
    {
      "epoch": 0.14087272523273608,
      "grad_norm": 0.5103694200515747,
      "learning_rate": 4.7652900409424345e-05,
      "loss": 1.3109,
      "step": 45200
    },
    {
      "epoch": 0.14102855789339175,
      "grad_norm": 0.5206372737884521,
      "learning_rate": 4.765030319841342e-05,
      "loss": 1.2882,
      "step": 45250
    },
    {
      "epoch": 0.14118439055404744,
      "grad_norm": 0.6091538667678833,
      "learning_rate": 4.764770598740249e-05,
      "loss": 1.25,
      "step": 45300
    },
    {
      "epoch": 0.14134022321470313,
      "grad_norm": 0.583690345287323,
      "learning_rate": 4.764510877639156e-05,
      "loss": 1.3268,
      "step": 45350
    },
    {
      "epoch": 0.1414960558753588,
      "grad_norm": 0.5274431705474854,
      "learning_rate": 4.7642511565380635e-05,
      "loss": 1.2737,
      "step": 45400
    },
    {
      "epoch": 0.1416518885360145,
      "grad_norm": 1.0306389331817627,
      "learning_rate": 4.763991435436971e-05,
      "loss": 1.2967,
      "step": 45450
    },
    {
      "epoch": 0.14180772119667018,
      "grad_norm": 0.6288632154464722,
      "learning_rate": 4.763731714335878e-05,
      "loss": 1.274,
      "step": 45500
    },
    {
      "epoch": 0.14196355385732584,
      "grad_norm": 0.6862047910690308,
      "learning_rate": 4.7634719932347846e-05,
      "loss": 1.2857,
      "step": 45550
    },
    {
      "epoch": 0.14211938651798153,
      "grad_norm": 0.6466913223266602,
      "learning_rate": 4.763212272133692e-05,
      "loss": 1.2605,
      "step": 45600
    },
    {
      "epoch": 0.14227521917863722,
      "grad_norm": 0.44355010986328125,
      "learning_rate": 4.7629525510326e-05,
      "loss": 1.2609,
      "step": 45650
    },
    {
      "epoch": 0.1424310518392929,
      "grad_norm": 0.5979684591293335,
      "learning_rate": 4.762692829931506e-05,
      "loss": 1.3904,
      "step": 45700
    },
    {
      "epoch": 0.14258688449994858,
      "grad_norm": 0.6139285564422607,
      "learning_rate": 4.7624331088304136e-05,
      "loss": 1.3007,
      "step": 45750
    },
    {
      "epoch": 0.14274271716060424,
      "grad_norm": 0.7001574635505676,
      "learning_rate": 4.7621733877293215e-05,
      "loss": 1.2474,
      "step": 45800
    },
    {
      "epoch": 0.14289854982125993,
      "grad_norm": 0.5156061053276062,
      "learning_rate": 4.761913666628228e-05,
      "loss": 1.2905,
      "step": 45850
    },
    {
      "epoch": 0.14305438248191563,
      "grad_norm": 0.6082873344421387,
      "learning_rate": 4.761653945527135e-05,
      "loss": 1.2814,
      "step": 45900
    },
    {
      "epoch": 0.1432102151425713,
      "grad_norm": 0.5992400050163269,
      "learning_rate": 4.7613942244260426e-05,
      "loss": 1.2918,
      "step": 45950
    },
    {
      "epoch": 0.14336604780322698,
      "grad_norm": 0.6718001961708069,
      "learning_rate": 4.76113450332495e-05,
      "loss": 1.2228,
      "step": 46000
    },
    {
      "epoch": 0.14352188046388267,
      "grad_norm": 0.6390703916549683,
      "learning_rate": 4.760874782223857e-05,
      "loss": 1.348,
      "step": 46050
    },
    {
      "epoch": 0.14367771312453834,
      "grad_norm": 0.6935913562774658,
      "learning_rate": 4.760615061122764e-05,
      "loss": 1.341,
      "step": 46100
    },
    {
      "epoch": 0.14383354578519403,
      "grad_norm": 0.5469261407852173,
      "learning_rate": 4.7603553400216716e-05,
      "loss": 1.3196,
      "step": 46150
    },
    {
      "epoch": 0.14398937844584972,
      "grad_norm": 0.497283399105072,
      "learning_rate": 4.760095618920579e-05,
      "loss": 1.277,
      "step": 46200
    },
    {
      "epoch": 0.14414521110650538,
      "grad_norm": 0.5855477452278137,
      "learning_rate": 4.7598358978194854e-05,
      "loss": 1.2888,
      "step": 46250
    },
    {
      "epoch": 0.14430104376716107,
      "grad_norm": 0.6780020594596863,
      "learning_rate": 4.7595761767183926e-05,
      "loss": 1.3435,
      "step": 46300
    },
    {
      "epoch": 0.14445687642781677,
      "grad_norm": 0.631712794303894,
      "learning_rate": 4.7593164556173006e-05,
      "loss": 1.2982,
      "step": 46350
    },
    {
      "epoch": 0.14461270908847243,
      "grad_norm": 0.629278838634491,
      "learning_rate": 4.759056734516207e-05,
      "loss": 1.2163,
      "step": 46400
    },
    {
      "epoch": 0.14476854174912812,
      "grad_norm": 0.5930646657943726,
      "learning_rate": 4.7587970134151144e-05,
      "loss": 1.3104,
      "step": 46450
    },
    {
      "epoch": 0.14492437440978378,
      "grad_norm": 0.5432794690132141,
      "learning_rate": 4.758537292314022e-05,
      "loss": 1.3126,
      "step": 46500
    },
    {
      "epoch": 0.14508020707043948,
      "grad_norm": 0.6498282551765442,
      "learning_rate": 4.758277571212929e-05,
      "loss": 1.3508,
      "step": 46550
    },
    {
      "epoch": 0.14523603973109517,
      "grad_norm": 0.6671502590179443,
      "learning_rate": 4.758017850111836e-05,
      "loss": 1.2987,
      "step": 46600
    },
    {
      "epoch": 0.14539187239175083,
      "grad_norm": 0.6619839072227478,
      "learning_rate": 4.7577581290107434e-05,
      "loss": 1.3545,
      "step": 46650
    },
    {
      "epoch": 0.14554770505240652,
      "grad_norm": 0.5610492825508118,
      "learning_rate": 4.7574984079096506e-05,
      "loss": 1.2768,
      "step": 46700
    },
    {
      "epoch": 0.14570353771306221,
      "grad_norm": 0.5148947238922119,
      "learning_rate": 4.757238686808558e-05,
      "loss": 1.3472,
      "step": 46750
    },
    {
      "epoch": 0.14585937037371788,
      "grad_norm": 0.6535899639129639,
      "learning_rate": 4.756978965707465e-05,
      "loss": 1.236,
      "step": 46800
    },
    {
      "epoch": 0.14601520303437357,
      "grad_norm": 0.716399610042572,
      "learning_rate": 4.756719244606372e-05,
      "loss": 1.3596,
      "step": 46850
    },
    {
      "epoch": 0.14617103569502926,
      "grad_norm": 0.5054202079772949,
      "learning_rate": 4.7564595235052796e-05,
      "loss": 1.2714,
      "step": 46900
    },
    {
      "epoch": 0.14632686835568492,
      "grad_norm": 0.6806410551071167,
      "learning_rate": 4.756199802404186e-05,
      "loss": 1.2655,
      "step": 46950
    },
    {
      "epoch": 0.14648270101634062,
      "grad_norm": 0.6615918874740601,
      "learning_rate": 4.7559400813030935e-05,
      "loss": 1.3279,
      "step": 47000
    },
    {
      "epoch": 0.1466385336769963,
      "grad_norm": 0.5518030524253845,
      "learning_rate": 4.7556803602020014e-05,
      "loss": 1.2662,
      "step": 47050
    },
    {
      "epoch": 0.14679436633765197,
      "grad_norm": 0.7467600703239441,
      "learning_rate": 4.75542583352293e-05,
      "loss": 1.3342,
      "step": 47100
    },
    {
      "epoch": 0.14695019899830766,
      "grad_norm": 0.7006278038024902,
      "learning_rate": 4.755166112421837e-05,
      "loss": 1.3333,
      "step": 47150
    },
    {
      "epoch": 0.14710603165896333,
      "grad_norm": 0.748554527759552,
      "learning_rate": 4.7549063913207444e-05,
      "loss": 1.2765,
      "step": 47200
    },
    {
      "epoch": 0.14726186431961902,
      "grad_norm": 0.5702926516532898,
      "learning_rate": 4.754646670219652e-05,
      "loss": 1.2998,
      "step": 47250
    },
    {
      "epoch": 0.1474176969802747,
      "grad_norm": 0.7072381973266602,
      "learning_rate": 4.754386949118559e-05,
      "loss": 1.2935,
      "step": 47300
    },
    {
      "epoch": 0.14757352964093037,
      "grad_norm": 0.5056155323982239,
      "learning_rate": 4.754127228017466e-05,
      "loss": 1.2518,
      "step": 47350
    },
    {
      "epoch": 0.14772936230158606,
      "grad_norm": 0.7123218774795532,
      "learning_rate": 4.753867506916373e-05,
      "loss": 1.3274,
      "step": 47400
    },
    {
      "epoch": 0.14788519496224176,
      "grad_norm": 0.5381593704223633,
      "learning_rate": 4.753607785815281e-05,
      "loss": 1.2138,
      "step": 47450
    },
    {
      "epoch": 0.14804102762289742,
      "grad_norm": 0.6295660734176636,
      "learning_rate": 4.753348064714187e-05,
      "loss": 1.2946,
      "step": 47500
    },
    {
      "epoch": 0.1481968602835531,
      "grad_norm": 0.6624152660369873,
      "learning_rate": 4.7530883436130945e-05,
      "loss": 1.3117,
      "step": 47550
    },
    {
      "epoch": 0.1483526929442088,
      "grad_norm": 0.461669921875,
      "learning_rate": 4.752828622512002e-05,
      "loss": 1.2501,
      "step": 47600
    },
    {
      "epoch": 0.14850852560486447,
      "grad_norm": 0.7476308345794678,
      "learning_rate": 4.752568901410909e-05,
      "loss": 1.3033,
      "step": 47650
    },
    {
      "epoch": 0.14866435826552016,
      "grad_norm": 0.5894016027450562,
      "learning_rate": 4.752309180309816e-05,
      "loss": 1.2955,
      "step": 47700
    },
    {
      "epoch": 0.14882019092617582,
      "grad_norm": 0.5479288697242737,
      "learning_rate": 4.7520494592087235e-05,
      "loss": 1.3109,
      "step": 47750
    },
    {
      "epoch": 0.1489760235868315,
      "grad_norm": 0.6771673560142517,
      "learning_rate": 4.751789738107631e-05,
      "loss": 1.2525,
      "step": 47800
    },
    {
      "epoch": 0.1491318562474872,
      "grad_norm": 0.6551806330680847,
      "learning_rate": 4.751530017006538e-05,
      "loss": 1.2812,
      "step": 47850
    },
    {
      "epoch": 0.14928768890814287,
      "grad_norm": 0.5975406169891357,
      "learning_rate": 4.751270295905445e-05,
      "loss": 1.3285,
      "step": 47900
    },
    {
      "epoch": 0.14944352156879856,
      "grad_norm": 0.7483738660812378,
      "learning_rate": 4.751010574804352e-05,
      "loss": 1.3364,
      "step": 47950
    },
    {
      "epoch": 0.14959935422945425,
      "grad_norm": 0.7158468961715698,
      "learning_rate": 4.75075085370326e-05,
      "loss": 1.3399,
      "step": 48000
    },
    {
      "epoch": 0.14975518689010991,
      "grad_norm": 0.526233434677124,
      "learning_rate": 4.750491132602167e-05,
      "loss": 1.2677,
      "step": 48050
    },
    {
      "epoch": 0.1499110195507656,
      "grad_norm": 0.7907243967056274,
      "learning_rate": 4.7502314115010736e-05,
      "loss": 1.2429,
      "step": 48100
    },
    {
      "epoch": 0.1500668522114213,
      "grad_norm": 0.49132493138313293,
      "learning_rate": 4.7499716903999815e-05,
      "loss": 1.3135,
      "step": 48150
    },
    {
      "epoch": 0.15022268487207696,
      "grad_norm": 0.7562090754508972,
      "learning_rate": 4.749711969298888e-05,
      "loss": 1.2948,
      "step": 48200
    },
    {
      "epoch": 0.15037851753273265,
      "grad_norm": 0.8394302129745483,
      "learning_rate": 4.749452248197795e-05,
      "loss": 1.3507,
      "step": 48250
    },
    {
      "epoch": 0.15053435019338834,
      "grad_norm": 0.5934147238731384,
      "learning_rate": 4.7491925270967026e-05,
      "loss": 1.3175,
      "step": 48300
    },
    {
      "epoch": 0.150690182854044,
      "grad_norm": 0.6099887490272522,
      "learning_rate": 4.74893280599561e-05,
      "loss": 1.2897,
      "step": 48350
    },
    {
      "epoch": 0.1508460155146997,
      "grad_norm": 0.49642619490623474,
      "learning_rate": 4.748673084894517e-05,
      "loss": 1.3421,
      "step": 48400
    },
    {
      "epoch": 0.15100184817535536,
      "grad_norm": 0.6047653555870056,
      "learning_rate": 4.748413363793424e-05,
      "loss": 1.2742,
      "step": 48450
    },
    {
      "epoch": 0.15115768083601105,
      "grad_norm": 0.6022976040840149,
      "learning_rate": 4.7481536426923316e-05,
      "loss": 1.2742,
      "step": 48500
    },
    {
      "epoch": 0.15131351349666675,
      "grad_norm": 0.6360905170440674,
      "learning_rate": 4.747893921591239e-05,
      "loss": 1.3057,
      "step": 48550
    },
    {
      "epoch": 0.1514693461573224,
      "grad_norm": 0.551357090473175,
      "learning_rate": 4.747634200490146e-05,
      "loss": 1.2872,
      "step": 48600
    },
    {
      "epoch": 0.1516251788179781,
      "grad_norm": 0.6255840063095093,
      "learning_rate": 4.7473744793890527e-05,
      "loss": 1.3019,
      "step": 48650
    },
    {
      "epoch": 0.1517810114786338,
      "grad_norm": 0.6032414436340332,
      "learning_rate": 4.747119952709982e-05,
      "loss": 1.2696,
      "step": 48700
    },
    {
      "epoch": 0.15193684413928946,
      "grad_norm": 0.5515727996826172,
      "learning_rate": 4.74686023160889e-05,
      "loss": 1.2824,
      "step": 48750
    },
    {
      "epoch": 0.15209267679994515,
      "grad_norm": 0.520797073841095,
      "learning_rate": 4.7466005105077964e-05,
      "loss": 1.3204,
      "step": 48800
    },
    {
      "epoch": 0.15224850946060084,
      "grad_norm": 0.6213647723197937,
      "learning_rate": 4.7463407894067036e-05,
      "loss": 1.3306,
      "step": 48850
    },
    {
      "epoch": 0.1524043421212565,
      "grad_norm": 0.544164776802063,
      "learning_rate": 4.746081068305611e-05,
      "loss": 1.2429,
      "step": 48900
    },
    {
      "epoch": 0.1525601747819122,
      "grad_norm": 0.523759126663208,
      "learning_rate": 4.745821347204518e-05,
      "loss": 1.2291,
      "step": 48950
    },
    {
      "epoch": 0.15271600744256789,
      "grad_norm": 0.7201810479164124,
      "learning_rate": 4.7455616261034254e-05,
      "loss": 1.3042,
      "step": 49000
    },
    {
      "epoch": 0.15287184010322355,
      "grad_norm": 0.6231229901313782,
      "learning_rate": 4.7453019050023326e-05,
      "loss": 1.3077,
      "step": 49050
    },
    {
      "epoch": 0.15302767276387924,
      "grad_norm": 0.6407829523086548,
      "learning_rate": 4.74504218390124e-05,
      "loss": 1.2665,
      "step": 49100
    },
    {
      "epoch": 0.1531835054245349,
      "grad_norm": 0.5942546725273132,
      "learning_rate": 4.744782462800147e-05,
      "loss": 1.2979,
      "step": 49150
    },
    {
      "epoch": 0.1533393380851906,
      "grad_norm": 0.5979925394058228,
      "learning_rate": 4.744522741699054e-05,
      "loss": 1.2374,
      "step": 49200
    },
    {
      "epoch": 0.1534951707458463,
      "grad_norm": 0.6734188795089722,
      "learning_rate": 4.7442630205979616e-05,
      "loss": 1.3095,
      "step": 49250
    },
    {
      "epoch": 0.15365100340650195,
      "grad_norm": 0.6103375554084778,
      "learning_rate": 4.744003299496869e-05,
      "loss": 1.2826,
      "step": 49300
    },
    {
      "epoch": 0.15380683606715764,
      "grad_norm": 0.5991376638412476,
      "learning_rate": 4.7437435783957754e-05,
      "loss": 1.2649,
      "step": 49350
    },
    {
      "epoch": 0.15396266872781333,
      "grad_norm": 0.7735300660133362,
      "learning_rate": 4.743483857294683e-05,
      "loss": 1.3173,
      "step": 49400
    },
    {
      "epoch": 0.154118501388469,
      "grad_norm": 0.6168805360794067,
      "learning_rate": 4.7432241361935906e-05,
      "loss": 1.3437,
      "step": 49450
    },
    {
      "epoch": 0.1542743340491247,
      "grad_norm": 0.5506919026374817,
      "learning_rate": 4.742964415092497e-05,
      "loss": 1.2792,
      "step": 49500
    },
    {
      "epoch": 0.15443016670978038,
      "grad_norm": 0.65177983045578,
      "learning_rate": 4.7427046939914044e-05,
      "loss": 1.2938,
      "step": 49550
    },
    {
      "epoch": 0.15458599937043604,
      "grad_norm": 0.6306948661804199,
      "learning_rate": 4.742444972890312e-05,
      "loss": 1.301,
      "step": 49600
    },
    {
      "epoch": 0.15474183203109174,
      "grad_norm": 0.6506693363189697,
      "learning_rate": 4.742185251789219e-05,
      "loss": 1.3025,
      "step": 49650
    },
    {
      "epoch": 0.15489766469174743,
      "grad_norm": 0.6562357544898987,
      "learning_rate": 4.741925530688126e-05,
      "loss": 1.3146,
      "step": 49700
    },
    {
      "epoch": 0.1550534973524031,
      "grad_norm": 0.5832184553146362,
      "learning_rate": 4.741665809587033e-05,
      "loss": 1.2902,
      "step": 49750
    },
    {
      "epoch": 0.15520933001305878,
      "grad_norm": 0.6198565363883972,
      "learning_rate": 4.741406088485941e-05,
      "loss": 1.3143,
      "step": 49800
    },
    {
      "epoch": 0.15536516267371445,
      "grad_norm": 0.6375946402549744,
      "learning_rate": 4.741146367384848e-05,
      "loss": 1.25,
      "step": 49850
    },
    {
      "epoch": 0.15552099533437014,
      "grad_norm": 0.7925576567649841,
      "learning_rate": 4.7408866462837545e-05,
      "loss": 1.2343,
      "step": 49900
    },
    {
      "epoch": 0.15567682799502583,
      "grad_norm": 0.5241273045539856,
      "learning_rate": 4.740626925182662e-05,
      "loss": 1.3047,
      "step": 49950
    },
    {
      "epoch": 0.1558326606556815,
      "grad_norm": 0.6378611326217651,
      "learning_rate": 4.74036720408157e-05,
      "loss": 1.3249,
      "step": 50000
    },
    {
      "epoch": 0.15598849331633718,
      "grad_norm": 0.6073411107063293,
      "learning_rate": 4.740107482980476e-05,
      "loss": 1.3362,
      "step": 50050
    },
    {
      "epoch": 0.15614432597699288,
      "grad_norm": 0.6360065937042236,
      "learning_rate": 4.7398477618793835e-05,
      "loss": 1.2765,
      "step": 50100
    },
    {
      "epoch": 0.15630015863764854,
      "grad_norm": 0.4784819781780243,
      "learning_rate": 4.739588040778291e-05,
      "loss": 1.2834,
      "step": 50150
    },
    {
      "epoch": 0.15645599129830423,
      "grad_norm": 0.6639899015426636,
      "learning_rate": 4.739328319677198e-05,
      "loss": 1.3134,
      "step": 50200
    },
    {
      "epoch": 0.15661182395895992,
      "grad_norm": 0.565961480140686,
      "learning_rate": 4.739068598576105e-05,
      "loss": 1.2494,
      "step": 50250
    },
    {
      "epoch": 0.1567676566196156,
      "grad_norm": 0.6243980526924133,
      "learning_rate": 4.7388088774750125e-05,
      "loss": 1.3138,
      "step": 50300
    },
    {
      "epoch": 0.15692348928027128,
      "grad_norm": 0.5265403389930725,
      "learning_rate": 4.73854915637392e-05,
      "loss": 1.3218,
      "step": 50350
    },
    {
      "epoch": 0.15707932194092694,
      "grad_norm": 0.5159313678741455,
      "learning_rate": 4.738289435272827e-05,
      "loss": 1.2397,
      "step": 50400
    },
    {
      "epoch": 0.15723515460158263,
      "grad_norm": 0.5974559187889099,
      "learning_rate": 4.7380297141717336e-05,
      "loss": 1.3008,
      "step": 50450
    },
    {
      "epoch": 0.15739098726223832,
      "grad_norm": 0.5885030627250671,
      "learning_rate": 4.7377699930706415e-05,
      "loss": 1.3078,
      "step": 50500
    },
    {
      "epoch": 0.157546819922894,
      "grad_norm": 0.592151939868927,
      "learning_rate": 4.737510271969549e-05,
      "loss": 1.3624,
      "step": 50550
    },
    {
      "epoch": 0.15770265258354968,
      "grad_norm": 0.58753502368927,
      "learning_rate": 4.7372505508684553e-05,
      "loss": 1.319,
      "step": 50600
    },
    {
      "epoch": 0.15785848524420537,
      "grad_norm": 0.6585125923156738,
      "learning_rate": 4.7369908297673626e-05,
      "loss": 1.2259,
      "step": 50650
    },
    {
      "epoch": 0.15801431790486103,
      "grad_norm": 0.5793206691741943,
      "learning_rate": 4.7367311086662705e-05,
      "loss": 1.2308,
      "step": 50700
    },
    {
      "epoch": 0.15817015056551673,
      "grad_norm": 0.5937303304672241,
      "learning_rate": 4.736471387565177e-05,
      "loss": 1.3012,
      "step": 50750
    },
    {
      "epoch": 0.15832598322617242,
      "grad_norm": 0.6383602023124695,
      "learning_rate": 4.7362116664640844e-05,
      "loss": 1.2795,
      "step": 50800
    },
    {
      "epoch": 0.15848181588682808,
      "grad_norm": 0.6071351170539856,
      "learning_rate": 4.7359519453629916e-05,
      "loss": 1.2741,
      "step": 50850
    },
    {
      "epoch": 0.15863764854748377,
      "grad_norm": 0.4669966399669647,
      "learning_rate": 4.735692224261899e-05,
      "loss": 1.3153,
      "step": 50900
    },
    {
      "epoch": 0.15879348120813946,
      "grad_norm": 0.4810694754123688,
      "learning_rate": 4.735432503160806e-05,
      "loss": 1.2926,
      "step": 50950
    },
    {
      "epoch": 0.15894931386879513,
      "grad_norm": 0.5982159972190857,
      "learning_rate": 4.7351727820597134e-05,
      "loss": 1.3164,
      "step": 51000
    },
    {
      "epoch": 0.15910514652945082,
      "grad_norm": 0.6321678161621094,
      "learning_rate": 4.7349130609586206e-05,
      "loss": 1.248,
      "step": 51050
    },
    {
      "epoch": 0.15926097919010648,
      "grad_norm": 0.664496660232544,
      "learning_rate": 4.734653339857528e-05,
      "loss": 1.2982,
      "step": 51100
    },
    {
      "epoch": 0.15941681185076217,
      "grad_norm": 0.6804054379463196,
      "learning_rate": 4.7343936187564344e-05,
      "loss": 1.2199,
      "step": 51150
    },
    {
      "epoch": 0.15957264451141787,
      "grad_norm": 0.5332902669906616,
      "learning_rate": 4.734133897655342e-05,
      "loss": 1.3142,
      "step": 51200
    },
    {
      "epoch": 0.15972847717207353,
      "grad_norm": 0.4563589096069336,
      "learning_rate": 4.7338741765542496e-05,
      "loss": 1.2966,
      "step": 51250
    },
    {
      "epoch": 0.15988430983272922,
      "grad_norm": 0.6743607521057129,
      "learning_rate": 4.733614455453156e-05,
      "loss": 1.2759,
      "step": 51300
    },
    {
      "epoch": 0.1600401424933849,
      "grad_norm": 0.7027798295021057,
      "learning_rate": 4.7333547343520634e-05,
      "loss": 1.2976,
      "step": 51350
    },
    {
      "epoch": 0.16019597515404058,
      "grad_norm": 0.5894086360931396,
      "learning_rate": 4.7330950132509714e-05,
      "loss": 1.2721,
      "step": 51400
    },
    {
      "epoch": 0.16035180781469627,
      "grad_norm": 0.7255103588104248,
      "learning_rate": 4.732835292149878e-05,
      "loss": 1.2995,
      "step": 51450
    },
    {
      "epoch": 0.16050764047535196,
      "grad_norm": 0.631500780582428,
      "learning_rate": 4.732575571048785e-05,
      "loss": 1.2828,
      "step": 51500
    },
    {
      "epoch": 0.16066347313600762,
      "grad_norm": 0.7047225832939148,
      "learning_rate": 4.7323158499476924e-05,
      "loss": 1.2995,
      "step": 51550
    },
    {
      "epoch": 0.16081930579666331,
      "grad_norm": 0.5260810852050781,
      "learning_rate": 4.7320561288466e-05,
      "loss": 1.3346,
      "step": 51600
    },
    {
      "epoch": 0.160975138457319,
      "grad_norm": 0.5934505462646484,
      "learning_rate": 4.731796407745507e-05,
      "loss": 1.2494,
      "step": 51650
    },
    {
      "epoch": 0.16113097111797467,
      "grad_norm": 0.6663302183151245,
      "learning_rate": 4.731536686644414e-05,
      "loss": 1.2597,
      "step": 51700
    },
    {
      "epoch": 0.16128680377863036,
      "grad_norm": 0.6263468861579895,
      "learning_rate": 4.7312769655433214e-05,
      "loss": 1.182,
      "step": 51750
    },
    {
      "epoch": 0.16144263643928602,
      "grad_norm": 0.5685796141624451,
      "learning_rate": 4.731017244442229e-05,
      "loss": 1.3038,
      "step": 51800
    },
    {
      "epoch": 0.16159846909994172,
      "grad_norm": 0.5558069944381714,
      "learning_rate": 4.730757523341135e-05,
      "loss": 1.3132,
      "step": 51850
    },
    {
      "epoch": 0.1617543017605974,
      "grad_norm": 0.5868362188339233,
      "learning_rate": 4.7304978022400425e-05,
      "loss": 1.2622,
      "step": 51900
    },
    {
      "epoch": 0.16191013442125307,
      "grad_norm": 0.5877620577812195,
      "learning_rate": 4.7302380811389504e-05,
      "loss": 1.269,
      "step": 51950
    },
    {
      "epoch": 0.16206596708190876,
      "grad_norm": 0.5977360606193542,
      "learning_rate": 4.729978360037857e-05,
      "loss": 1.2879,
      "step": 52000
    },
    {
      "epoch": 0.16222179974256445,
      "grad_norm": 0.6452680826187134,
      "learning_rate": 4.729718638936764e-05,
      "loss": 1.3048,
      "step": 52050
    },
    {
      "epoch": 0.16237763240322012,
      "grad_norm": 0.6917064189910889,
      "learning_rate": 4.7294589178356715e-05,
      "loss": 1.3434,
      "step": 52100
    },
    {
      "epoch": 0.1625334650638758,
      "grad_norm": 0.560120165348053,
      "learning_rate": 4.729199196734579e-05,
      "loss": 1.3113,
      "step": 52150
    },
    {
      "epoch": 0.1626892977245315,
      "grad_norm": 0.6354068517684937,
      "learning_rate": 4.728939475633486e-05,
      "loss": 1.3326,
      "step": 52200
    },
    {
      "epoch": 0.16284513038518716,
      "grad_norm": 0.531467080116272,
      "learning_rate": 4.728679754532393e-05,
      "loss": 1.2942,
      "step": 52250
    },
    {
      "epoch": 0.16300096304584286,
      "grad_norm": 0.5961429476737976,
      "learning_rate": 4.7284200334313005e-05,
      "loss": 1.3128,
      "step": 52300
    },
    {
      "epoch": 0.16315679570649855,
      "grad_norm": 0.5652366280555725,
      "learning_rate": 4.728160312330208e-05,
      "loss": 1.3495,
      "step": 52350
    },
    {
      "epoch": 0.1633126283671542,
      "grad_norm": 0.6784855723381042,
      "learning_rate": 4.727900591229114e-05,
      "loss": 1.2645,
      "step": 52400
    },
    {
      "epoch": 0.1634684610278099,
      "grad_norm": 0.5327118039131165,
      "learning_rate": 4.7276408701280216e-05,
      "loss": 1.2679,
      "step": 52450
    },
    {
      "epoch": 0.16362429368846557,
      "grad_norm": 0.5225902795791626,
      "learning_rate": 4.7273811490269295e-05,
      "loss": 1.2567,
      "step": 52500
    },
    {
      "epoch": 0.16378012634912126,
      "grad_norm": 0.4770641326904297,
      "learning_rate": 4.727121427925836e-05,
      "loss": 1.2611,
      "step": 52550
    },
    {
      "epoch": 0.16393595900977695,
      "grad_norm": 0.7698712944984436,
      "learning_rate": 4.726861706824743e-05,
      "loss": 1.2859,
      "step": 52600
    },
    {
      "epoch": 0.1640917916704326,
      "grad_norm": 0.5703412890434265,
      "learning_rate": 4.726601985723651e-05,
      "loss": 1.3186,
      "step": 52650
    },
    {
      "epoch": 0.1642476243310883,
      "grad_norm": 0.56523597240448,
      "learning_rate": 4.726342264622558e-05,
      "loss": 1.3296,
      "step": 52700
    },
    {
      "epoch": 0.164403456991744,
      "grad_norm": 0.729796826839447,
      "learning_rate": 4.726082543521465e-05,
      "loss": 1.3136,
      "step": 52750
    },
    {
      "epoch": 0.16455928965239966,
      "grad_norm": 0.5407925844192505,
      "learning_rate": 4.725822822420372e-05,
      "loss": 1.2829,
      "step": 52800
    },
    {
      "epoch": 0.16471512231305535,
      "grad_norm": 0.7108252048492432,
      "learning_rate": 4.7255631013192796e-05,
      "loss": 1.2915,
      "step": 52850
    },
    {
      "epoch": 0.16487095497371104,
      "grad_norm": 0.5285722017288208,
      "learning_rate": 4.725303380218187e-05,
      "loss": 1.2813,
      "step": 52900
    },
    {
      "epoch": 0.1650267876343667,
      "grad_norm": 0.7689785361289978,
      "learning_rate": 4.725043659117094e-05,
      "loss": 1.2504,
      "step": 52950
    },
    {
      "epoch": 0.1651826202950224,
      "grad_norm": 0.4969322979450226,
      "learning_rate": 4.724783938016001e-05,
      "loss": 1.2731,
      "step": 53000
    },
    {
      "epoch": 0.16533845295567806,
      "grad_norm": 0.5848227739334106,
      "learning_rate": 4.7245242169149086e-05,
      "loss": 1.2999,
      "step": 53050
    },
    {
      "epoch": 0.16549428561633375,
      "grad_norm": 0.5453819036483765,
      "learning_rate": 4.724264495813815e-05,
      "loss": 1.2221,
      "step": 53100
    },
    {
      "epoch": 0.16565011827698944,
      "grad_norm": 0.6185139417648315,
      "learning_rate": 4.7240047747127224e-05,
      "loss": 1.265,
      "step": 53150
    },
    {
      "epoch": 0.1658059509376451,
      "grad_norm": 0.6024397611618042,
      "learning_rate": 4.72374505361163e-05,
      "loss": 1.3331,
      "step": 53200
    },
    {
      "epoch": 0.1659617835983008,
      "grad_norm": 0.4431383013725281,
      "learning_rate": 4.723485332510537e-05,
      "loss": 1.2798,
      "step": 53250
    },
    {
      "epoch": 0.1661176162589565,
      "grad_norm": 0.605276882648468,
      "learning_rate": 4.723225611409444e-05,
      "loss": 1.3355,
      "step": 53300
    },
    {
      "epoch": 0.16627344891961215,
      "grad_norm": 0.5784716010093689,
      "learning_rate": 4.7229658903083514e-05,
      "loss": 1.2687,
      "step": 53350
    },
    {
      "epoch": 0.16642928158026785,
      "grad_norm": 0.6234331727027893,
      "learning_rate": 4.7227061692072587e-05,
      "loss": 1.34,
      "step": 53400
    },
    {
      "epoch": 0.16658511424092354,
      "grad_norm": 0.553568959236145,
      "learning_rate": 4.722446448106166e-05,
      "loss": 1.2785,
      "step": 53450
    },
    {
      "epoch": 0.1667409469015792,
      "grad_norm": 0.47208699584007263,
      "learning_rate": 4.722186727005073e-05,
      "loss": 1.3165,
      "step": 53500
    },
    {
      "epoch": 0.1668967795622349,
      "grad_norm": 0.7031481266021729,
      "learning_rate": 4.7219270059039804e-05,
      "loss": 1.2737,
      "step": 53550
    },
    {
      "epoch": 0.16705261222289058,
      "grad_norm": 0.6212272644042969,
      "learning_rate": 4.7216672848028877e-05,
      "loss": 1.3033,
      "step": 53600
    },
    {
      "epoch": 0.16720844488354625,
      "grad_norm": 0.7215019464492798,
      "learning_rate": 4.721407563701795e-05,
      "loss": 1.3365,
      "step": 53650
    },
    {
      "epoch": 0.16736427754420194,
      "grad_norm": 0.6680421829223633,
      "learning_rate": 4.7211478426007015e-05,
      "loss": 1.2741,
      "step": 53700
    },
    {
      "epoch": 0.1675201102048576,
      "grad_norm": 0.5331757664680481,
      "learning_rate": 4.7208881214996094e-05,
      "loss": 1.2606,
      "step": 53750
    },
    {
      "epoch": 0.1676759428655133,
      "grad_norm": 0.6193802952766418,
      "learning_rate": 4.720628400398516e-05,
      "loss": 1.3097,
      "step": 53800
    },
    {
      "epoch": 0.16783177552616899,
      "grad_norm": 0.6230438351631165,
      "learning_rate": 4.720368679297423e-05,
      "loss": 1.2907,
      "step": 53850
    },
    {
      "epoch": 0.16798760818682465,
      "grad_norm": 0.7060507535934448,
      "learning_rate": 4.720108958196331e-05,
      "loss": 1.2449,
      "step": 53900
    },
    {
      "epoch": 0.16814344084748034,
      "grad_norm": 0.6673861145973206,
      "learning_rate": 4.719849237095238e-05,
      "loss": 1.3136,
      "step": 53950
    },
    {
      "epoch": 0.16829927350813603,
      "grad_norm": 0.68222576379776,
      "learning_rate": 4.719589515994145e-05,
      "loss": 1.3211,
      "step": 54000
    },
    {
      "epoch": 0.1684551061687917,
      "grad_norm": 0.7842297554016113,
      "learning_rate": 4.719329794893052e-05,
      "loss": 1.3064,
      "step": 54050
    },
    {
      "epoch": 0.1686109388294474,
      "grad_norm": 0.6245383024215698,
      "learning_rate": 4.7190700737919595e-05,
      "loss": 1.3797,
      "step": 54100
    },
    {
      "epoch": 0.16876677149010308,
      "grad_norm": 0.737577497959137,
      "learning_rate": 4.718810352690867e-05,
      "loss": 1.2703,
      "step": 54150
    },
    {
      "epoch": 0.16892260415075874,
      "grad_norm": 0.6095147132873535,
      "learning_rate": 4.718550631589774e-05,
      "loss": 1.2245,
      "step": 54200
    },
    {
      "epoch": 0.16907843681141443,
      "grad_norm": 0.5832446217536926,
      "learning_rate": 4.718290910488681e-05,
      "loss": 1.3105,
      "step": 54250
    },
    {
      "epoch": 0.16923426947207013,
      "grad_norm": 0.6300756931304932,
      "learning_rate": 4.7180311893875885e-05,
      "loss": 1.2529,
      "step": 54300
    },
    {
      "epoch": 0.1693901021327258,
      "grad_norm": 0.7226868867874146,
      "learning_rate": 4.717771468286496e-05,
      "loss": 1.3726,
      "step": 54350
    },
    {
      "epoch": 0.16954593479338148,
      "grad_norm": 0.5497592687606812,
      "learning_rate": 4.717511747185402e-05,
      "loss": 1.3057,
      "step": 54400
    },
    {
      "epoch": 0.16970176745403714,
      "grad_norm": 0.5992254018783569,
      "learning_rate": 4.71725202608431e-05,
      "loss": 1.2584,
      "step": 54450
    },
    {
      "epoch": 0.16985760011469284,
      "grad_norm": 0.5505867004394531,
      "learning_rate": 4.716992304983217e-05,
      "loss": 1.2852,
      "step": 54500
    },
    {
      "epoch": 0.17001343277534853,
      "grad_norm": 0.6675106883049011,
      "learning_rate": 4.716732583882124e-05,
      "loss": 1.2604,
      "step": 54550
    },
    {
      "epoch": 0.1701692654360042,
      "grad_norm": 0.6804835796356201,
      "learning_rate": 4.716483251625075e-05,
      "loss": 1.2962,
      "step": 54600
    },
    {
      "epoch": 0.17032509809665988,
      "grad_norm": 0.5279883146286011,
      "learning_rate": 4.716223530523982e-05,
      "loss": 1.2784,
      "step": 54650
    },
    {
      "epoch": 0.17048093075731557,
      "grad_norm": 0.5971202850341797,
      "learning_rate": 4.71596380942289e-05,
      "loss": 1.2252,
      "step": 54700
    },
    {
      "epoch": 0.17063676341797124,
      "grad_norm": 0.550841212272644,
      "learning_rate": 4.715704088321797e-05,
      "loss": 1.2721,
      "step": 54750
    },
    {
      "epoch": 0.17079259607862693,
      "grad_norm": 0.6309087872505188,
      "learning_rate": 4.7154443672207036e-05,
      "loss": 1.2954,
      "step": 54800
    },
    {
      "epoch": 0.17094842873928262,
      "grad_norm": 0.6179776191711426,
      "learning_rate": 4.7151846461196115e-05,
      "loss": 1.3511,
      "step": 54850
    },
    {
      "epoch": 0.17110426139993828,
      "grad_norm": 0.5271955132484436,
      "learning_rate": 4.714924925018519e-05,
      "loss": 1.2535,
      "step": 54900
    },
    {
      "epoch": 0.17126009406059398,
      "grad_norm": 0.6633601784706116,
      "learning_rate": 4.714665203917425e-05,
      "loss": 1.2825,
      "step": 54950
    },
    {
      "epoch": 0.17141592672124964,
      "grad_norm": 0.5820274353027344,
      "learning_rate": 4.7144054828163326e-05,
      "loss": 1.3176,
      "step": 55000
    },
    {
      "epoch": 0.17157175938190533,
      "grad_norm": 0.5209540128707886,
      "learning_rate": 4.71414576171524e-05,
      "loss": 1.3447,
      "step": 55050
    },
    {
      "epoch": 0.17172759204256102,
      "grad_norm": 0.5751566886901855,
      "learning_rate": 4.713886040614147e-05,
      "loss": 1.3136,
      "step": 55100
    },
    {
      "epoch": 0.1718834247032167,
      "grad_norm": 0.6558486819267273,
      "learning_rate": 4.713626319513054e-05,
      "loss": 1.2875,
      "step": 55150
    },
    {
      "epoch": 0.17203925736387238,
      "grad_norm": 0.5714756846427917,
      "learning_rate": 4.7133665984119616e-05,
      "loss": 1.2821,
      "step": 55200
    },
    {
      "epoch": 0.17219509002452807,
      "grad_norm": 0.4454645812511444,
      "learning_rate": 4.713106877310869e-05,
      "loss": 1.2816,
      "step": 55250
    },
    {
      "epoch": 0.17235092268518373,
      "grad_norm": 0.5003577470779419,
      "learning_rate": 4.712847156209776e-05,
      "loss": 1.2337,
      "step": 55300
    },
    {
      "epoch": 0.17250675534583942,
      "grad_norm": 0.6348138451576233,
      "learning_rate": 4.7125874351086826e-05,
      "loss": 1.3087,
      "step": 55350
    },
    {
      "epoch": 0.17266258800649512,
      "grad_norm": 0.6000345349311829,
      "learning_rate": 4.7123277140075906e-05,
      "loss": 1.3136,
      "step": 55400
    },
    {
      "epoch": 0.17281842066715078,
      "grad_norm": 0.5770976543426514,
      "learning_rate": 4.712067992906498e-05,
      "loss": 1.2848,
      "step": 55450
    },
    {
      "epoch": 0.17297425332780647,
      "grad_norm": 0.5976584553718567,
      "learning_rate": 4.7118082718054044e-05,
      "loss": 1.2564,
      "step": 55500
    },
    {
      "epoch": 0.17313008598846216,
      "grad_norm": 0.4788415729999542,
      "learning_rate": 4.7115485507043116e-05,
      "loss": 1.3459,
      "step": 55550
    },
    {
      "epoch": 0.17328591864911783,
      "grad_norm": 0.4703768491744995,
      "learning_rate": 4.7112888296032196e-05,
      "loss": 1.2858,
      "step": 55600
    },
    {
      "epoch": 0.17344175130977352,
      "grad_norm": 0.4698921740055084,
      "learning_rate": 4.711029108502126e-05,
      "loss": 1.3097,
      "step": 55650
    },
    {
      "epoch": 0.17359758397042918,
      "grad_norm": 0.5629891753196716,
      "learning_rate": 4.7107693874010334e-05,
      "loss": 1.3011,
      "step": 55700
    },
    {
      "epoch": 0.17375341663108487,
      "grad_norm": 0.6493116617202759,
      "learning_rate": 4.7105096662999406e-05,
      "loss": 1.3071,
      "step": 55750
    },
    {
      "epoch": 0.17390924929174056,
      "grad_norm": 0.48479267954826355,
      "learning_rate": 4.710249945198848e-05,
      "loss": 1.276,
      "step": 55800
    },
    {
      "epoch": 0.17406508195239623,
      "grad_norm": 0.9696296453475952,
      "learning_rate": 4.709990224097755e-05,
      "loss": 1.2595,
      "step": 55850
    },
    {
      "epoch": 0.17422091461305192,
      "grad_norm": 0.5265432000160217,
      "learning_rate": 4.7097305029966624e-05,
      "loss": 1.3095,
      "step": 55900
    },
    {
      "epoch": 0.1743767472737076,
      "grad_norm": 0.5796397924423218,
      "learning_rate": 4.7094707818955696e-05,
      "loss": 1.342,
      "step": 55950
    },
    {
      "epoch": 0.17453257993436327,
      "grad_norm": 0.7524457573890686,
      "learning_rate": 4.709211060794477e-05,
      "loss": 1.3127,
      "step": 56000
    },
    {
      "epoch": 0.17468841259501897,
      "grad_norm": 0.7153769135475159,
      "learning_rate": 4.7089513396933835e-05,
      "loss": 1.2983,
      "step": 56050
    },
    {
      "epoch": 0.17484424525567466,
      "grad_norm": 0.5242143869400024,
      "learning_rate": 4.7086916185922914e-05,
      "loss": 1.2663,
      "step": 56100
    },
    {
      "epoch": 0.17500007791633032,
      "grad_norm": 0.5622346997261047,
      "learning_rate": 4.7084318974911986e-05,
      "loss": 1.2721,
      "step": 56150
    },
    {
      "epoch": 0.175155910576986,
      "grad_norm": 0.536456286907196,
      "learning_rate": 4.708172176390105e-05,
      "loss": 1.2976,
      "step": 56200
    },
    {
      "epoch": 0.1753117432376417,
      "grad_norm": 0.5546011328697205,
      "learning_rate": 4.7079124552890125e-05,
      "loss": 1.3276,
      "step": 56250
    },
    {
      "epoch": 0.17546757589829737,
      "grad_norm": 0.528068482875824,
      "learning_rate": 4.7076527341879204e-05,
      "loss": 1.3021,
      "step": 56300
    },
    {
      "epoch": 0.17562340855895306,
      "grad_norm": 1.0322834253311157,
      "learning_rate": 4.707393013086827e-05,
      "loss": 1.3284,
      "step": 56350
    },
    {
      "epoch": 0.17577924121960872,
      "grad_norm": 0.6589359641075134,
      "learning_rate": 4.707133291985734e-05,
      "loss": 1.2876,
      "step": 56400
    },
    {
      "epoch": 0.17593507388026441,
      "grad_norm": 0.6678602695465088,
      "learning_rate": 4.7068735708846415e-05,
      "loss": 1.2927,
      "step": 56450
    },
    {
      "epoch": 0.1760909065409201,
      "grad_norm": 0.5709044337272644,
      "learning_rate": 4.706613849783549e-05,
      "loss": 1.3093,
      "step": 56500
    },
    {
      "epoch": 0.17624673920157577,
      "grad_norm": 0.6769551634788513,
      "learning_rate": 4.706354128682456e-05,
      "loss": 1.2624,
      "step": 56550
    },
    {
      "epoch": 0.17640257186223146,
      "grad_norm": 0.6009325981140137,
      "learning_rate": 4.706094407581363e-05,
      "loss": 1.2996,
      "step": 56600
    },
    {
      "epoch": 0.17655840452288715,
      "grad_norm": 0.5227594971656799,
      "learning_rate": 4.7058346864802705e-05,
      "loss": 1.3633,
      "step": 56650
    },
    {
      "epoch": 0.17671423718354282,
      "grad_norm": 0.5533131957054138,
      "learning_rate": 4.705574965379178e-05,
      "loss": 1.254,
      "step": 56700
    },
    {
      "epoch": 0.1768700698441985,
      "grad_norm": 0.5110976696014404,
      "learning_rate": 4.705315244278084e-05,
      "loss": 1.2804,
      "step": 56750
    },
    {
      "epoch": 0.1770259025048542,
      "grad_norm": 0.6988949775695801,
      "learning_rate": 4.7050555231769915e-05,
      "loss": 1.255,
      "step": 56800
    },
    {
      "epoch": 0.17718173516550986,
      "grad_norm": 1.1014723777770996,
      "learning_rate": 4.7047958020758995e-05,
      "loss": 1.353,
      "step": 56850
    },
    {
      "epoch": 0.17733756782616555,
      "grad_norm": 0.42577528953552246,
      "learning_rate": 4.704536080974806e-05,
      "loss": 1.2911,
      "step": 56900
    },
    {
      "epoch": 0.17749340048682125,
      "grad_norm": 0.6652510762214661,
      "learning_rate": 4.704276359873713e-05,
      "loss": 1.3362,
      "step": 56950
    },
    {
      "epoch": 0.1776492331474769,
      "grad_norm": 0.7359871864318848,
      "learning_rate": 4.704016638772621e-05,
      "loss": 1.3263,
      "step": 57000
    },
    {
      "epoch": 0.1778050658081326,
      "grad_norm": 0.5226501822471619,
      "learning_rate": 4.703756917671528e-05,
      "loss": 1.3103,
      "step": 57050
    },
    {
      "epoch": 0.17796089846878826,
      "grad_norm": 0.4817734360694885,
      "learning_rate": 4.703497196570435e-05,
      "loss": 1.2992,
      "step": 57100
    },
    {
      "epoch": 0.17811673112944396,
      "grad_norm": 0.695124626159668,
      "learning_rate": 4.703237475469342e-05,
      "loss": 1.2857,
      "step": 57150
    },
    {
      "epoch": 0.17827256379009965,
      "grad_norm": 0.6365607380867004,
      "learning_rate": 4.7029777543682495e-05,
      "loss": 1.3107,
      "step": 57200
    },
    {
      "epoch": 0.1784283964507553,
      "grad_norm": 0.47737324237823486,
      "learning_rate": 4.702718033267157e-05,
      "loss": 1.2345,
      "step": 57250
    },
    {
      "epoch": 0.178584229111411,
      "grad_norm": 0.52214515209198,
      "learning_rate": 4.7024583121660634e-05,
      "loss": 1.2795,
      "step": 57300
    },
    {
      "epoch": 0.1787400617720667,
      "grad_norm": 0.545793354511261,
      "learning_rate": 4.702198591064971e-05,
      "loss": 1.2627,
      "step": 57350
    },
    {
      "epoch": 0.17889589443272236,
      "grad_norm": 0.5430454611778259,
      "learning_rate": 4.7019388699638785e-05,
      "loss": 1.2275,
      "step": 57400
    },
    {
      "epoch": 0.17905172709337805,
      "grad_norm": 0.5432339906692505,
      "learning_rate": 4.701679148862785e-05,
      "loss": 1.2793,
      "step": 57450
    },
    {
      "epoch": 0.17920755975403374,
      "grad_norm": 0.6725878715515137,
      "learning_rate": 4.7014194277616924e-05,
      "loss": 1.2959,
      "step": 57500
    },
    {
      "epoch": 0.1793633924146894,
      "grad_norm": 0.6320638656616211,
      "learning_rate": 4.7011597066606e-05,
      "loss": 1.2601,
      "step": 57550
    },
    {
      "epoch": 0.1795192250753451,
      "grad_norm": 0.5129230618476868,
      "learning_rate": 4.700899985559507e-05,
      "loss": 1.306,
      "step": 57600
    },
    {
      "epoch": 0.17967505773600076,
      "grad_norm": 0.7840808033943176,
      "learning_rate": 4.700640264458414e-05,
      "loss": 1.3114,
      "step": 57650
    },
    {
      "epoch": 0.17983089039665645,
      "grad_norm": 0.4893730580806732,
      "learning_rate": 4.7003805433573214e-05,
      "loss": 1.2796,
      "step": 57700
    },
    {
      "epoch": 0.17998672305731214,
      "grad_norm": 0.5873516201972961,
      "learning_rate": 4.7001208222562286e-05,
      "loss": 1.2732,
      "step": 57750
    },
    {
      "epoch": 0.1801425557179678,
      "grad_norm": 0.6236594319343567,
      "learning_rate": 4.699861101155136e-05,
      "loss": 1.3082,
      "step": 57800
    },
    {
      "epoch": 0.1802983883786235,
      "grad_norm": 0.8165914416313171,
      "learning_rate": 4.699601380054043e-05,
      "loss": 1.3357,
      "step": 57850
    },
    {
      "epoch": 0.1804542210392792,
      "grad_norm": 0.6000475883483887,
      "learning_rate": 4.6993416589529504e-05,
      "loss": 1.2846,
      "step": 57900
    },
    {
      "epoch": 0.18061005369993485,
      "grad_norm": 0.6653291583061218,
      "learning_rate": 4.6990819378518576e-05,
      "loss": 1.3003,
      "step": 57950
    },
    {
      "epoch": 0.18076588636059054,
      "grad_norm": 0.613470733165741,
      "learning_rate": 4.698822216750764e-05,
      "loss": 1.3226,
      "step": 58000
    },
    {
      "epoch": 0.18092171902124624,
      "grad_norm": 0.4694667160511017,
      "learning_rate": 4.6985624956496714e-05,
      "loss": 1.2417,
      "step": 58050
    },
    {
      "epoch": 0.1810775516819019,
      "grad_norm": 0.5886856913566589,
      "learning_rate": 4.6983027745485794e-05,
      "loss": 1.3072,
      "step": 58100
    },
    {
      "epoch": 0.1812333843425576,
      "grad_norm": 0.6833328604698181,
      "learning_rate": 4.698043053447486e-05,
      "loss": 1.2924,
      "step": 58150
    },
    {
      "epoch": 0.18138921700321328,
      "grad_norm": 0.7099449634552002,
      "learning_rate": 4.697783332346393e-05,
      "loss": 1.3084,
      "step": 58200
    },
    {
      "epoch": 0.18154504966386895,
      "grad_norm": 0.5740602016448975,
      "learning_rate": 4.697523611245301e-05,
      "loss": 1.3076,
      "step": 58250
    },
    {
      "epoch": 0.18170088232452464,
      "grad_norm": 0.5194025635719299,
      "learning_rate": 4.697263890144208e-05,
      "loss": 1.2867,
      "step": 58300
    },
    {
      "epoch": 0.1818567149851803,
      "grad_norm": 0.5680169463157654,
      "learning_rate": 4.697004169043115e-05,
      "loss": 1.3025,
      "step": 58350
    },
    {
      "epoch": 0.182012547645836,
      "grad_norm": 0.4742376208305359,
      "learning_rate": 4.696744447942022e-05,
      "loss": 1.3269,
      "step": 58400
    },
    {
      "epoch": 0.18216838030649168,
      "grad_norm": 0.6269148588180542,
      "learning_rate": 4.6964847268409294e-05,
      "loss": 1.2496,
      "step": 58450
    },
    {
      "epoch": 0.18232421296714735,
      "grad_norm": 0.4865037202835083,
      "learning_rate": 4.696225005739837e-05,
      "loss": 1.2176,
      "step": 58500
    },
    {
      "epoch": 0.18248004562780304,
      "grad_norm": 0.6392529606819153,
      "learning_rate": 4.695965284638744e-05,
      "loss": 1.2816,
      "step": 58550
    },
    {
      "epoch": 0.18263587828845873,
      "grad_norm": 0.5653790831565857,
      "learning_rate": 4.6957107579596725e-05,
      "loss": 1.3278,
      "step": 58600
    },
    {
      "epoch": 0.1827917109491144,
      "grad_norm": 0.6262145042419434,
      "learning_rate": 4.6954510368585804e-05,
      "loss": 1.2705,
      "step": 58650
    },
    {
      "epoch": 0.18294754360977009,
      "grad_norm": 0.43185144662857056,
      "learning_rate": 4.695191315757487e-05,
      "loss": 1.3137,
      "step": 58700
    },
    {
      "epoch": 0.18310337627042578,
      "grad_norm": 0.5930753946304321,
      "learning_rate": 4.694931594656394e-05,
      "loss": 1.3109,
      "step": 58750
    },
    {
      "epoch": 0.18325920893108144,
      "grad_norm": 0.458350270986557,
      "learning_rate": 4.6946718735553015e-05,
      "loss": 1.2569,
      "step": 58800
    },
    {
      "epoch": 0.18341504159173713,
      "grad_norm": 0.6241365671157837,
      "learning_rate": 4.694412152454209e-05,
      "loss": 1.2142,
      "step": 58850
    },
    {
      "epoch": 0.18357087425239282,
      "grad_norm": 0.5335342884063721,
      "learning_rate": 4.694152431353116e-05,
      "loss": 1.3026,
      "step": 58900
    },
    {
      "epoch": 0.1837267069130485,
      "grad_norm": 0.602455735206604,
      "learning_rate": 4.693892710252023e-05,
      "loss": 1.3038,
      "step": 58950
    },
    {
      "epoch": 0.18388253957370418,
      "grad_norm": 0.6164147257804871,
      "learning_rate": 4.6936329891509305e-05,
      "loss": 1.2848,
      "step": 59000
    },
    {
      "epoch": 0.18403837223435984,
      "grad_norm": 0.5972850322723389,
      "learning_rate": 4.693373268049838e-05,
      "loss": 1.278,
      "step": 59050
    },
    {
      "epoch": 0.18419420489501553,
      "grad_norm": 0.5610015988349915,
      "learning_rate": 4.693113546948745e-05,
      "loss": 1.2828,
      "step": 59100
    },
    {
      "epoch": 0.18435003755567123,
      "grad_norm": 0.7036600112915039,
      "learning_rate": 4.6928538258476516e-05,
      "loss": 1.3009,
      "step": 59150
    },
    {
      "epoch": 0.1845058702163269,
      "grad_norm": 0.5208149552345276,
      "learning_rate": 4.6925941047465595e-05,
      "loss": 1.3066,
      "step": 59200
    },
    {
      "epoch": 0.18466170287698258,
      "grad_norm": 0.6510921716690063,
      "learning_rate": 4.692334383645467e-05,
      "loss": 1.2967,
      "step": 59250
    },
    {
      "epoch": 0.18481753553763827,
      "grad_norm": 0.6631600260734558,
      "learning_rate": 4.692074662544373e-05,
      "loss": 1.3074,
      "step": 59300
    },
    {
      "epoch": 0.18497336819829394,
      "grad_norm": 0.5808557271957397,
      "learning_rate": 4.691814941443281e-05,
      "loss": 1.2673,
      "step": 59350
    },
    {
      "epoch": 0.18512920085894963,
      "grad_norm": 0.5610140562057495,
      "learning_rate": 4.691555220342188e-05,
      "loss": 1.2694,
      "step": 59400
    },
    {
      "epoch": 0.18528503351960532,
      "grad_norm": 0.5310288667678833,
      "learning_rate": 4.691295499241095e-05,
      "loss": 1.2753,
      "step": 59450
    },
    {
      "epoch": 0.18544086618026098,
      "grad_norm": 0.5361382365226746,
      "learning_rate": 4.691035778140002e-05,
      "loss": 1.3334,
      "step": 59500
    },
    {
      "epoch": 0.18559669884091667,
      "grad_norm": 0.5900775194168091,
      "learning_rate": 4.6907760570389096e-05,
      "loss": 1.2472,
      "step": 59550
    },
    {
      "epoch": 0.18575253150157234,
      "grad_norm": 0.7311044931411743,
      "learning_rate": 4.690516335937817e-05,
      "loss": 1.3038,
      "step": 59600
    },
    {
      "epoch": 0.18590836416222803,
      "grad_norm": 0.8028233647346497,
      "learning_rate": 4.690256614836724e-05,
      "loss": 1.2957,
      "step": 59650
    },
    {
      "epoch": 0.18606419682288372,
      "grad_norm": 0.5221911668777466,
      "learning_rate": 4.6899968937356306e-05,
      "loss": 1.2815,
      "step": 59700
    },
    {
      "epoch": 0.18622002948353938,
      "grad_norm": 0.6366532444953918,
      "learning_rate": 4.6897371726345386e-05,
      "loss": 1.267,
      "step": 59750
    },
    {
      "epoch": 0.18637586214419508,
      "grad_norm": 0.6475458741188049,
      "learning_rate": 4.689477451533446e-05,
      "loss": 1.2794,
      "step": 59800
    },
    {
      "epoch": 0.18653169480485077,
      "grad_norm": 0.6154825687408447,
      "learning_rate": 4.6892177304323524e-05,
      "loss": 1.314,
      "step": 59850
    },
    {
      "epoch": 0.18668752746550643,
      "grad_norm": 0.7863314151763916,
      "learning_rate": 4.68895800933126e-05,
      "loss": 1.3209,
      "step": 59900
    },
    {
      "epoch": 0.18684336012616212,
      "grad_norm": 0.6910321116447449,
      "learning_rate": 4.688698288230167e-05,
      "loss": 1.3071,
      "step": 59950
    },
    {
      "epoch": 0.1869991927868178,
      "grad_norm": 0.6287990808486938,
      "learning_rate": 4.688438567129074e-05,
      "loss": 1.264,
      "step": 60000
    },
    {
      "epoch": 0.18715502544747348,
      "grad_norm": 0.6216883659362793,
      "learning_rate": 4.6881788460279814e-05,
      "loss": 1.2913,
      "step": 60050
    },
    {
      "epoch": 0.18731085810812917,
      "grad_norm": 0.5786150097846985,
      "learning_rate": 4.6879191249268886e-05,
      "loss": 1.2756,
      "step": 60100
    },
    {
      "epoch": 0.18746669076878486,
      "grad_norm": 0.6773401498794556,
      "learning_rate": 4.687659403825796e-05,
      "loss": 1.2745,
      "step": 60150
    },
    {
      "epoch": 0.18762252342944052,
      "grad_norm": 0.812893807888031,
      "learning_rate": 4.687399682724703e-05,
      "loss": 1.3258,
      "step": 60200
    },
    {
      "epoch": 0.18777835609009622,
      "grad_norm": 0.5750018954277039,
      "learning_rate": 4.6871399616236104e-05,
      "loss": 1.3111,
      "step": 60250
    },
    {
      "epoch": 0.18793418875075188,
      "grad_norm": 0.6157856583595276,
      "learning_rate": 4.6868802405225176e-05,
      "loss": 1.2769,
      "step": 60300
    },
    {
      "epoch": 0.18809002141140757,
      "grad_norm": 0.5587257146835327,
      "learning_rate": 4.686620519421425e-05,
      "loss": 1.2972,
      "step": 60350
    },
    {
      "epoch": 0.18824585407206326,
      "grad_norm": 0.4938853085041046,
      "learning_rate": 4.6863607983203315e-05,
      "loss": 1.2913,
      "step": 60400
    },
    {
      "epoch": 0.18840168673271893,
      "grad_norm": 0.6593256592750549,
      "learning_rate": 4.6861010772192394e-05,
      "loss": 1.3124,
      "step": 60450
    },
    {
      "epoch": 0.18855751939337462,
      "grad_norm": 0.5255851745605469,
      "learning_rate": 4.6858413561181466e-05,
      "loss": 1.2629,
      "step": 60500
    },
    {
      "epoch": 0.1887133520540303,
      "grad_norm": 0.7060503959655762,
      "learning_rate": 4.685581635017053e-05,
      "loss": 1.2823,
      "step": 60550
    },
    {
      "epoch": 0.18886918471468597,
      "grad_norm": 0.6652365922927856,
      "learning_rate": 4.6853271083379824e-05,
      "loss": 1.3088,
      "step": 60600
    },
    {
      "epoch": 0.18902501737534166,
      "grad_norm": 0.6527070999145508,
      "learning_rate": 4.68506738723689e-05,
      "loss": 1.264,
      "step": 60650
    },
    {
      "epoch": 0.18918085003599736,
      "grad_norm": 0.5362449884414673,
      "learning_rate": 4.684807666135797e-05,
      "loss": 1.3432,
      "step": 60700
    },
    {
      "epoch": 0.18933668269665302,
      "grad_norm": 0.5410618782043457,
      "learning_rate": 4.684547945034704e-05,
      "loss": 1.2559,
      "step": 60750
    },
    {
      "epoch": 0.1894925153573087,
      "grad_norm": 0.7672276496887207,
      "learning_rate": 4.6842882239336114e-05,
      "loss": 1.2627,
      "step": 60800
    },
    {
      "epoch": 0.1896483480179644,
      "grad_norm": 0.6490287184715271,
      "learning_rate": 4.684028502832519e-05,
      "loss": 1.2832,
      "step": 60850
    },
    {
      "epoch": 0.18980418067862007,
      "grad_norm": 0.6637516021728516,
      "learning_rate": 4.683768781731426e-05,
      "loss": 1.3015,
      "step": 60900
    },
    {
      "epoch": 0.18996001333927576,
      "grad_norm": 0.5007506012916565,
      "learning_rate": 4.6835090606303325e-05,
      "loss": 1.3082,
      "step": 60950
    },
    {
      "epoch": 0.19011584599993142,
      "grad_norm": 0.7084264159202576,
      "learning_rate": 4.6832493395292404e-05,
      "loss": 1.2714,
      "step": 61000
    },
    {
      "epoch": 0.1902716786605871,
      "grad_norm": 0.5587547421455383,
      "learning_rate": 4.682989618428148e-05,
      "loss": 1.2921,
      "step": 61050
    },
    {
      "epoch": 0.1904275113212428,
      "grad_norm": 0.6688686609268188,
      "learning_rate": 4.682729897327054e-05,
      "loss": 1.2323,
      "step": 61100
    },
    {
      "epoch": 0.19058334398189847,
      "grad_norm": 0.5860046148300171,
      "learning_rate": 4.6824701762259615e-05,
      "loss": 1.3094,
      "step": 61150
    },
    {
      "epoch": 0.19073917664255416,
      "grad_norm": 0.7459748387336731,
      "learning_rate": 4.6822104551248694e-05,
      "loss": 1.3045,
      "step": 61200
    },
    {
      "epoch": 0.19089500930320985,
      "grad_norm": 0.6785151362419128,
      "learning_rate": 4.681950734023776e-05,
      "loss": 1.3083,
      "step": 61250
    },
    {
      "epoch": 0.19105084196386551,
      "grad_norm": 0.6480129361152649,
      "learning_rate": 4.681691012922683e-05,
      "loss": 1.3168,
      "step": 61300
    },
    {
      "epoch": 0.1912066746245212,
      "grad_norm": 0.5682808756828308,
      "learning_rate": 4.6814312918215905e-05,
      "loss": 1.3117,
      "step": 61350
    },
    {
      "epoch": 0.1913625072851769,
      "grad_norm": 0.6151596307754517,
      "learning_rate": 4.681171570720498e-05,
      "loss": 1.2963,
      "step": 61400
    },
    {
      "epoch": 0.19151833994583256,
      "grad_norm": 0.6831915974617004,
      "learning_rate": 4.680911849619405e-05,
      "loss": 1.2606,
      "step": 61450
    },
    {
      "epoch": 0.19167417260648825,
      "grad_norm": 0.8361135125160217,
      "learning_rate": 4.680652128518312e-05,
      "loss": 1.3349,
      "step": 61500
    },
    {
      "epoch": 0.19183000526714394,
      "grad_norm": 0.5893268585205078,
      "learning_rate": 4.6803924074172195e-05,
      "loss": 1.2301,
      "step": 61550
    },
    {
      "epoch": 0.1919858379277996,
      "grad_norm": 0.6550257205963135,
      "learning_rate": 4.680132686316127e-05,
      "loss": 1.2891,
      "step": 61600
    },
    {
      "epoch": 0.1921416705884553,
      "grad_norm": 0.5188690423965454,
      "learning_rate": 4.679872965215033e-05,
      "loss": 1.3349,
      "step": 61650
    },
    {
      "epoch": 0.19229750324911096,
      "grad_norm": 0.5736362934112549,
      "learning_rate": 4.6796132441139406e-05,
      "loss": 1.2894,
      "step": 61700
    },
    {
      "epoch": 0.19245333590976665,
      "grad_norm": 0.576630175113678,
      "learning_rate": 4.6793535230128485e-05,
      "loss": 1.2784,
      "step": 61750
    },
    {
      "epoch": 0.19260916857042235,
      "grad_norm": 0.5815929174423218,
      "learning_rate": 4.679093801911755e-05,
      "loss": 1.3211,
      "step": 61800
    },
    {
      "epoch": 0.192765001231078,
      "grad_norm": 0.5877408385276794,
      "learning_rate": 4.678834080810662e-05,
      "loss": 1.307,
      "step": 61850
    },
    {
      "epoch": 0.1929208338917337,
      "grad_norm": 0.7317957878112793,
      "learning_rate": 4.67857435970957e-05,
      "loss": 1.2889,
      "step": 61900
    },
    {
      "epoch": 0.1930766665523894,
      "grad_norm": 0.49923935532569885,
      "learning_rate": 4.678314638608477e-05,
      "loss": 1.3166,
      "step": 61950
    },
    {
      "epoch": 0.19323249921304506,
      "grad_norm": 0.7177022099494934,
      "learning_rate": 4.678054917507384e-05,
      "loss": 1.3077,
      "step": 62000
    },
    {
      "epoch": 0.19338833187370075,
      "grad_norm": 0.6664307117462158,
      "learning_rate": 4.677795196406291e-05,
      "loss": 1.3558,
      "step": 62050
    },
    {
      "epoch": 0.19354416453435644,
      "grad_norm": 0.5353426933288574,
      "learning_rate": 4.6775354753051986e-05,
      "loss": 1.3572,
      "step": 62100
    },
    {
      "epoch": 0.1936999971950121,
      "grad_norm": 0.5262667536735535,
      "learning_rate": 4.677275754204106e-05,
      "loss": 1.2732,
      "step": 62150
    },
    {
      "epoch": 0.1938558298556678,
      "grad_norm": 0.5939745306968689,
      "learning_rate": 4.6770160331030124e-05,
      "loss": 1.244,
      "step": 62200
    },
    {
      "epoch": 0.19401166251632346,
      "grad_norm": 0.693976640701294,
      "learning_rate": 4.67675631200192e-05,
      "loss": 1.2725,
      "step": 62250
    },
    {
      "epoch": 0.19416749517697915,
      "grad_norm": 0.6894903779029846,
      "learning_rate": 4.6764965909008276e-05,
      "loss": 1.3027,
      "step": 62300
    },
    {
      "epoch": 0.19432332783763484,
      "grad_norm": 0.7556319832801819,
      "learning_rate": 4.676236869799734e-05,
      "loss": 1.2921,
      "step": 62350
    },
    {
      "epoch": 0.1944791604982905,
      "grad_norm": 0.5148922801017761,
      "learning_rate": 4.6759771486986414e-05,
      "loss": 1.2683,
      "step": 62400
    },
    {
      "epoch": 0.1946349931589462,
      "grad_norm": 0.5306206345558167,
      "learning_rate": 4.675717427597549e-05,
      "loss": 1.2964,
      "step": 62450
    },
    {
      "epoch": 0.1947908258196019,
      "grad_norm": 0.5471022725105286,
      "learning_rate": 4.675457706496456e-05,
      "loss": 1.3016,
      "step": 62500
    },
    {
      "epoch": 0.19494665848025755,
      "grad_norm": 0.6895194053649902,
      "learning_rate": 4.675197985395363e-05,
      "loss": 1.2919,
      "step": 62550
    },
    {
      "epoch": 0.19510249114091324,
      "grad_norm": 0.5279228091239929,
      "learning_rate": 4.6749382642942704e-05,
      "loss": 1.2743,
      "step": 62600
    },
    {
      "epoch": 0.19525832380156893,
      "grad_norm": 0.61063152551651,
      "learning_rate": 4.6746785431931776e-05,
      "loss": 1.2859,
      "step": 62650
    },
    {
      "epoch": 0.1954141564622246,
      "grad_norm": 0.6058220863342285,
      "learning_rate": 4.674418822092085e-05,
      "loss": 1.3146,
      "step": 62700
    },
    {
      "epoch": 0.1955699891228803,
      "grad_norm": 0.6152732372283936,
      "learning_rate": 4.674159100990992e-05,
      "loss": 1.3165,
      "step": 62750
    },
    {
      "epoch": 0.19572582178353598,
      "grad_norm": 0.6374164819717407,
      "learning_rate": 4.6738993798898994e-05,
      "loss": 1.276,
      "step": 62800
    },
    {
      "epoch": 0.19588165444419164,
      "grad_norm": 0.5670260190963745,
      "learning_rate": 4.6736396587888066e-05,
      "loss": 1.3247,
      "step": 62850
    },
    {
      "epoch": 0.19603748710484734,
      "grad_norm": 0.7136686444282532,
      "learning_rate": 4.673379937687713e-05,
      "loss": 1.2817,
      "step": 62900
    },
    {
      "epoch": 0.196193319765503,
      "grad_norm": 0.5999757647514343,
      "learning_rate": 4.6731202165866205e-05,
      "loss": 1.2342,
      "step": 62950
    },
    {
      "epoch": 0.1963491524261587,
      "grad_norm": 0.8270983695983887,
      "learning_rate": 4.6728604954855284e-05,
      "loss": 1.2666,
      "step": 63000
    },
    {
      "epoch": 0.19650498508681438,
      "grad_norm": 0.6094933152198792,
      "learning_rate": 4.672600774384435e-05,
      "loss": 1.3077,
      "step": 63050
    },
    {
      "epoch": 0.19666081774747005,
      "grad_norm": 0.35794368386268616,
      "learning_rate": 4.672341053283342e-05,
      "loss": 1.2706,
      "step": 63100
    },
    {
      "epoch": 0.19681665040812574,
      "grad_norm": 0.4591834247112274,
      "learning_rate": 4.67208133218225e-05,
      "loss": 1.2844,
      "step": 63150
    },
    {
      "epoch": 0.19697248306878143,
      "grad_norm": 0.5197128653526306,
      "learning_rate": 4.671821611081157e-05,
      "loss": 1.2565,
      "step": 63200
    },
    {
      "epoch": 0.1971283157294371,
      "grad_norm": 0.5964681506156921,
      "learning_rate": 4.671561889980064e-05,
      "loss": 1.2632,
      "step": 63250
    },
    {
      "epoch": 0.19728414839009278,
      "grad_norm": 0.61607426404953,
      "learning_rate": 4.671302168878971e-05,
      "loss": 1.2789,
      "step": 63300
    },
    {
      "epoch": 0.19743998105074848,
      "grad_norm": 0.5795137286186218,
      "learning_rate": 4.6710424477778785e-05,
      "loss": 1.2833,
      "step": 63350
    },
    {
      "epoch": 0.19759581371140414,
      "grad_norm": 0.5214031338691711,
      "learning_rate": 4.670782726676786e-05,
      "loss": 1.2673,
      "step": 63400
    },
    {
      "epoch": 0.19775164637205983,
      "grad_norm": 0.469007283449173,
      "learning_rate": 4.670528199997715e-05,
      "loss": 1.2718,
      "step": 63450
    },
    {
      "epoch": 0.19790747903271552,
      "grad_norm": 0.6888889670372009,
      "learning_rate": 4.6702684788966215e-05,
      "loss": 1.2942,
      "step": 63500
    },
    {
      "epoch": 0.19806331169337119,
      "grad_norm": 0.5400487184524536,
      "learning_rate": 4.6700087577955294e-05,
      "loss": 1.2491,
      "step": 63550
    },
    {
      "epoch": 0.19821914435402688,
      "grad_norm": 0.43381232023239136,
      "learning_rate": 4.669749036694436e-05,
      "loss": 1.2621,
      "step": 63600
    },
    {
      "epoch": 0.19837497701468254,
      "grad_norm": 0.759233832359314,
      "learning_rate": 4.669489315593343e-05,
      "loss": 1.2726,
      "step": 63650
    },
    {
      "epoch": 0.19853080967533823,
      "grad_norm": 0.4882024824619293,
      "learning_rate": 4.6692295944922505e-05,
      "loss": 1.2999,
      "step": 63700
    },
    {
      "epoch": 0.19868664233599392,
      "grad_norm": 0.5794182419776917,
      "learning_rate": 4.668969873391158e-05,
      "loss": 1.2727,
      "step": 63750
    },
    {
      "epoch": 0.1988424749966496,
      "grad_norm": 0.7788763046264648,
      "learning_rate": 4.668710152290065e-05,
      "loss": 1.2853,
      "step": 63800
    },
    {
      "epoch": 0.19899830765730528,
      "grad_norm": 0.4552573263645172,
      "learning_rate": 4.668450431188972e-05,
      "loss": 1.2877,
      "step": 63850
    },
    {
      "epoch": 0.19915414031796097,
      "grad_norm": 0.536320686340332,
      "learning_rate": 4.6681907100878795e-05,
      "loss": 1.3078,
      "step": 63900
    },
    {
      "epoch": 0.19930997297861663,
      "grad_norm": 0.7263410091400146,
      "learning_rate": 4.667930988986787e-05,
      "loss": 1.2873,
      "step": 63950
    },
    {
      "epoch": 0.19946580563927233,
      "grad_norm": 0.7510873675346375,
      "learning_rate": 4.667671267885694e-05,
      "loss": 1.2952,
      "step": 64000
    },
    {
      "epoch": 0.19962163829992802,
      "grad_norm": 0.7078385949134827,
      "learning_rate": 4.6674115467846006e-05,
      "loss": 1.2906,
      "step": 64050
    },
    {
      "epoch": 0.19977747096058368,
      "grad_norm": 0.5398227572441101,
      "learning_rate": 4.6671518256835085e-05,
      "loss": 1.2587,
      "step": 64100
    },
    {
      "epoch": 0.19993330362123937,
      "grad_norm": 0.8083759546279907,
      "learning_rate": 4.666892104582416e-05,
      "loss": 1.2827,
      "step": 64150
    },
    {
      "epoch": 0.20008913628189506,
      "grad_norm": 0.5607863664627075,
      "learning_rate": 4.666632383481322e-05,
      "loss": 1.2189,
      "step": 64200
    },
    {
      "epoch": 0.20024496894255073,
      "grad_norm": 0.5749654769897461,
      "learning_rate": 4.66637266238023e-05,
      "loss": 1.2696,
      "step": 64250
    },
    {
      "epoch": 0.20040080160320642,
      "grad_norm": 0.508385956287384,
      "learning_rate": 4.666112941279137e-05,
      "loss": 1.257,
      "step": 64300
    },
    {
      "epoch": 0.20055663426386208,
      "grad_norm": 0.5113421082496643,
      "learning_rate": 4.665853220178044e-05,
      "loss": 1.2471,
      "step": 64350
    },
    {
      "epoch": 0.20071246692451777,
      "grad_norm": 0.591773509979248,
      "learning_rate": 4.6655934990769513e-05,
      "loss": 1.2728,
      "step": 64400
    },
    {
      "epoch": 0.20086829958517347,
      "grad_norm": 0.6883741617202759,
      "learning_rate": 4.6653337779758586e-05,
      "loss": 1.2983,
      "step": 64450
    },
    {
      "epoch": 0.20102413224582913,
      "grad_norm": 0.6746755242347717,
      "learning_rate": 4.665074056874766e-05,
      "loss": 1.2335,
      "step": 64500
    },
    {
      "epoch": 0.20117996490648482,
      "grad_norm": 0.6022537350654602,
      "learning_rate": 4.664814335773673e-05,
      "loss": 1.3162,
      "step": 64550
    },
    {
      "epoch": 0.2013357975671405,
      "grad_norm": 0.6761201024055481,
      "learning_rate": 4.6645546146725803e-05,
      "loss": 1.2771,
      "step": 64600
    },
    {
      "epoch": 0.20149163022779618,
      "grad_norm": 0.647148072719574,
      "learning_rate": 4.6642948935714876e-05,
      "loss": 1.348,
      "step": 64650
    },
    {
      "epoch": 0.20164746288845187,
      "grad_norm": 0.5826601982116699,
      "learning_rate": 4.664035172470395e-05,
      "loss": 1.2329,
      "step": 64700
    },
    {
      "epoch": 0.20180329554910756,
      "grad_norm": 0.628215491771698,
      "learning_rate": 4.6637754513693014e-05,
      "loss": 1.2789,
      "step": 64750
    },
    {
      "epoch": 0.20195912820976322,
      "grad_norm": 0.6472412943840027,
      "learning_rate": 4.6635157302682093e-05,
      "loss": 1.3025,
      "step": 64800
    },
    {
      "epoch": 0.2021149608704189,
      "grad_norm": 0.5969371795654297,
      "learning_rate": 4.663256009167116e-05,
      "loss": 1.2825,
      "step": 64850
    },
    {
      "epoch": 0.20227079353107458,
      "grad_norm": 0.5639589428901672,
      "learning_rate": 4.662996288066023e-05,
      "loss": 1.3038,
      "step": 64900
    },
    {
      "epoch": 0.20242662619173027,
      "grad_norm": 0.5382996797561646,
      "learning_rate": 4.6627365669649304e-05,
      "loss": 1.3117,
      "step": 64950
    },
    {
      "epoch": 0.20258245885238596,
      "grad_norm": 0.5715367794036865,
      "learning_rate": 4.662476845863838e-05,
      "loss": 1.2814,
      "step": 65000
    },
    {
      "epoch": 0.20273829151304162,
      "grad_norm": 0.7551167607307434,
      "learning_rate": 4.662217124762745e-05,
      "loss": 1.3443,
      "step": 65050
    },
    {
      "epoch": 0.20289412417369732,
      "grad_norm": 0.4995189309120178,
      "learning_rate": 4.661957403661652e-05,
      "loss": 1.3279,
      "step": 65100
    },
    {
      "epoch": 0.203049956834353,
      "grad_norm": 0.728512167930603,
      "learning_rate": 4.6616976825605594e-05,
      "loss": 1.3124,
      "step": 65150
    },
    {
      "epoch": 0.20320578949500867,
      "grad_norm": 0.5708598494529724,
      "learning_rate": 4.661437961459467e-05,
      "loss": 1.3464,
      "step": 65200
    },
    {
      "epoch": 0.20336162215566436,
      "grad_norm": 0.5918168425559998,
      "learning_rate": 4.661178240358374e-05,
      "loss": 1.315,
      "step": 65250
    },
    {
      "epoch": 0.20351745481632005,
      "grad_norm": 0.5681039690971375,
      "learning_rate": 4.6609185192572805e-05,
      "loss": 1.2649,
      "step": 65300
    },
    {
      "epoch": 0.20367328747697572,
      "grad_norm": 0.7084054946899414,
      "learning_rate": 4.6606587981561884e-05,
      "loss": 1.3076,
      "step": 65350
    },
    {
      "epoch": 0.2038291201376314,
      "grad_norm": 0.6380575895309448,
      "learning_rate": 4.660399077055096e-05,
      "loss": 1.3857,
      "step": 65400
    },
    {
      "epoch": 0.2039849527982871,
      "grad_norm": 0.63450026512146,
      "learning_rate": 4.660139355954002e-05,
      "loss": 1.2811,
      "step": 65450
    },
    {
      "epoch": 0.20414078545894276,
      "grad_norm": 0.49069610238075256,
      "learning_rate": 4.65987963485291e-05,
      "loss": 1.31,
      "step": 65500
    },
    {
      "epoch": 0.20429661811959846,
      "grad_norm": 0.7103584408760071,
      "learning_rate": 4.659619913751817e-05,
      "loss": 1.2822,
      "step": 65550
    },
    {
      "epoch": 0.20445245078025412,
      "grad_norm": 0.47147369384765625,
      "learning_rate": 4.659360192650724e-05,
      "loss": 1.276,
      "step": 65600
    },
    {
      "epoch": 0.2046082834409098,
      "grad_norm": 0.5865196585655212,
      "learning_rate": 4.659100471549631e-05,
      "loss": 1.2518,
      "step": 65650
    },
    {
      "epoch": 0.2047641161015655,
      "grad_norm": 0.5246824026107788,
      "learning_rate": 4.6588407504485385e-05,
      "loss": 1.2537,
      "step": 65700
    },
    {
      "epoch": 0.20491994876222117,
      "grad_norm": 0.6241628527641296,
      "learning_rate": 4.658581029347446e-05,
      "loss": 1.2999,
      "step": 65750
    },
    {
      "epoch": 0.20507578142287686,
      "grad_norm": 0.6123270988464355,
      "learning_rate": 4.658321308246353e-05,
      "loss": 1.2867,
      "step": 65800
    },
    {
      "epoch": 0.20523161408353255,
      "grad_norm": 0.7367225885391235,
      "learning_rate": 4.65806158714526e-05,
      "loss": 1.3309,
      "step": 65850
    },
    {
      "epoch": 0.2053874467441882,
      "grad_norm": 0.5684239268302917,
      "learning_rate": 4.6578018660441675e-05,
      "loss": 1.2368,
      "step": 65900
    },
    {
      "epoch": 0.2055432794048439,
      "grad_norm": 0.6555652022361755,
      "learning_rate": 4.657542144943075e-05,
      "loss": 1.203,
      "step": 65950
    },
    {
      "epoch": 0.2056991120654996,
      "grad_norm": 0.6085348725318909,
      "learning_rate": 4.657282423841981e-05,
      "loss": 1.3143,
      "step": 66000
    },
    {
      "epoch": 0.20585494472615526,
      "grad_norm": 0.7464703321456909,
      "learning_rate": 4.657022702740889e-05,
      "loss": 1.2456,
      "step": 66050
    },
    {
      "epoch": 0.20601077738681095,
      "grad_norm": 0.6690695881843567,
      "learning_rate": 4.6567629816397965e-05,
      "loss": 1.3512,
      "step": 66100
    },
    {
      "epoch": 0.20616661004746664,
      "grad_norm": 0.5802823901176453,
      "learning_rate": 4.656503260538703e-05,
      "loss": 1.3003,
      "step": 66150
    },
    {
      "epoch": 0.2063224427081223,
      "grad_norm": 0.5819591283798218,
      "learning_rate": 4.65624353943761e-05,
      "loss": 1.3067,
      "step": 66200
    },
    {
      "epoch": 0.206478275368778,
      "grad_norm": 0.5117917060852051,
      "learning_rate": 4.6559838183365176e-05,
      "loss": 1.2968,
      "step": 66250
    },
    {
      "epoch": 0.20663410802943366,
      "grad_norm": 0.5727739930152893,
      "learning_rate": 4.655724097235425e-05,
      "loss": 1.3033,
      "step": 66300
    },
    {
      "epoch": 0.20678994069008935,
      "grad_norm": 0.7060168385505676,
      "learning_rate": 4.655464376134332e-05,
      "loss": 1.2167,
      "step": 66350
    },
    {
      "epoch": 0.20694577335074504,
      "grad_norm": 0.5490187406539917,
      "learning_rate": 4.655204655033239e-05,
      "loss": 1.2873,
      "step": 66400
    },
    {
      "epoch": 0.2071016060114007,
      "grad_norm": 0.5274326801300049,
      "learning_rate": 4.6549501283541685e-05,
      "loss": 1.3695,
      "step": 66450
    },
    {
      "epoch": 0.2072574386720564,
      "grad_norm": 0.5958650708198547,
      "learning_rate": 4.654690407253076e-05,
      "loss": 1.2324,
      "step": 66500
    },
    {
      "epoch": 0.2074132713327121,
      "grad_norm": 0.4372328221797943,
      "learning_rate": 4.6544306861519824e-05,
      "loss": 1.2887,
      "step": 66550
    },
    {
      "epoch": 0.20756910399336775,
      "grad_norm": 0.6431561708450317,
      "learning_rate": 4.65417096505089e-05,
      "loss": 1.2875,
      "step": 66600
    },
    {
      "epoch": 0.20772493665402345,
      "grad_norm": 0.7644646763801575,
      "learning_rate": 4.6539112439497975e-05,
      "loss": 1.2811,
      "step": 66650
    },
    {
      "epoch": 0.20788076931467914,
      "grad_norm": 0.5666146874427795,
      "learning_rate": 4.653651522848704e-05,
      "loss": 1.2754,
      "step": 66700
    },
    {
      "epoch": 0.2080366019753348,
      "grad_norm": 0.5595414042472839,
      "learning_rate": 4.6533918017476114e-05,
      "loss": 1.251,
      "step": 66750
    },
    {
      "epoch": 0.2081924346359905,
      "grad_norm": 0.7823895215988159,
      "learning_rate": 4.653132080646519e-05,
      "loss": 1.3021,
      "step": 66800
    },
    {
      "epoch": 0.20834826729664616,
      "grad_norm": 0.4601406157016754,
      "learning_rate": 4.652872359545426e-05,
      "loss": 1.2543,
      "step": 66850
    },
    {
      "epoch": 0.20850409995730185,
      "grad_norm": 0.5399758815765381,
      "learning_rate": 4.652612638444333e-05,
      "loss": 1.241,
      "step": 66900
    },
    {
      "epoch": 0.20865993261795754,
      "grad_norm": 0.5484157800674438,
      "learning_rate": 4.6523529173432404e-05,
      "loss": 1.251,
      "step": 66950
    },
    {
      "epoch": 0.2088157652786132,
      "grad_norm": 0.612287700176239,
      "learning_rate": 4.6520931962421476e-05,
      "loss": 1.2407,
      "step": 67000
    },
    {
      "epoch": 0.2089715979392689,
      "grad_norm": 0.657568633556366,
      "learning_rate": 4.651833475141055e-05,
      "loss": 1.2534,
      "step": 67050
    },
    {
      "epoch": 0.20912743059992459,
      "grad_norm": 0.7256750464439392,
      "learning_rate": 4.6515737540399614e-05,
      "loss": 1.2852,
      "step": 67100
    },
    {
      "epoch": 0.20928326326058025,
      "grad_norm": 0.569068193435669,
      "learning_rate": 4.6513140329388694e-05,
      "loss": 1.2825,
      "step": 67150
    },
    {
      "epoch": 0.20943909592123594,
      "grad_norm": 0.5841131210327148,
      "learning_rate": 4.6510543118377766e-05,
      "loss": 1.2867,
      "step": 67200
    },
    {
      "epoch": 0.20959492858189163,
      "grad_norm": 0.5607755780220032,
      "learning_rate": 4.650794590736683e-05,
      "loss": 1.2401,
      "step": 67250
    },
    {
      "epoch": 0.2097507612425473,
      "grad_norm": 0.6084451675415039,
      "learning_rate": 4.6505348696355904e-05,
      "loss": 1.3017,
      "step": 67300
    },
    {
      "epoch": 0.209906593903203,
      "grad_norm": 0.5152478218078613,
      "learning_rate": 4.6502751485344984e-05,
      "loss": 1.2703,
      "step": 67350
    },
    {
      "epoch": 0.21006242656385868,
      "grad_norm": 0.6660149097442627,
      "learning_rate": 4.650015427433405e-05,
      "loss": 1.2934,
      "step": 67400
    },
    {
      "epoch": 0.21021825922451434,
      "grad_norm": 0.5849317312240601,
      "learning_rate": 4.649755706332312e-05,
      "loss": 1.3076,
      "step": 67450
    },
    {
      "epoch": 0.21037409188517003,
      "grad_norm": 0.5215211510658264,
      "learning_rate": 4.6494959852312194e-05,
      "loss": 1.3181,
      "step": 67500
    },
    {
      "epoch": 0.2105299245458257,
      "grad_norm": 0.6967973709106445,
      "learning_rate": 4.649236264130127e-05,
      "loss": 1.3053,
      "step": 67550
    },
    {
      "epoch": 0.2106857572064814,
      "grad_norm": 0.6250441074371338,
      "learning_rate": 4.648976543029034e-05,
      "loss": 1.2743,
      "step": 67600
    },
    {
      "epoch": 0.21084158986713708,
      "grad_norm": 0.7048274874687195,
      "learning_rate": 4.648716821927941e-05,
      "loss": 1.2834,
      "step": 67650
    },
    {
      "epoch": 0.21099742252779274,
      "grad_norm": 0.5840187668800354,
      "learning_rate": 4.6484571008268484e-05,
      "loss": 1.283,
      "step": 67700
    },
    {
      "epoch": 0.21115325518844844,
      "grad_norm": 0.4861902892589569,
      "learning_rate": 4.648197379725756e-05,
      "loss": 1.2971,
      "step": 67750
    },
    {
      "epoch": 0.21130908784910413,
      "grad_norm": 0.6368274092674255,
      "learning_rate": 4.647937658624662e-05,
      "loss": 1.2534,
      "step": 67800
    },
    {
      "epoch": 0.2114649205097598,
      "grad_norm": 0.6637482643127441,
      "learning_rate": 4.64767793752357e-05,
      "loss": 1.2902,
      "step": 67850
    },
    {
      "epoch": 0.21162075317041548,
      "grad_norm": 0.5981953740119934,
      "learning_rate": 4.6474182164224774e-05,
      "loss": 1.2384,
      "step": 67900
    },
    {
      "epoch": 0.21177658583107117,
      "grad_norm": 0.6270100474357605,
      "learning_rate": 4.647158495321384e-05,
      "loss": 1.31,
      "step": 67950
    },
    {
      "epoch": 0.21193241849172684,
      "grad_norm": 0.7264842987060547,
      "learning_rate": 4.646898774220291e-05,
      "loss": 1.3427,
      "step": 68000
    },
    {
      "epoch": 0.21208825115238253,
      "grad_norm": 0.5019625425338745,
      "learning_rate": 4.646639053119199e-05,
      "loss": 1.3089,
      "step": 68050
    },
    {
      "epoch": 0.21224408381303822,
      "grad_norm": 0.7746782302856445,
      "learning_rate": 4.646379332018106e-05,
      "loss": 1.3176,
      "step": 68100
    },
    {
      "epoch": 0.21239991647369388,
      "grad_norm": 0.49563097953796387,
      "learning_rate": 4.646119610917013e-05,
      "loss": 1.2728,
      "step": 68150
    },
    {
      "epoch": 0.21255574913434958,
      "grad_norm": 0.49140456318855286,
      "learning_rate": 4.64585988981592e-05,
      "loss": 1.3201,
      "step": 68200
    },
    {
      "epoch": 0.21271158179500524,
      "grad_norm": 0.639885663986206,
      "learning_rate": 4.6456001687148275e-05,
      "loss": 1.308,
      "step": 68250
    },
    {
      "epoch": 0.21286741445566093,
      "grad_norm": 0.6340157389640808,
      "learning_rate": 4.645340447613735e-05,
      "loss": 1.2965,
      "step": 68300
    },
    {
      "epoch": 0.21302324711631662,
      "grad_norm": 0.5175265073776245,
      "learning_rate": 4.645080726512642e-05,
      "loss": 1.337,
      "step": 68350
    },
    {
      "epoch": 0.21317907977697229,
      "grad_norm": 0.6173223853111267,
      "learning_rate": 4.644821005411549e-05,
      "loss": 1.256,
      "step": 68400
    },
    {
      "epoch": 0.21333491243762798,
      "grad_norm": 0.7605581879615784,
      "learning_rate": 4.6445612843104565e-05,
      "loss": 1.2634,
      "step": 68450
    },
    {
      "epoch": 0.21349074509828367,
      "grad_norm": 0.47486287355422974,
      "learning_rate": 4.644301563209363e-05,
      "loss": 1.2333,
      "step": 68500
    },
    {
      "epoch": 0.21364657775893933,
      "grad_norm": 0.6538503170013428,
      "learning_rate": 4.64404184210827e-05,
      "loss": 1.2919,
      "step": 68550
    },
    {
      "epoch": 0.21380241041959502,
      "grad_norm": 0.6573764681816101,
      "learning_rate": 4.643782121007178e-05,
      "loss": 1.3305,
      "step": 68600
    },
    {
      "epoch": 0.21395824308025072,
      "grad_norm": 0.7415863871574402,
      "learning_rate": 4.643522399906085e-05,
      "loss": 1.2966,
      "step": 68650
    },
    {
      "epoch": 0.21411407574090638,
      "grad_norm": 0.49995601177215576,
      "learning_rate": 4.643262678804992e-05,
      "loss": 1.223,
      "step": 68700
    },
    {
      "epoch": 0.21426990840156207,
      "grad_norm": 0.5276639461517334,
      "learning_rate": 4.6430029577039e-05,
      "loss": 1.2962,
      "step": 68750
    },
    {
      "epoch": 0.21442574106221776,
      "grad_norm": 0.623737633228302,
      "learning_rate": 4.6427432366028066e-05,
      "loss": 1.2518,
      "step": 68800
    },
    {
      "epoch": 0.21458157372287343,
      "grad_norm": 0.587867796421051,
      "learning_rate": 4.642483515501714e-05,
      "loss": 1.2683,
      "step": 68850
    },
    {
      "epoch": 0.21473740638352912,
      "grad_norm": 0.5999011993408203,
      "learning_rate": 4.642223794400621e-05,
      "loss": 1.2849,
      "step": 68900
    },
    {
      "epoch": 0.21489323904418478,
      "grad_norm": 0.4813564717769623,
      "learning_rate": 4.641964073299528e-05,
      "loss": 1.3464,
      "step": 68950
    },
    {
      "epoch": 0.21504907170484047,
      "grad_norm": 0.5506970882415771,
      "learning_rate": 4.6417043521984356e-05,
      "loss": 1.2882,
      "step": 69000
    },
    {
      "epoch": 0.21520490436549616,
      "grad_norm": 0.5990175008773804,
      "learning_rate": 4.641444631097343e-05,
      "loss": 1.29,
      "step": 69050
    },
    {
      "epoch": 0.21536073702615183,
      "grad_norm": 0.7059299349784851,
      "learning_rate": 4.64118490999625e-05,
      "loss": 1.3017,
      "step": 69100
    },
    {
      "epoch": 0.21551656968680752,
      "grad_norm": 0.5940800309181213,
      "learning_rate": 4.640925188895157e-05,
      "loss": 1.2732,
      "step": 69150
    },
    {
      "epoch": 0.2156724023474632,
      "grad_norm": 0.8108808994293213,
      "learning_rate": 4.640665467794064e-05,
      "loss": 1.3124,
      "step": 69200
    },
    {
      "epoch": 0.21582823500811887,
      "grad_norm": 0.7018696665763855,
      "learning_rate": 4.640405746692971e-05,
      "loss": 1.2857,
      "step": 69250
    },
    {
      "epoch": 0.21598406766877457,
      "grad_norm": 0.4780503213405609,
      "learning_rate": 4.640146025591879e-05,
      "loss": 1.242,
      "step": 69300
    },
    {
      "epoch": 0.21613990032943026,
      "grad_norm": 0.4494949281215668,
      "learning_rate": 4.6398863044907857e-05,
      "loss": 1.2937,
      "step": 69350
    },
    {
      "epoch": 0.21629573299008592,
      "grad_norm": 0.7227841019630432,
      "learning_rate": 4.639626583389693e-05,
      "loss": 1.2746,
      "step": 69400
    },
    {
      "epoch": 0.2164515656507416,
      "grad_norm": 0.5682891607284546,
      "learning_rate": 4.6393668622886e-05,
      "loss": 1.3361,
      "step": 69450
    },
    {
      "epoch": 0.21660739831139728,
      "grad_norm": 0.6672849655151367,
      "learning_rate": 4.6391071411875074e-05,
      "loss": 1.2853,
      "step": 69500
    },
    {
      "epoch": 0.21676323097205297,
      "grad_norm": 0.6178155541419983,
      "learning_rate": 4.638847420086415e-05,
      "loss": 1.3622,
      "step": 69550
    },
    {
      "epoch": 0.21691906363270866,
      "grad_norm": 0.6324227452278137,
      "learning_rate": 4.638587698985322e-05,
      "loss": 1.2766,
      "step": 69600
    },
    {
      "epoch": 0.21707489629336432,
      "grad_norm": 0.5885457396507263,
      "learning_rate": 4.638327977884229e-05,
      "loss": 1.2663,
      "step": 69650
    },
    {
      "epoch": 0.21723072895402,
      "grad_norm": 0.640190839767456,
      "learning_rate": 4.6380682567831364e-05,
      "loss": 1.2757,
      "step": 69700
    },
    {
      "epoch": 0.2173865616146757,
      "grad_norm": 0.6598213911056519,
      "learning_rate": 4.637808535682043e-05,
      "loss": 1.2824,
      "step": 69750
    },
    {
      "epoch": 0.21754239427533137,
      "grad_norm": 0.6065354347229004,
      "learning_rate": 4.63754881458095e-05,
      "loss": 1.3174,
      "step": 69800
    },
    {
      "epoch": 0.21769822693598706,
      "grad_norm": 0.7042612433433533,
      "learning_rate": 4.637289093479858e-05,
      "loss": 1.2876,
      "step": 69850
    },
    {
      "epoch": 0.21785405959664275,
      "grad_norm": 0.5661587119102478,
      "learning_rate": 4.637029372378765e-05,
      "loss": 1.2802,
      "step": 69900
    },
    {
      "epoch": 0.21800989225729842,
      "grad_norm": 0.7826735377311707,
      "learning_rate": 4.636769651277672e-05,
      "loss": 1.2866,
      "step": 69950
    },
    {
      "epoch": 0.2181657249179541,
      "grad_norm": 0.6057630777359009,
      "learning_rate": 4.63650993017658e-05,
      "loss": 1.3286,
      "step": 70000
    },
    {
      "epoch": 0.2183215575786098,
      "grad_norm": 0.5641568303108215,
      "learning_rate": 4.6362502090754865e-05,
      "loss": 1.2846,
      "step": 70050
    },
    {
      "epoch": 0.21847739023926546,
      "grad_norm": 0.6100899577140808,
      "learning_rate": 4.635990487974394e-05,
      "loss": 1.3144,
      "step": 70100
    },
    {
      "epoch": 0.21863322289992115,
      "grad_norm": 0.5492218136787415,
      "learning_rate": 4.635730766873301e-05,
      "loss": 1.2967,
      "step": 70150
    },
    {
      "epoch": 0.21878905556057682,
      "grad_norm": 0.449149489402771,
      "learning_rate": 4.635471045772208e-05,
      "loss": 1.2593,
      "step": 70200
    },
    {
      "epoch": 0.2189448882212325,
      "grad_norm": 0.6660369038581848,
      "learning_rate": 4.6352113246711155e-05,
      "loss": 1.2836,
      "step": 70250
    },
    {
      "epoch": 0.2191007208818882,
      "grad_norm": 0.540694534778595,
      "learning_rate": 4.634951603570023e-05,
      "loss": 1.2342,
      "step": 70300
    },
    {
      "epoch": 0.21925655354254386,
      "grad_norm": 0.5647057294845581,
      "learning_rate": 4.63469188246893e-05,
      "loss": 1.2427,
      "step": 70350
    },
    {
      "epoch": 0.21941238620319956,
      "grad_norm": 0.7145959734916687,
      "learning_rate": 4.634432161367837e-05,
      "loss": 1.3418,
      "step": 70400
    },
    {
      "epoch": 0.21956821886385525,
      "grad_norm": 0.4907006025314331,
      "learning_rate": 4.634172440266744e-05,
      "loss": 1.332,
      "step": 70450
    },
    {
      "epoch": 0.2197240515245109,
      "grad_norm": 0.5644859075546265,
      "learning_rate": 4.633912719165651e-05,
      "loss": 1.3088,
      "step": 70500
    },
    {
      "epoch": 0.2198798841851666,
      "grad_norm": 0.7533993721008301,
      "learning_rate": 4.63365819248658e-05,
      "loss": 1.2883,
      "step": 70550
    },
    {
      "epoch": 0.2200357168458223,
      "grad_norm": 0.6795079112052917,
      "learning_rate": 4.6333984713854875e-05,
      "loss": 1.2248,
      "step": 70600
    },
    {
      "epoch": 0.22019154950647796,
      "grad_norm": 0.6312673091888428,
      "learning_rate": 4.633138750284395e-05,
      "loss": 1.2871,
      "step": 70650
    },
    {
      "epoch": 0.22034738216713365,
      "grad_norm": 0.5526705384254456,
      "learning_rate": 4.632879029183302e-05,
      "loss": 1.3203,
      "step": 70700
    },
    {
      "epoch": 0.22050321482778934,
      "grad_norm": 0.6753116846084595,
      "learning_rate": 4.632619308082209e-05,
      "loss": 1.3083,
      "step": 70750
    },
    {
      "epoch": 0.220659047488445,
      "grad_norm": 0.5424126982688904,
      "learning_rate": 4.6323595869811165e-05,
      "loss": 1.2855,
      "step": 70800
    },
    {
      "epoch": 0.2208148801491007,
      "grad_norm": 0.6450543403625488,
      "learning_rate": 4.632105060302046e-05,
      "loss": 1.2697,
      "step": 70850
    },
    {
      "epoch": 0.22097071280975636,
      "grad_norm": 0.6385448575019836,
      "learning_rate": 4.631845339200952e-05,
      "loss": 1.3153,
      "step": 70900
    },
    {
      "epoch": 0.22112654547041205,
      "grad_norm": 0.6255855560302734,
      "learning_rate": 4.63158561809986e-05,
      "loss": 1.2947,
      "step": 70950
    },
    {
      "epoch": 0.22128237813106774,
      "grad_norm": 0.6269358396530151,
      "learning_rate": 4.6313258969987675e-05,
      "loss": 1.2769,
      "step": 71000
    },
    {
      "epoch": 0.2214382107917234,
      "grad_norm": 0.7384969592094421,
      "learning_rate": 4.631066175897674e-05,
      "loss": 1.2648,
      "step": 71050
    },
    {
      "epoch": 0.2215940434523791,
      "grad_norm": 0.48208484053611755,
      "learning_rate": 4.630806454796581e-05,
      "loss": 1.3073,
      "step": 71100
    },
    {
      "epoch": 0.2217498761130348,
      "grad_norm": 0.7402802109718323,
      "learning_rate": 4.6305467336954886e-05,
      "loss": 1.3035,
      "step": 71150
    },
    {
      "epoch": 0.22190570877369045,
      "grad_norm": 0.7635326385498047,
      "learning_rate": 4.630287012594396e-05,
      "loss": 1.3093,
      "step": 71200
    },
    {
      "epoch": 0.22206154143434614,
      "grad_norm": 0.4652780592441559,
      "learning_rate": 4.630027291493303e-05,
      "loss": 1.2578,
      "step": 71250
    },
    {
      "epoch": 0.22221737409500184,
      "grad_norm": 0.5958724617958069,
      "learning_rate": 4.62976757039221e-05,
      "loss": 1.2637,
      "step": 71300
    },
    {
      "epoch": 0.2223732067556575,
      "grad_norm": 0.54151850938797,
      "learning_rate": 4.6295078492911176e-05,
      "loss": 1.2283,
      "step": 71350
    },
    {
      "epoch": 0.2225290394163132,
      "grad_norm": 0.7490941882133484,
      "learning_rate": 4.629248128190025e-05,
      "loss": 1.3136,
      "step": 71400
    },
    {
      "epoch": 0.22268487207696885,
      "grad_norm": 0.46164342761039734,
      "learning_rate": 4.6289884070889314e-05,
      "loss": 1.2614,
      "step": 71450
    },
    {
      "epoch": 0.22284070473762455,
      "grad_norm": 0.528932511806488,
      "learning_rate": 4.628728685987839e-05,
      "loss": 1.3151,
      "step": 71500
    },
    {
      "epoch": 0.22299653739828024,
      "grad_norm": 0.6686425805091858,
      "learning_rate": 4.6284689648867466e-05,
      "loss": 1.2825,
      "step": 71550
    },
    {
      "epoch": 0.2231523700589359,
      "grad_norm": 0.6674734950065613,
      "learning_rate": 4.628209243785653e-05,
      "loss": 1.3012,
      "step": 71600
    },
    {
      "epoch": 0.2233082027195916,
      "grad_norm": 0.6535020470619202,
      "learning_rate": 4.6279495226845604e-05,
      "loss": 1.2742,
      "step": 71650
    },
    {
      "epoch": 0.22346403538024728,
      "grad_norm": 0.6152780652046204,
      "learning_rate": 4.627689801583468e-05,
      "loss": 1.335,
      "step": 71700
    },
    {
      "epoch": 0.22361986804090295,
      "grad_norm": 0.6633535623550415,
      "learning_rate": 4.627430080482375e-05,
      "loss": 1.3124,
      "step": 71750
    },
    {
      "epoch": 0.22377570070155864,
      "grad_norm": 0.5165836215019226,
      "learning_rate": 4.627170359381282e-05,
      "loss": 1.2765,
      "step": 71800
    },
    {
      "epoch": 0.22393153336221433,
      "grad_norm": 0.5673712491989136,
      "learning_rate": 4.6269106382801894e-05,
      "loss": 1.3092,
      "step": 71850
    },
    {
      "epoch": 0.22408736602287,
      "grad_norm": 0.5639752149581909,
      "learning_rate": 4.6266509171790966e-05,
      "loss": 1.2742,
      "step": 71900
    },
    {
      "epoch": 0.22424319868352569,
      "grad_norm": 0.5311650633811951,
      "learning_rate": 4.626391196078004e-05,
      "loss": 1.2554,
      "step": 71950
    },
    {
      "epoch": 0.22439903134418138,
      "grad_norm": 0.562175452709198,
      "learning_rate": 4.6261314749769105e-05,
      "loss": 1.296,
      "step": 72000
    },
    {
      "epoch": 0.22455486400483704,
      "grad_norm": 0.5725643038749695,
      "learning_rate": 4.6258717538758184e-05,
      "loss": 1.2973,
      "step": 72050
    },
    {
      "epoch": 0.22471069666549273,
      "grad_norm": 0.6529726982116699,
      "learning_rate": 4.6256120327747256e-05,
      "loss": 1.277,
      "step": 72100
    },
    {
      "epoch": 0.2248665293261484,
      "grad_norm": 0.4923674464225769,
      "learning_rate": 4.625352311673632e-05,
      "loss": 1.3147,
      "step": 72150
    },
    {
      "epoch": 0.2250223619868041,
      "grad_norm": 0.624786376953125,
      "learning_rate": 4.62509259057254e-05,
      "loss": 1.3141,
      "step": 72200
    },
    {
      "epoch": 0.22517819464745978,
      "grad_norm": 0.605603039264679,
      "learning_rate": 4.6248328694714474e-05,
      "loss": 1.2762,
      "step": 72250
    },
    {
      "epoch": 0.22533402730811544,
      "grad_norm": 0.5627497434616089,
      "learning_rate": 4.624573148370354e-05,
      "loss": 1.2986,
      "step": 72300
    },
    {
      "epoch": 0.22548985996877113,
      "grad_norm": 0.5139368772506714,
      "learning_rate": 4.624313427269261e-05,
      "loss": 1.2929,
      "step": 72350
    },
    {
      "epoch": 0.22564569262942683,
      "grad_norm": 0.47183385491371155,
      "learning_rate": 4.6240537061681685e-05,
      "loss": 1.3023,
      "step": 72400
    },
    {
      "epoch": 0.2258015252900825,
      "grad_norm": 0.5910354256629944,
      "learning_rate": 4.623793985067076e-05,
      "loss": 1.2758,
      "step": 72450
    },
    {
      "epoch": 0.22595735795073818,
      "grad_norm": 0.6033272743225098,
      "learning_rate": 4.623534263965983e-05,
      "loss": 1.3106,
      "step": 72500
    },
    {
      "epoch": 0.22611319061139387,
      "grad_norm": 0.5516175627708435,
      "learning_rate": 4.62327454286489e-05,
      "loss": 1.3273,
      "step": 72550
    },
    {
      "epoch": 0.22626902327204954,
      "grad_norm": 0.6564483046531677,
      "learning_rate": 4.6230148217637975e-05,
      "loss": 1.3392,
      "step": 72600
    },
    {
      "epoch": 0.22642485593270523,
      "grad_norm": 0.45165371894836426,
      "learning_rate": 4.622755100662705e-05,
      "loss": 1.2653,
      "step": 72650
    },
    {
      "epoch": 0.22658068859336092,
      "grad_norm": 0.5875057578086853,
      "learning_rate": 4.622495379561611e-05,
      "loss": 1.2457,
      "step": 72700
    },
    {
      "epoch": 0.22673652125401658,
      "grad_norm": 0.6385176181793213,
      "learning_rate": 4.622235658460519e-05,
      "loss": 1.3232,
      "step": 72750
    },
    {
      "epoch": 0.22689235391467227,
      "grad_norm": 0.548184871673584,
      "learning_rate": 4.6219759373594265e-05,
      "loss": 1.2806,
      "step": 72800
    },
    {
      "epoch": 0.22704818657532794,
      "grad_norm": 0.6916170120239258,
      "learning_rate": 4.621716216258333e-05,
      "loss": 1.3147,
      "step": 72850
    },
    {
      "epoch": 0.22720401923598363,
      "grad_norm": 0.6753619313240051,
      "learning_rate": 4.62145649515724e-05,
      "loss": 1.2873,
      "step": 72900
    },
    {
      "epoch": 0.22735985189663932,
      "grad_norm": 0.675290584564209,
      "learning_rate": 4.621196774056148e-05,
      "loss": 1.2789,
      "step": 72950
    },
    {
      "epoch": 0.22751568455729498,
      "grad_norm": 0.8153882622718811,
      "learning_rate": 4.620937052955055e-05,
      "loss": 1.2639,
      "step": 73000
    },
    {
      "epoch": 0.22767151721795068,
      "grad_norm": 0.6233119964599609,
      "learning_rate": 4.620677331853962e-05,
      "loss": 1.2469,
      "step": 73050
    },
    {
      "epoch": 0.22782734987860637,
      "grad_norm": 0.5969549417495728,
      "learning_rate": 4.620417610752869e-05,
      "loss": 1.2321,
      "step": 73100
    },
    {
      "epoch": 0.22798318253926203,
      "grad_norm": 0.5448806285858154,
      "learning_rate": 4.6201578896517765e-05,
      "loss": 1.2528,
      "step": 73150
    },
    {
      "epoch": 0.22813901519991772,
      "grad_norm": 0.676522970199585,
      "learning_rate": 4.619898168550684e-05,
      "loss": 1.3166,
      "step": 73200
    },
    {
      "epoch": 0.2282948478605734,
      "grad_norm": 0.5689308643341064,
      "learning_rate": 4.619638447449591e-05,
      "loss": 1.3051,
      "step": 73250
    },
    {
      "epoch": 0.22845068052122908,
      "grad_norm": 0.46251481771469116,
      "learning_rate": 4.619378726348498e-05,
      "loss": 1.2859,
      "step": 73300
    },
    {
      "epoch": 0.22860651318188477,
      "grad_norm": 0.7993087768554688,
      "learning_rate": 4.6191190052474055e-05,
      "loss": 1.2494,
      "step": 73350
    },
    {
      "epoch": 0.22876234584254046,
      "grad_norm": 0.5669376850128174,
      "learning_rate": 4.618859284146312e-05,
      "loss": 1.2668,
      "step": 73400
    },
    {
      "epoch": 0.22891817850319612,
      "grad_norm": 0.6385453343391418,
      "learning_rate": 4.61859956304522e-05,
      "loss": 1.2938,
      "step": 73450
    },
    {
      "epoch": 0.22907401116385182,
      "grad_norm": 0.5411500334739685,
      "learning_rate": 4.618339841944127e-05,
      "loss": 1.3361,
      "step": 73500
    },
    {
      "epoch": 0.22922984382450748,
      "grad_norm": 0.5956188440322876,
      "learning_rate": 4.618080120843034e-05,
      "loss": 1.3177,
      "step": 73550
    },
    {
      "epoch": 0.22938567648516317,
      "grad_norm": 0.613857626914978,
      "learning_rate": 4.617820399741941e-05,
      "loss": 1.3219,
      "step": 73600
    },
    {
      "epoch": 0.22954150914581886,
      "grad_norm": 0.5228366255760193,
      "learning_rate": 4.617560678640849e-05,
      "loss": 1.2672,
      "step": 73650
    },
    {
      "epoch": 0.22969734180647453,
      "grad_norm": 0.7445792555809021,
      "learning_rate": 4.6173009575397556e-05,
      "loss": 1.3079,
      "step": 73700
    },
    {
      "epoch": 0.22985317446713022,
      "grad_norm": 0.6832590699195862,
      "learning_rate": 4.617041236438663e-05,
      "loss": 1.3308,
      "step": 73750
    },
    {
      "epoch": 0.2300090071277859,
      "grad_norm": 0.6676473021507263,
      "learning_rate": 4.61678151533757e-05,
      "loss": 1.302,
      "step": 73800
    },
    {
      "epoch": 0.23016483978844157,
      "grad_norm": 0.5063507556915283,
      "learning_rate": 4.6165217942364774e-05,
      "loss": 1.3165,
      "step": 73850
    },
    {
      "epoch": 0.23032067244909726,
      "grad_norm": 0.6791144609451294,
      "learning_rate": 4.6162620731353846e-05,
      "loss": 1.3221,
      "step": 73900
    },
    {
      "epoch": 0.23047650510975295,
      "grad_norm": 0.6085173487663269,
      "learning_rate": 4.616002352034292e-05,
      "loss": 1.2532,
      "step": 73950
    },
    {
      "epoch": 0.23063233777040862,
      "grad_norm": 0.4614095389842987,
      "learning_rate": 4.615742630933199e-05,
      "loss": 1.2951,
      "step": 74000
    },
    {
      "epoch": 0.2307881704310643,
      "grad_norm": 0.6210775971412659,
      "learning_rate": 4.6154829098321064e-05,
      "loss": 1.2307,
      "step": 74050
    },
    {
      "epoch": 0.23094400309171997,
      "grad_norm": 0.48948371410369873,
      "learning_rate": 4.615223188731013e-05,
      "loss": 1.222,
      "step": 74100
    },
    {
      "epoch": 0.23109983575237567,
      "grad_norm": 0.5536307692527771,
      "learning_rate": 4.61496346762992e-05,
      "loss": 1.3688,
      "step": 74150
    },
    {
      "epoch": 0.23125566841303136,
      "grad_norm": 0.582335889339447,
      "learning_rate": 4.614703746528828e-05,
      "loss": 1.28,
      "step": 74200
    },
    {
      "epoch": 0.23141150107368702,
      "grad_norm": 0.7649626135826111,
      "learning_rate": 4.614444025427735e-05,
      "loss": 1.2661,
      "step": 74250
    },
    {
      "epoch": 0.2315673337343427,
      "grad_norm": 0.4314311742782593,
      "learning_rate": 4.614184304326642e-05,
      "loss": 1.2803,
      "step": 74300
    },
    {
      "epoch": 0.2317231663949984,
      "grad_norm": 0.709029495716095,
      "learning_rate": 4.61392458322555e-05,
      "loss": 1.2899,
      "step": 74350
    },
    {
      "epoch": 0.23187899905565407,
      "grad_norm": 0.5977361798286438,
      "learning_rate": 4.6136648621244564e-05,
      "loss": 1.2833,
      "step": 74400
    },
    {
      "epoch": 0.23203483171630976,
      "grad_norm": 0.7451409697532654,
      "learning_rate": 4.613405141023364e-05,
      "loss": 1.3304,
      "step": 74450
    },
    {
      "epoch": 0.23219066437696545,
      "grad_norm": 0.5732812285423279,
      "learning_rate": 4.613145419922271e-05,
      "loss": 1.281,
      "step": 74500
    },
    {
      "epoch": 0.2323464970376211,
      "grad_norm": 0.5096186995506287,
      "learning_rate": 4.612885698821178e-05,
      "loss": 1.3106,
      "step": 74550
    },
    {
      "epoch": 0.2325023296982768,
      "grad_norm": 0.6808014512062073,
      "learning_rate": 4.6126311721421074e-05,
      "loss": 1.3898,
      "step": 74600
    },
    {
      "epoch": 0.2326581623589325,
      "grad_norm": 0.6214515566825867,
      "learning_rate": 4.612371451041014e-05,
      "loss": 1.3078,
      "step": 74650
    },
    {
      "epoch": 0.23281399501958816,
      "grad_norm": 0.5926674604415894,
      "learning_rate": 4.612111729939921e-05,
      "loss": 1.2158,
      "step": 74700
    },
    {
      "epoch": 0.23296982768024385,
      "grad_norm": 0.5435240268707275,
      "learning_rate": 4.611852008838829e-05,
      "loss": 1.2607,
      "step": 74750
    },
    {
      "epoch": 0.23312566034089952,
      "grad_norm": 0.6387382745742798,
      "learning_rate": 4.611592287737736e-05,
      "loss": 1.2726,
      "step": 74800
    },
    {
      "epoch": 0.2332814930015552,
      "grad_norm": 0.6734755039215088,
      "learning_rate": 4.611332566636643e-05,
      "loss": 1.2656,
      "step": 74850
    },
    {
      "epoch": 0.2334373256622109,
      "grad_norm": 0.6931257247924805,
      "learning_rate": 4.61107284553555e-05,
      "loss": 1.2902,
      "step": 74900
    },
    {
      "epoch": 0.23359315832286656,
      "grad_norm": 0.6530857682228088,
      "learning_rate": 4.6108131244344575e-05,
      "loss": 1.3127,
      "step": 74950
    },
    {
      "epoch": 0.23374899098352225,
      "grad_norm": 0.6114856004714966,
      "learning_rate": 4.610553403333365e-05,
      "loss": 1.2923,
      "step": 75000
    },
    {
      "epoch": 0.23390482364417794,
      "grad_norm": 0.5969224572181702,
      "learning_rate": 4.610293682232272e-05,
      "loss": 1.3287,
      "step": 75050
    },
    {
      "epoch": 0.2340606563048336,
      "grad_norm": 0.6447217464447021,
      "learning_rate": 4.610033961131179e-05,
      "loss": 1.278,
      "step": 75100
    },
    {
      "epoch": 0.2342164889654893,
      "grad_norm": 0.6092022061347961,
      "learning_rate": 4.6097742400300865e-05,
      "loss": 1.297,
      "step": 75150
    },
    {
      "epoch": 0.234372321626145,
      "grad_norm": 0.5810270309448242,
      "learning_rate": 4.609514518928994e-05,
      "loss": 1.2922,
      "step": 75200
    },
    {
      "epoch": 0.23452815428680066,
      "grad_norm": 0.7039566040039062,
      "learning_rate": 4.6092547978279e-05,
      "loss": 1.274,
      "step": 75250
    },
    {
      "epoch": 0.23468398694745635,
      "grad_norm": 0.6150133013725281,
      "learning_rate": 4.608995076726808e-05,
      "loss": 1.2687,
      "step": 75300
    },
    {
      "epoch": 0.23483981960811204,
      "grad_norm": 0.629364013671875,
      "learning_rate": 4.608735355625715e-05,
      "loss": 1.329,
      "step": 75350
    },
    {
      "epoch": 0.2349956522687677,
      "grad_norm": 0.47224631905555725,
      "learning_rate": 4.608475634524622e-05,
      "loss": 1.3268,
      "step": 75400
    },
    {
      "epoch": 0.2351514849294234,
      "grad_norm": 0.535197377204895,
      "learning_rate": 4.60821591342353e-05,
      "loss": 1.2754,
      "step": 75450
    },
    {
      "epoch": 0.23530731759007906,
      "grad_norm": 0.5683671236038208,
      "learning_rate": 4.6079561923224366e-05,
      "loss": 1.3026,
      "step": 75500
    },
    {
      "epoch": 0.23546315025073475,
      "grad_norm": 0.5500588417053223,
      "learning_rate": 4.607696471221344e-05,
      "loss": 1.3208,
      "step": 75550
    },
    {
      "epoch": 0.23561898291139044,
      "grad_norm": 0.5358873009681702,
      "learning_rate": 4.607436750120251e-05,
      "loss": 1.3118,
      "step": 75600
    },
    {
      "epoch": 0.2357748155720461,
      "grad_norm": 0.6396069526672363,
      "learning_rate": 4.607177029019158e-05,
      "loss": 1.2985,
      "step": 75650
    },
    {
      "epoch": 0.2359306482327018,
      "grad_norm": 0.6249249577522278,
      "learning_rate": 4.6069173079180656e-05,
      "loss": 1.2933,
      "step": 75700
    },
    {
      "epoch": 0.2360864808933575,
      "grad_norm": 0.6301833987236023,
      "learning_rate": 4.606657586816973e-05,
      "loss": 1.3344,
      "step": 75750
    },
    {
      "epoch": 0.23624231355401315,
      "grad_norm": 0.6244150996208191,
      "learning_rate": 4.6063978657158794e-05,
      "loss": 1.2265,
      "step": 75800
    },
    {
      "epoch": 0.23639814621466884,
      "grad_norm": 0.7013332843780518,
      "learning_rate": 4.606138144614787e-05,
      "loss": 1.2557,
      "step": 75850
    },
    {
      "epoch": 0.23655397887532453,
      "grad_norm": 0.5582396388053894,
      "learning_rate": 4.6058784235136946e-05,
      "loss": 1.3168,
      "step": 75900
    },
    {
      "epoch": 0.2367098115359802,
      "grad_norm": 0.757702112197876,
      "learning_rate": 4.605618702412601e-05,
      "loss": 1.2864,
      "step": 75950
    },
    {
      "epoch": 0.2368656441966359,
      "grad_norm": 0.5092594027519226,
      "learning_rate": 4.605358981311509e-05,
      "loss": 1.3026,
      "step": 76000
    },
    {
      "epoch": 0.23702147685729158,
      "grad_norm": 0.5936386585235596,
      "learning_rate": 4.6050992602104156e-05,
      "loss": 1.2361,
      "step": 76050
    },
    {
      "epoch": 0.23717730951794724,
      "grad_norm": 0.7020496129989624,
      "learning_rate": 4.604839539109323e-05,
      "loss": 1.2419,
      "step": 76100
    },
    {
      "epoch": 0.23733314217860293,
      "grad_norm": 0.5075629353523254,
      "learning_rate": 4.60457981800823e-05,
      "loss": 1.2543,
      "step": 76150
    },
    {
      "epoch": 0.2374889748392586,
      "grad_norm": 0.6495800614356995,
      "learning_rate": 4.6043200969071374e-05,
      "loss": 1.3196,
      "step": 76200
    },
    {
      "epoch": 0.2376448074999143,
      "grad_norm": 0.5867325067520142,
      "learning_rate": 4.6040603758060446e-05,
      "loss": 1.2724,
      "step": 76250
    },
    {
      "epoch": 0.23780064016056998,
      "grad_norm": 0.4871244430541992,
      "learning_rate": 4.603800654704952e-05,
      "loss": 1.2874,
      "step": 76300
    },
    {
      "epoch": 0.23795647282122565,
      "grad_norm": 0.622615396976471,
      "learning_rate": 4.603540933603859e-05,
      "loss": 1.2952,
      "step": 76350
    },
    {
      "epoch": 0.23811230548188134,
      "grad_norm": 0.5532708168029785,
      "learning_rate": 4.6032812125027664e-05,
      "loss": 1.2795,
      "step": 76400
    },
    {
      "epoch": 0.23826813814253703,
      "grad_norm": 0.5001797676086426,
      "learning_rate": 4.6030214914016736e-05,
      "loss": 1.288,
      "step": 76450
    },
    {
      "epoch": 0.2384239708031927,
      "grad_norm": 0.5992991328239441,
      "learning_rate": 4.60276177030058e-05,
      "loss": 1.2567,
      "step": 76500
    },
    {
      "epoch": 0.23857980346384838,
      "grad_norm": 0.6636461019515991,
      "learning_rate": 4.602502049199488e-05,
      "loss": 1.2843,
      "step": 76550
    },
    {
      "epoch": 0.23873563612450407,
      "grad_norm": 0.5596132278442383,
      "learning_rate": 4.6022423280983954e-05,
      "loss": 1.3314,
      "step": 76600
    },
    {
      "epoch": 0.23889146878515974,
      "grad_norm": 0.7188637256622314,
      "learning_rate": 4.601982606997302e-05,
      "loss": 1.3308,
      "step": 76650
    },
    {
      "epoch": 0.23904730144581543,
      "grad_norm": 0.6429800987243652,
      "learning_rate": 4.60172288589621e-05,
      "loss": 1.2938,
      "step": 76700
    },
    {
      "epoch": 0.2392031341064711,
      "grad_norm": 0.6637905836105347,
      "learning_rate": 4.6014631647951165e-05,
      "loss": 1.3301,
      "step": 76750
    },
    {
      "epoch": 0.23935896676712679,
      "grad_norm": 0.5810577273368835,
      "learning_rate": 4.601203443694024e-05,
      "loss": 1.2666,
      "step": 76800
    },
    {
      "epoch": 0.23951479942778248,
      "grad_norm": 0.5039186477661133,
      "learning_rate": 4.600943722592931e-05,
      "loss": 1.2808,
      "step": 76850
    },
    {
      "epoch": 0.23967063208843814,
      "grad_norm": 0.6417985558509827,
      "learning_rate": 4.600684001491838e-05,
      "loss": 1.2673,
      "step": 76900
    },
    {
      "epoch": 0.23982646474909383,
      "grad_norm": 0.6685624718666077,
      "learning_rate": 4.6004242803907455e-05,
      "loss": 1.2239,
      "step": 76950
    },
    {
      "epoch": 0.23998229740974952,
      "grad_norm": 0.667351484298706,
      "learning_rate": 4.600164559289653e-05,
      "loss": 1.1985,
      "step": 77000
    },
    {
      "epoch": 0.2401381300704052,
      "grad_norm": 0.5203225016593933,
      "learning_rate": 4.599904838188559e-05,
      "loss": 1.2769,
      "step": 77050
    },
    {
      "epoch": 0.24029396273106088,
      "grad_norm": 0.4758932888507843,
      "learning_rate": 4.599645117087467e-05,
      "loss": 1.3245,
      "step": 77100
    },
    {
      "epoch": 0.24044979539171657,
      "grad_norm": 0.6451480388641357,
      "learning_rate": 4.5993853959863745e-05,
      "loss": 1.2858,
      "step": 77150
    },
    {
      "epoch": 0.24060562805237223,
      "grad_norm": 0.5684905648231506,
      "learning_rate": 4.599125674885281e-05,
      "loss": 1.289,
      "step": 77200
    },
    {
      "epoch": 0.24076146071302792,
      "grad_norm": 0.6385517716407776,
      "learning_rate": 4.598865953784189e-05,
      "loss": 1.2507,
      "step": 77250
    },
    {
      "epoch": 0.24091729337368362,
      "grad_norm": 0.5189354419708252,
      "learning_rate": 4.5986062326830955e-05,
      "loss": 1.2781,
      "step": 77300
    },
    {
      "epoch": 0.24107312603433928,
      "grad_norm": 0.5467830300331116,
      "learning_rate": 4.598346511582003e-05,
      "loss": 1.291,
      "step": 77350
    },
    {
      "epoch": 0.24122895869499497,
      "grad_norm": 0.5707492232322693,
      "learning_rate": 4.59808679048091e-05,
      "loss": 1.3421,
      "step": 77400
    },
    {
      "epoch": 0.24138479135565064,
      "grad_norm": 0.6309916973114014,
      "learning_rate": 4.597827069379817e-05,
      "loss": 1.2908,
      "step": 77450
    },
    {
      "epoch": 0.24154062401630633,
      "grad_norm": 0.5995920300483704,
      "learning_rate": 4.5975673482787245e-05,
      "loss": 1.317,
      "step": 77500
    },
    {
      "epoch": 0.24169645667696202,
      "grad_norm": 0.5592604875564575,
      "learning_rate": 4.597307627177632e-05,
      "loss": 1.3039,
      "step": 77550
    },
    {
      "epoch": 0.24185228933761768,
      "grad_norm": 0.6691204309463501,
      "learning_rate": 4.597047906076539e-05,
      "loss": 1.3144,
      "step": 77600
    },
    {
      "epoch": 0.24200812199827337,
      "grad_norm": 0.688119649887085,
      "learning_rate": 4.596788184975446e-05,
      "loss": 1.2719,
      "step": 77650
    },
    {
      "epoch": 0.24216395465892906,
      "grad_norm": 0.516312301158905,
      "learning_rate": 4.5965284638743535e-05,
      "loss": 1.2799,
      "step": 77700
    },
    {
      "epoch": 0.24231978731958473,
      "grad_norm": 0.5335947871208191,
      "learning_rate": 4.59626874277326e-05,
      "loss": 1.2919,
      "step": 77750
    },
    {
      "epoch": 0.24247561998024042,
      "grad_norm": 0.6216434836387634,
      "learning_rate": 4.596009021672168e-05,
      "loss": 1.3169,
      "step": 77800
    },
    {
      "epoch": 0.2426314526408961,
      "grad_norm": 0.4849635660648346,
      "learning_rate": 4.595749300571075e-05,
      "loss": 1.3097,
      "step": 77850
    },
    {
      "epoch": 0.24278728530155178,
      "grad_norm": 0.6191376447677612,
      "learning_rate": 4.595489579469982e-05,
      "loss": 1.2668,
      "step": 77900
    },
    {
      "epoch": 0.24294311796220747,
      "grad_norm": 0.5080739259719849,
      "learning_rate": 4.59522985836889e-05,
      "loss": 1.2906,
      "step": 77950
    },
    {
      "epoch": 0.24309895062286316,
      "grad_norm": 0.6187155246734619,
      "learning_rate": 4.5949701372677964e-05,
      "loss": 1.2395,
      "step": 78000
    },
    {
      "epoch": 0.24325478328351882,
      "grad_norm": 0.5383922457695007,
      "learning_rate": 4.5947104161667036e-05,
      "loss": 1.2656,
      "step": 78050
    },
    {
      "epoch": 0.2434106159441745,
      "grad_norm": 0.5913935303688049,
      "learning_rate": 4.594450695065611e-05,
      "loss": 1.2429,
      "step": 78100
    },
    {
      "epoch": 0.24356644860483018,
      "grad_norm": 0.5097468495368958,
      "learning_rate": 4.594190973964518e-05,
      "loss": 1.3542,
      "step": 78150
    },
    {
      "epoch": 0.24372228126548587,
      "grad_norm": 0.5657509565353394,
      "learning_rate": 4.5939312528634254e-05,
      "loss": 1.2617,
      "step": 78200
    },
    {
      "epoch": 0.24387811392614156,
      "grad_norm": 0.6034310460090637,
      "learning_rate": 4.5936715317623326e-05,
      "loss": 1.2603,
      "step": 78250
    },
    {
      "epoch": 0.24403394658679722,
      "grad_norm": 0.6543072462081909,
      "learning_rate": 4.593411810661239e-05,
      "loss": 1.2793,
      "step": 78300
    },
    {
      "epoch": 0.24418977924745291,
      "grad_norm": 0.6545208692550659,
      "learning_rate": 4.593152089560147e-05,
      "loss": 1.23,
      "step": 78350
    },
    {
      "epoch": 0.2443456119081086,
      "grad_norm": 0.5291104912757874,
      "learning_rate": 4.5928923684590544e-05,
      "loss": 1.3234,
      "step": 78400
    },
    {
      "epoch": 0.24450144456876427,
      "grad_norm": 0.5951617360115051,
      "learning_rate": 4.592632647357961e-05,
      "loss": 1.3096,
      "step": 78450
    },
    {
      "epoch": 0.24465727722941996,
      "grad_norm": 0.6951316595077515,
      "learning_rate": 4.592372926256869e-05,
      "loss": 1.3088,
      "step": 78500
    },
    {
      "epoch": 0.24481310989007565,
      "grad_norm": 0.5203333497047424,
      "learning_rate": 4.592113205155776e-05,
      "loss": 1.2912,
      "step": 78550
    },
    {
      "epoch": 0.24496894255073132,
      "grad_norm": 0.7288040518760681,
      "learning_rate": 4.591853484054683e-05,
      "loss": 1.286,
      "step": 78600
    },
    {
      "epoch": 0.245124775211387,
      "grad_norm": 0.5122436285018921,
      "learning_rate": 4.59159376295359e-05,
      "loss": 1.3429,
      "step": 78650
    },
    {
      "epoch": 0.24528060787204267,
      "grad_norm": 0.5654112696647644,
      "learning_rate": 4.591334041852497e-05,
      "loss": 1.2697,
      "step": 78700
    },
    {
      "epoch": 0.24543644053269836,
      "grad_norm": 0.7556186318397522,
      "learning_rate": 4.5910743207514044e-05,
      "loss": 1.3129,
      "step": 78750
    },
    {
      "epoch": 0.24559227319335405,
      "grad_norm": 0.4935595691204071,
      "learning_rate": 4.5908197940723337e-05,
      "loss": 1.315,
      "step": 78800
    },
    {
      "epoch": 0.24574810585400972,
      "grad_norm": 0.6311109066009521,
      "learning_rate": 4.590560072971241e-05,
      "loss": 1.2777,
      "step": 78850
    },
    {
      "epoch": 0.2459039385146654,
      "grad_norm": 0.6602144241333008,
      "learning_rate": 4.590300351870148e-05,
      "loss": 1.2048,
      "step": 78900
    },
    {
      "epoch": 0.2460597711753211,
      "grad_norm": 0.6622995138168335,
      "learning_rate": 4.5900406307690554e-05,
      "loss": 1.2901,
      "step": 78950
    },
    {
      "epoch": 0.24621560383597677,
      "grad_norm": 0.6864298582077026,
      "learning_rate": 4.589780909667962e-05,
      "loss": 1.3042,
      "step": 79000
    },
    {
      "epoch": 0.24637143649663246,
      "grad_norm": 0.7986307144165039,
      "learning_rate": 4.589521188566869e-05,
      "loss": 1.3055,
      "step": 79050
    },
    {
      "epoch": 0.24652726915728815,
      "grad_norm": 0.5294826626777649,
      "learning_rate": 4.589261467465777e-05,
      "loss": 1.2883,
      "step": 79100
    },
    {
      "epoch": 0.2466831018179438,
      "grad_norm": 0.7019808888435364,
      "learning_rate": 4.589001746364684e-05,
      "loss": 1.3177,
      "step": 79150
    },
    {
      "epoch": 0.2468389344785995,
      "grad_norm": 0.5301319360733032,
      "learning_rate": 4.588742025263591e-05,
      "loss": 1.2697,
      "step": 79200
    },
    {
      "epoch": 0.2469947671392552,
      "grad_norm": 0.6391617655754089,
      "learning_rate": 4.588482304162499e-05,
      "loss": 1.2749,
      "step": 79250
    },
    {
      "epoch": 0.24715059979991086,
      "grad_norm": 0.5405246615409851,
      "learning_rate": 4.5882225830614055e-05,
      "loss": 1.3291,
      "step": 79300
    },
    {
      "epoch": 0.24730643246056655,
      "grad_norm": 0.5661253929138184,
      "learning_rate": 4.587962861960313e-05,
      "loss": 1.3648,
      "step": 79350
    },
    {
      "epoch": 0.2474622651212222,
      "grad_norm": 0.5902490615844727,
      "learning_rate": 4.58770314085922e-05,
      "loss": 1.3006,
      "step": 79400
    },
    {
      "epoch": 0.2476180977818779,
      "grad_norm": 0.6764198541641235,
      "learning_rate": 4.587443419758127e-05,
      "loss": 1.277,
      "step": 79450
    },
    {
      "epoch": 0.2477739304425336,
      "grad_norm": 0.5784648656845093,
      "learning_rate": 4.5871836986570345e-05,
      "loss": 1.3407,
      "step": 79500
    },
    {
      "epoch": 0.24792976310318926,
      "grad_norm": 0.5986754298210144,
      "learning_rate": 4.586923977555941e-05,
      "loss": 1.2893,
      "step": 79550
    },
    {
      "epoch": 0.24808559576384495,
      "grad_norm": 0.6897023916244507,
      "learning_rate": 4.586664256454849e-05,
      "loss": 1.2677,
      "step": 79600
    },
    {
      "epoch": 0.24824142842450064,
      "grad_norm": 0.6593602299690247,
      "learning_rate": 4.586404535353756e-05,
      "loss": 1.3311,
      "step": 79650
    },
    {
      "epoch": 0.2483972610851563,
      "grad_norm": 0.6085437536239624,
      "learning_rate": 4.586144814252663e-05,
      "loss": 1.2918,
      "step": 79700
    },
    {
      "epoch": 0.248553093745812,
      "grad_norm": 0.5363956689834595,
      "learning_rate": 4.58588509315157e-05,
      "loss": 1.2475,
      "step": 79750
    },
    {
      "epoch": 0.2487089264064677,
      "grad_norm": 0.7886404395103455,
      "learning_rate": 4.585625372050478e-05,
      "loss": 1.2556,
      "step": 79800
    },
    {
      "epoch": 0.24886475906712335,
      "grad_norm": 0.5461465120315552,
      "learning_rate": 4.5853656509493846e-05,
      "loss": 1.307,
      "step": 79850
    },
    {
      "epoch": 0.24902059172777904,
      "grad_norm": 0.4164615869522095,
      "learning_rate": 4.585105929848292e-05,
      "loss": 1.3048,
      "step": 79900
    },
    {
      "epoch": 0.24917642438843474,
      "grad_norm": 0.7136761546134949,
      "learning_rate": 4.584846208747199e-05,
      "loss": 1.2971,
      "step": 79950
    },
    {
      "epoch": 0.2493322570490904,
      "grad_norm": 0.7377680540084839,
      "learning_rate": 4.584586487646106e-05,
      "loss": 1.2582,
      "step": 80000
    },
    {
      "epoch": 0.2494880897097461,
      "grad_norm": 0.5250226259231567,
      "learning_rate": 4.5843267665450136e-05,
      "loss": 1.2539,
      "step": 80050
    },
    {
      "epoch": 0.24964392237040176,
      "grad_norm": 0.5304407477378845,
      "learning_rate": 4.584067045443921e-05,
      "loss": 1.2648,
      "step": 80100
    },
    {
      "epoch": 0.24979975503105745,
      "grad_norm": 0.6282007098197937,
      "learning_rate": 4.583807324342828e-05,
      "loss": 1.2791,
      "step": 80150
    },
    {
      "epoch": 0.24995558769171314,
      "grad_norm": 0.547230064868927,
      "learning_rate": 4.583547603241735e-05,
      "loss": 1.3136,
      "step": 80200
    },
    {
      "epoch": 0.25011142035236883,
      "grad_norm": 0.5064212679862976,
      "learning_rate": 4.583287882140642e-05,
      "loss": 1.2824,
      "step": 80250
    },
    {
      "epoch": 0.2502672530130245,
      "grad_norm": 0.7569674849510193,
      "learning_rate": 4.583028161039549e-05,
      "loss": 1.241,
      "step": 80300
    },
    {
      "epoch": 0.25042308567368016,
      "grad_norm": 0.583357572555542,
      "learning_rate": 4.582768439938457e-05,
      "loss": 1.3504,
      "step": 80350
    },
    {
      "epoch": 0.2505789183343359,
      "grad_norm": 0.5195572972297668,
      "learning_rate": 4.5825087188373636e-05,
      "loss": 1.3046,
      "step": 80400
    },
    {
      "epoch": 0.25073475099499154,
      "grad_norm": 0.4808945953845978,
      "learning_rate": 4.582248997736271e-05,
      "loss": 1.2959,
      "step": 80450
    },
    {
      "epoch": 0.2508905836556472,
      "grad_norm": 0.47794362902641296,
      "learning_rate": 4.581989276635179e-05,
      "loss": 1.2789,
      "step": 80500
    },
    {
      "epoch": 0.2510464163163029,
      "grad_norm": 0.5360226035118103,
      "learning_rate": 4.5817295555340854e-05,
      "loss": 1.2395,
      "step": 80550
    },
    {
      "epoch": 0.2512022489769586,
      "grad_norm": 0.6140544414520264,
      "learning_rate": 4.5814698344329926e-05,
      "loss": 1.2613,
      "step": 80600
    },
    {
      "epoch": 0.25135808163761425,
      "grad_norm": 0.5352336168289185,
      "learning_rate": 4.5812101133319e-05,
      "loss": 1.2774,
      "step": 80650
    },
    {
      "epoch": 0.25151391429826997,
      "grad_norm": 0.6317477226257324,
      "learning_rate": 4.580950392230807e-05,
      "loss": 1.2928,
      "step": 80700
    },
    {
      "epoch": 0.25166974695892563,
      "grad_norm": 0.5884549617767334,
      "learning_rate": 4.5806906711297144e-05,
      "loss": 1.2475,
      "step": 80750
    },
    {
      "epoch": 0.2518255796195813,
      "grad_norm": 0.5632742047309875,
      "learning_rate": 4.5804309500286216e-05,
      "loss": 1.307,
      "step": 80800
    },
    {
      "epoch": 0.251981412280237,
      "grad_norm": 0.7146185636520386,
      "learning_rate": 4.580171228927529e-05,
      "loss": 1.313,
      "step": 80850
    },
    {
      "epoch": 0.2521372449408927,
      "grad_norm": 0.4831809103488922,
      "learning_rate": 4.579911507826436e-05,
      "loss": 1.314,
      "step": 80900
    },
    {
      "epoch": 0.25229307760154834,
      "grad_norm": 0.6504733562469482,
      "learning_rate": 4.579651786725343e-05,
      "loss": 1.2716,
      "step": 80950
    },
    {
      "epoch": 0.252448910262204,
      "grad_norm": 0.5283527374267578,
      "learning_rate": 4.57939206562425e-05,
      "loss": 1.2766,
      "step": 81000
    },
    {
      "epoch": 0.2526047429228597,
      "grad_norm": 0.5459429025650024,
      "learning_rate": 4.579132344523158e-05,
      "loss": 1.3062,
      "step": 81050
    },
    {
      "epoch": 0.2527605755835154,
      "grad_norm": 0.7217633128166199,
      "learning_rate": 4.5788726234220645e-05,
      "loss": 1.2777,
      "step": 81100
    },
    {
      "epoch": 0.25291640824417105,
      "grad_norm": 0.623176634311676,
      "learning_rate": 4.578612902320972e-05,
      "loss": 1.3402,
      "step": 81150
    },
    {
      "epoch": 0.2530722409048268,
      "grad_norm": 0.5629448294639587,
      "learning_rate": 4.5783531812198796e-05,
      "loss": 1.2865,
      "step": 81200
    },
    {
      "epoch": 0.25322807356548244,
      "grad_norm": 0.5487751960754395,
      "learning_rate": 4.578093460118786e-05,
      "loss": 1.2697,
      "step": 81250
    },
    {
      "epoch": 0.2533839062261381,
      "grad_norm": 0.7594932317733765,
      "learning_rate": 4.5778337390176935e-05,
      "loss": 1.3241,
      "step": 81300
    },
    {
      "epoch": 0.2535397388867938,
      "grad_norm": 0.6269635558128357,
      "learning_rate": 4.577574017916601e-05,
      "loss": 1.2756,
      "step": 81350
    },
    {
      "epoch": 0.2536955715474495,
      "grad_norm": 0.5294318795204163,
      "learning_rate": 4.577319491237529e-05,
      "loss": 1.2756,
      "step": 81400
    },
    {
      "epoch": 0.25385140420810515,
      "grad_norm": 0.583104133605957,
      "learning_rate": 4.577059770136437e-05,
      "loss": 1.2803,
      "step": 81450
    },
    {
      "epoch": 0.25400723686876087,
      "grad_norm": 0.6475543975830078,
      "learning_rate": 4.5768000490353444e-05,
      "loss": 1.279,
      "step": 81500
    },
    {
      "epoch": 0.25416306952941653,
      "grad_norm": 0.5847091674804688,
      "learning_rate": 4.576540327934251e-05,
      "loss": 1.2619,
      "step": 81550
    },
    {
      "epoch": 0.2543189021900722,
      "grad_norm": 0.49943676590919495,
      "learning_rate": 4.576280606833159e-05,
      "loss": 1.252,
      "step": 81600
    },
    {
      "epoch": 0.2544747348507279,
      "grad_norm": 0.7525278329849243,
      "learning_rate": 4.5760208857320655e-05,
      "loss": 1.2604,
      "step": 81650
    },
    {
      "epoch": 0.2546305675113836,
      "grad_norm": 0.603931188583374,
      "learning_rate": 4.575761164630973e-05,
      "loss": 1.2275,
      "step": 81700
    },
    {
      "epoch": 0.25478640017203924,
      "grad_norm": 0.5545457005500793,
      "learning_rate": 4.57550144352988e-05,
      "loss": 1.2531,
      "step": 81750
    },
    {
      "epoch": 0.25494223283269496,
      "grad_norm": 0.5500612854957581,
      "learning_rate": 4.575241722428787e-05,
      "loss": 1.2754,
      "step": 81800
    },
    {
      "epoch": 0.2550980654933506,
      "grad_norm": 0.4567192494869232,
      "learning_rate": 4.5749820013276945e-05,
      "loss": 1.2978,
      "step": 81850
    },
    {
      "epoch": 0.2552538981540063,
      "grad_norm": 0.6230711936950684,
      "learning_rate": 4.574722280226602e-05,
      "loss": 1.3388,
      "step": 81900
    },
    {
      "epoch": 0.255409730814662,
      "grad_norm": 0.6170932054519653,
      "learning_rate": 4.574462559125509e-05,
      "loss": 1.3183,
      "step": 81950
    },
    {
      "epoch": 0.25556556347531767,
      "grad_norm": 0.5693236589431763,
      "learning_rate": 4.574202838024416e-05,
      "loss": 1.3112,
      "step": 82000
    },
    {
      "epoch": 0.25572139613597333,
      "grad_norm": 0.5062043070793152,
      "learning_rate": 4.5739431169233235e-05,
      "loss": 1.2639,
      "step": 82050
    },
    {
      "epoch": 0.25587722879662905,
      "grad_norm": 0.4948459565639496,
      "learning_rate": 4.57368339582223e-05,
      "loss": 1.2675,
      "step": 82100
    },
    {
      "epoch": 0.2560330614572847,
      "grad_norm": 0.5767163038253784,
      "learning_rate": 4.573423674721138e-05,
      "loss": 1.2493,
      "step": 82150
    },
    {
      "epoch": 0.2561888941179404,
      "grad_norm": 0.5225650668144226,
      "learning_rate": 4.5731639536200446e-05,
      "loss": 1.3188,
      "step": 82200
    },
    {
      "epoch": 0.2563447267785961,
      "grad_norm": 0.47443124651908875,
      "learning_rate": 4.572904232518952e-05,
      "loss": 1.2612,
      "step": 82250
    },
    {
      "epoch": 0.25650055943925176,
      "grad_norm": 0.49568450450897217,
      "learning_rate": 4.572644511417859e-05,
      "loss": 1.3361,
      "step": 82300
    },
    {
      "epoch": 0.2566563920999074,
      "grad_norm": 0.5769704580307007,
      "learning_rate": 4.572384790316766e-05,
      "loss": 1.2962,
      "step": 82350
    },
    {
      "epoch": 0.2568122247605631,
      "grad_norm": 0.6007116436958313,
      "learning_rate": 4.5721250692156736e-05,
      "loss": 1.3261,
      "step": 82400
    },
    {
      "epoch": 0.2569680574212188,
      "grad_norm": 0.5866349935531616,
      "learning_rate": 4.571865348114581e-05,
      "loss": 1.2787,
      "step": 82450
    },
    {
      "epoch": 0.2571238900818745,
      "grad_norm": 0.5911731123924255,
      "learning_rate": 4.571605627013488e-05,
      "loss": 1.2997,
      "step": 82500
    },
    {
      "epoch": 0.25727972274253014,
      "grad_norm": 0.5986641049385071,
      "learning_rate": 4.571345905912395e-05,
      "loss": 1.2849,
      "step": 82550
    },
    {
      "epoch": 0.25743555540318586,
      "grad_norm": 0.6680855751037598,
      "learning_rate": 4.5710861848113026e-05,
      "loss": 1.2923,
      "step": 82600
    },
    {
      "epoch": 0.2575913880638415,
      "grad_norm": 0.6190816760063171,
      "learning_rate": 4.570826463710209e-05,
      "loss": 1.3252,
      "step": 82650
    },
    {
      "epoch": 0.2577472207244972,
      "grad_norm": 0.6487060785293579,
      "learning_rate": 4.570566742609117e-05,
      "loss": 1.2871,
      "step": 82700
    },
    {
      "epoch": 0.2579030533851529,
      "grad_norm": 0.6265318989753723,
      "learning_rate": 4.570307021508024e-05,
      "loss": 1.2531,
      "step": 82750
    },
    {
      "epoch": 0.25805888604580857,
      "grad_norm": 0.430514931678772,
      "learning_rate": 4.570047300406931e-05,
      "loss": 1.3373,
      "step": 82800
    },
    {
      "epoch": 0.25821471870646423,
      "grad_norm": 0.5861346125602722,
      "learning_rate": 4.569787579305839e-05,
      "loss": 1.3209,
      "step": 82850
    },
    {
      "epoch": 0.25837055136711995,
      "grad_norm": 0.565089762210846,
      "learning_rate": 4.5695278582047454e-05,
      "loss": 1.2529,
      "step": 82900
    },
    {
      "epoch": 0.2585263840277756,
      "grad_norm": 0.5519312620162964,
      "learning_rate": 4.5692681371036527e-05,
      "loss": 1.291,
      "step": 82950
    },
    {
      "epoch": 0.2586822166884313,
      "grad_norm": 0.669353187084198,
      "learning_rate": 4.56900841600256e-05,
      "loss": 1.2884,
      "step": 83000
    },
    {
      "epoch": 0.258838049349087,
      "grad_norm": 0.6625820994377136,
      "learning_rate": 4.568748694901467e-05,
      "loss": 1.2104,
      "step": 83050
    },
    {
      "epoch": 0.25899388200974266,
      "grad_norm": 0.6424161791801453,
      "learning_rate": 4.5684889738003744e-05,
      "loss": 1.2812,
      "step": 83100
    },
    {
      "epoch": 0.2591497146703983,
      "grad_norm": 0.5512340664863586,
      "learning_rate": 4.5682344471213036e-05,
      "loss": 1.308,
      "step": 83150
    },
    {
      "epoch": 0.25930554733105404,
      "grad_norm": 0.6497212052345276,
      "learning_rate": 4.56797472602021e-05,
      "loss": 1.2975,
      "step": 83200
    },
    {
      "epoch": 0.2594613799917097,
      "grad_norm": 0.45659691095352173,
      "learning_rate": 4.567715004919118e-05,
      "loss": 1.2867,
      "step": 83250
    },
    {
      "epoch": 0.25961721265236537,
      "grad_norm": 0.5545891523361206,
      "learning_rate": 4.5674552838180254e-05,
      "loss": 1.3126,
      "step": 83300
    },
    {
      "epoch": 0.2597730453130211,
      "grad_norm": 0.5637006163597107,
      "learning_rate": 4.567195562716932e-05,
      "loss": 1.284,
      "step": 83350
    },
    {
      "epoch": 0.25992887797367675,
      "grad_norm": 0.6540057063102722,
      "learning_rate": 4.566935841615839e-05,
      "loss": 1.2766,
      "step": 83400
    },
    {
      "epoch": 0.2600847106343324,
      "grad_norm": 0.494385689496994,
      "learning_rate": 4.566676120514747e-05,
      "loss": 1.2443,
      "step": 83450
    },
    {
      "epoch": 0.26024054329498814,
      "grad_norm": 0.5104668140411377,
      "learning_rate": 4.566416399413654e-05,
      "loss": 1.3449,
      "step": 83500
    },
    {
      "epoch": 0.2603963759556438,
      "grad_norm": 0.5445752143859863,
      "learning_rate": 4.566156678312561e-05,
      "loss": 1.2894,
      "step": 83550
    },
    {
      "epoch": 0.26055220861629946,
      "grad_norm": 0.49044206738471985,
      "learning_rate": 4.565896957211468e-05,
      "loss": 1.2392,
      "step": 83600
    },
    {
      "epoch": 0.2607080412769551,
      "grad_norm": 0.8458634614944458,
      "learning_rate": 4.5656372361103754e-05,
      "loss": 1.2883,
      "step": 83650
    },
    {
      "epoch": 0.26086387393761085,
      "grad_norm": 0.4892648458480835,
      "learning_rate": 4.565377515009283e-05,
      "loss": 1.279,
      "step": 83700
    },
    {
      "epoch": 0.2610197065982665,
      "grad_norm": 0.5816143155097961,
      "learning_rate": 4.56511779390819e-05,
      "loss": 1.3127,
      "step": 83750
    },
    {
      "epoch": 0.2611755392589222,
      "grad_norm": 0.5470326542854309,
      "learning_rate": 4.564858072807097e-05,
      "loss": 1.2608,
      "step": 83800
    },
    {
      "epoch": 0.2613313719195779,
      "grad_norm": 0.6689218282699585,
      "learning_rate": 4.5645983517060044e-05,
      "loss": 1.3129,
      "step": 83850
    },
    {
      "epoch": 0.26148720458023356,
      "grad_norm": 0.5353822708129883,
      "learning_rate": 4.564338630604911e-05,
      "loss": 1.2631,
      "step": 83900
    },
    {
      "epoch": 0.2616430372408892,
      "grad_norm": 0.46757256984710693,
      "learning_rate": 4.564078909503819e-05,
      "loss": 1.2937,
      "step": 83950
    },
    {
      "epoch": 0.26179886990154494,
      "grad_norm": 0.6434746980667114,
      "learning_rate": 4.563819188402726e-05,
      "loss": 1.3304,
      "step": 84000
    },
    {
      "epoch": 0.2619547025622006,
      "grad_norm": 0.6625784039497375,
      "learning_rate": 4.563559467301633e-05,
      "loss": 1.2732,
      "step": 84050
    },
    {
      "epoch": 0.26211053522285627,
      "grad_norm": 0.5427460074424744,
      "learning_rate": 4.56329974620054e-05,
      "loss": 1.2766,
      "step": 84100
    },
    {
      "epoch": 0.262266367883512,
      "grad_norm": 0.7200298309326172,
      "learning_rate": 4.563040025099448e-05,
      "loss": 1.2792,
      "step": 84150
    },
    {
      "epoch": 0.26242220054416765,
      "grad_norm": 0.6540895700454712,
      "learning_rate": 4.5627803039983545e-05,
      "loss": 1.2695,
      "step": 84200
    },
    {
      "epoch": 0.2625780332048233,
      "grad_norm": 0.6394543051719666,
      "learning_rate": 4.562520582897262e-05,
      "loss": 1.246,
      "step": 84250
    },
    {
      "epoch": 0.26273386586547903,
      "grad_norm": 0.5494763255119324,
      "learning_rate": 4.562260861796169e-05,
      "loss": 1.2869,
      "step": 84300
    },
    {
      "epoch": 0.2628896985261347,
      "grad_norm": 0.715196967124939,
      "learning_rate": 4.562001140695076e-05,
      "loss": 1.3124,
      "step": 84350
    },
    {
      "epoch": 0.26304553118679036,
      "grad_norm": 0.5641338229179382,
      "learning_rate": 4.5617414195939835e-05,
      "loss": 1.2437,
      "step": 84400
    },
    {
      "epoch": 0.2632013638474461,
      "grad_norm": 0.7060596346855164,
      "learning_rate": 4.56148169849289e-05,
      "loss": 1.3044,
      "step": 84450
    },
    {
      "epoch": 0.26335719650810174,
      "grad_norm": 0.6842904090881348,
      "learning_rate": 4.561221977391798e-05,
      "loss": 1.2462,
      "step": 84500
    },
    {
      "epoch": 0.2635130291687574,
      "grad_norm": 0.7185524106025696,
      "learning_rate": 4.560962256290705e-05,
      "loss": 1.3179,
      "step": 84550
    },
    {
      "epoch": 0.2636688618294131,
      "grad_norm": 0.5901867747306824,
      "learning_rate": 4.560702535189612e-05,
      "loss": 1.3145,
      "step": 84600
    },
    {
      "epoch": 0.2638246944900688,
      "grad_norm": 0.5830810070037842,
      "learning_rate": 4.560442814088519e-05,
      "loss": 1.2568,
      "step": 84650
    },
    {
      "epoch": 0.26398052715072445,
      "grad_norm": 0.5661691427230835,
      "learning_rate": 4.560183092987427e-05,
      "loss": 1.2716,
      "step": 84700
    },
    {
      "epoch": 0.2641363598113802,
      "grad_norm": 0.6351439356803894,
      "learning_rate": 4.5599233718863336e-05,
      "loss": 1.3316,
      "step": 84750
    },
    {
      "epoch": 0.26429219247203584,
      "grad_norm": 0.661577582359314,
      "learning_rate": 4.559663650785241e-05,
      "loss": 1.3035,
      "step": 84800
    },
    {
      "epoch": 0.2644480251326915,
      "grad_norm": 0.6967508792877197,
      "learning_rate": 4.559403929684148e-05,
      "loss": 1.3075,
      "step": 84850
    },
    {
      "epoch": 0.2646038577933472,
      "grad_norm": 0.5806007385253906,
      "learning_rate": 4.5591442085830553e-05,
      "loss": 1.286,
      "step": 84900
    },
    {
      "epoch": 0.2647596904540029,
      "grad_norm": 0.6083700656890869,
      "learning_rate": 4.5588844874819626e-05,
      "loss": 1.29,
      "step": 84950
    },
    {
      "epoch": 0.26491552311465855,
      "grad_norm": 0.5436133146286011,
      "learning_rate": 4.55862476638087e-05,
      "loss": 1.3154,
      "step": 85000
    },
    {
      "epoch": 0.2650713557753142,
      "grad_norm": 0.5759167075157166,
      "learning_rate": 4.558365045279777e-05,
      "loss": 1.341,
      "step": 85050
    },
    {
      "epoch": 0.26522718843596993,
      "grad_norm": 0.5384543538093567,
      "learning_rate": 4.5581053241786843e-05,
      "loss": 1.3103,
      "step": 85100
    },
    {
      "epoch": 0.2653830210966256,
      "grad_norm": 0.6477901935577393,
      "learning_rate": 4.557845603077591e-05,
      "loss": 1.262,
      "step": 85150
    },
    {
      "epoch": 0.26553885375728126,
      "grad_norm": 0.5784161686897278,
      "learning_rate": 4.557585881976499e-05,
      "loss": 1.2156,
      "step": 85200
    },
    {
      "epoch": 0.265694686417937,
      "grad_norm": 0.651058554649353,
      "learning_rate": 4.557326160875406e-05,
      "loss": 1.2931,
      "step": 85250
    },
    {
      "epoch": 0.26585051907859264,
      "grad_norm": 0.5347767472267151,
      "learning_rate": 4.557066439774313e-05,
      "loss": 1.2404,
      "step": 85300
    },
    {
      "epoch": 0.2660063517392483,
      "grad_norm": 0.5931082963943481,
      "learning_rate": 4.55680671867322e-05,
      "loss": 1.2691,
      "step": 85350
    },
    {
      "epoch": 0.266162184399904,
      "grad_norm": 0.7155861854553223,
      "learning_rate": 4.556546997572128e-05,
      "loss": 1.2653,
      "step": 85400
    },
    {
      "epoch": 0.2663180170605597,
      "grad_norm": 0.6382118463516235,
      "learning_rate": 4.5562872764710344e-05,
      "loss": 1.2407,
      "step": 85450
    },
    {
      "epoch": 0.26647384972121535,
      "grad_norm": 0.7435847520828247,
      "learning_rate": 4.556027555369942e-05,
      "loss": 1.2917,
      "step": 85500
    },
    {
      "epoch": 0.26662968238187107,
      "grad_norm": 0.48578453063964844,
      "learning_rate": 4.555767834268849e-05,
      "loss": 1.2972,
      "step": 85550
    },
    {
      "epoch": 0.26678551504252673,
      "grad_norm": 0.8409299254417419,
      "learning_rate": 4.555508113167756e-05,
      "loss": 1.3074,
      "step": 85600
    },
    {
      "epoch": 0.2669413477031824,
      "grad_norm": 0.4607927203178406,
      "learning_rate": 4.5552483920666634e-05,
      "loss": 1.24,
      "step": 85650
    },
    {
      "epoch": 0.2670971803638381,
      "grad_norm": 0.5138390064239502,
      "learning_rate": 4.554988670965571e-05,
      "loss": 1.3042,
      "step": 85700
    },
    {
      "epoch": 0.2672530130244938,
      "grad_norm": 0.5464673638343811,
      "learning_rate": 4.554728949864478e-05,
      "loss": 1.317,
      "step": 85750
    },
    {
      "epoch": 0.26740884568514944,
      "grad_norm": 0.5347546935081482,
      "learning_rate": 4.554469228763385e-05,
      "loss": 1.305,
      "step": 85800
    },
    {
      "epoch": 0.26756467834580516,
      "grad_norm": 0.6451399326324463,
      "learning_rate": 4.554209507662292e-05,
      "loss": 1.2723,
      "step": 85850
    },
    {
      "epoch": 0.2677205110064608,
      "grad_norm": 0.5333268046379089,
      "learning_rate": 4.553949786561199e-05,
      "loss": 1.2767,
      "step": 85900
    },
    {
      "epoch": 0.2678763436671165,
      "grad_norm": 0.6594564914703369,
      "learning_rate": 4.553690065460107e-05,
      "loss": 1.2895,
      "step": 85950
    },
    {
      "epoch": 0.2680321763277722,
      "grad_norm": 0.5379328727722168,
      "learning_rate": 4.5534303443590135e-05,
      "loss": 1.2431,
      "step": 86000
    },
    {
      "epoch": 0.2681880089884279,
      "grad_norm": 0.6412636637687683,
      "learning_rate": 4.553170623257921e-05,
      "loss": 1.2808,
      "step": 86050
    },
    {
      "epoch": 0.26834384164908354,
      "grad_norm": 0.5537891387939453,
      "learning_rate": 4.552910902156829e-05,
      "loss": 1.2861,
      "step": 86100
    },
    {
      "epoch": 0.26849967430973926,
      "grad_norm": 0.6035051345825195,
      "learning_rate": 4.552651181055735e-05,
      "loss": 1.328,
      "step": 86150
    },
    {
      "epoch": 0.2686555069703949,
      "grad_norm": 0.6944226622581482,
      "learning_rate": 4.5523914599546425e-05,
      "loss": 1.26,
      "step": 86200
    },
    {
      "epoch": 0.2688113396310506,
      "grad_norm": 0.6961657404899597,
      "learning_rate": 4.55213173885355e-05,
      "loss": 1.3308,
      "step": 86250
    },
    {
      "epoch": 0.26896717229170625,
      "grad_norm": 0.605569064617157,
      "learning_rate": 4.551872017752457e-05,
      "loss": 1.2581,
      "step": 86300
    },
    {
      "epoch": 0.26912300495236197,
      "grad_norm": 0.580876350402832,
      "learning_rate": 4.551612296651364e-05,
      "loss": 1.2967,
      "step": 86350
    },
    {
      "epoch": 0.26927883761301763,
      "grad_norm": 0.5834437608718872,
      "learning_rate": 4.5513525755502715e-05,
      "loss": 1.3805,
      "step": 86400
    },
    {
      "epoch": 0.2694346702736733,
      "grad_norm": 0.8851470351219177,
      "learning_rate": 4.551092854449179e-05,
      "loss": 1.2503,
      "step": 86450
    },
    {
      "epoch": 0.269590502934329,
      "grad_norm": 0.5412924885749817,
      "learning_rate": 4.550833133348086e-05,
      "loss": 1.3416,
      "step": 86500
    },
    {
      "epoch": 0.2697463355949847,
      "grad_norm": 0.5711610913276672,
      "learning_rate": 4.5505734122469926e-05,
      "loss": 1.2258,
      "step": 86550
    },
    {
      "epoch": 0.26990216825564034,
      "grad_norm": 0.6921356320381165,
      "learning_rate": 4.5503136911459e-05,
      "loss": 1.3367,
      "step": 86600
    },
    {
      "epoch": 0.27005800091629606,
      "grad_norm": 0.5513818264007568,
      "learning_rate": 4.550053970044808e-05,
      "loss": 1.2639,
      "step": 86650
    },
    {
      "epoch": 0.2702138335769517,
      "grad_norm": 0.5155803561210632,
      "learning_rate": 4.549794248943714e-05,
      "loss": 1.2101,
      "step": 86700
    },
    {
      "epoch": 0.2703696662376074,
      "grad_norm": 0.7908751368522644,
      "learning_rate": 4.5495397222646435e-05,
      "loss": 1.299,
      "step": 86750
    },
    {
      "epoch": 0.2705254988982631,
      "grad_norm": 0.5515145063400269,
      "learning_rate": 4.549280001163551e-05,
      "loss": 1.3332,
      "step": 86800
    },
    {
      "epoch": 0.27068133155891877,
      "grad_norm": 0.37788644433021545,
      "learning_rate": 4.549020280062458e-05,
      "loss": 1.2563,
      "step": 86850
    },
    {
      "epoch": 0.27083716421957443,
      "grad_norm": 0.5835317969322205,
      "learning_rate": 4.548760558961365e-05,
      "loss": 1.252,
      "step": 86900
    },
    {
      "epoch": 0.27099299688023015,
      "grad_norm": 0.804672122001648,
      "learning_rate": 4.5485008378602725e-05,
      "loss": 1.2363,
      "step": 86950
    },
    {
      "epoch": 0.2711488295408858,
      "grad_norm": 0.6022077202796936,
      "learning_rate": 4.548241116759179e-05,
      "loss": 1.2835,
      "step": 87000
    },
    {
      "epoch": 0.2713046622015415,
      "grad_norm": 0.5252754092216492,
      "learning_rate": 4.547981395658087e-05,
      "loss": 1.2698,
      "step": 87050
    },
    {
      "epoch": 0.2714604948621972,
      "grad_norm": 0.5144023895263672,
      "learning_rate": 4.5477216745569936e-05,
      "loss": 1.303,
      "step": 87100
    },
    {
      "epoch": 0.27161632752285286,
      "grad_norm": 0.5714381337165833,
      "learning_rate": 4.547461953455901e-05,
      "loss": 1.2788,
      "step": 87150
    },
    {
      "epoch": 0.2717721601835085,
      "grad_norm": 0.7098354697227478,
      "learning_rate": 4.547202232354809e-05,
      "loss": 1.264,
      "step": 87200
    },
    {
      "epoch": 0.27192799284416425,
      "grad_norm": 0.6366502642631531,
      "learning_rate": 4.5469425112537154e-05,
      "loss": 1.2885,
      "step": 87250
    },
    {
      "epoch": 0.2720838255048199,
      "grad_norm": 0.5165389776229858,
      "learning_rate": 4.5466827901526226e-05,
      "loss": 1.2934,
      "step": 87300
    },
    {
      "epoch": 0.2722396581654756,
      "grad_norm": 0.6315550208091736,
      "learning_rate": 4.54642306905153e-05,
      "loss": 1.2783,
      "step": 87350
    },
    {
      "epoch": 0.2723954908261313,
      "grad_norm": 0.7138054966926575,
      "learning_rate": 4.546163347950437e-05,
      "loss": 1.3093,
      "step": 87400
    },
    {
      "epoch": 0.27255132348678696,
      "grad_norm": 0.5123640298843384,
      "learning_rate": 4.5459036268493444e-05,
      "loss": 1.2721,
      "step": 87450
    },
    {
      "epoch": 0.2727071561474426,
      "grad_norm": 0.5342106223106384,
      "learning_rate": 4.5456439057482516e-05,
      "loss": 1.3476,
      "step": 87500
    },
    {
      "epoch": 0.27286298880809834,
      "grad_norm": 0.648418128490448,
      "learning_rate": 4.545384184647159e-05,
      "loss": 1.3011,
      "step": 87550
    },
    {
      "epoch": 0.273018821468754,
      "grad_norm": 0.41025906801223755,
      "learning_rate": 4.545124463546066e-05,
      "loss": 1.2909,
      "step": 87600
    },
    {
      "epoch": 0.27317465412940967,
      "grad_norm": 0.6340295672416687,
      "learning_rate": 4.5448647424449734e-05,
      "loss": 1.3022,
      "step": 87650
    },
    {
      "epoch": 0.27333048679006533,
      "grad_norm": 0.5079700350761414,
      "learning_rate": 4.54460502134388e-05,
      "loss": 1.2935,
      "step": 87700
    },
    {
      "epoch": 0.27348631945072105,
      "grad_norm": 0.780960738658905,
      "learning_rate": 4.544345300242788e-05,
      "loss": 1.2891,
      "step": 87750
    },
    {
      "epoch": 0.2736421521113767,
      "grad_norm": 0.5761730670928955,
      "learning_rate": 4.5440855791416944e-05,
      "loss": 1.2715,
      "step": 87800
    },
    {
      "epoch": 0.2737979847720324,
      "grad_norm": 0.48911619186401367,
      "learning_rate": 4.543825858040602e-05,
      "loss": 1.3001,
      "step": 87850
    },
    {
      "epoch": 0.2739538174326881,
      "grad_norm": 0.5055565237998962,
      "learning_rate": 4.543566136939509e-05,
      "loss": 1.2518,
      "step": 87900
    },
    {
      "epoch": 0.27410965009334376,
      "grad_norm": 0.5436840057373047,
      "learning_rate": 4.543306415838416e-05,
      "loss": 1.2718,
      "step": 87950
    },
    {
      "epoch": 0.2742654827539994,
      "grad_norm": 0.631568193435669,
      "learning_rate": 4.5430466947373234e-05,
      "loss": 1.2828,
      "step": 88000
    },
    {
      "epoch": 0.27442131541465514,
      "grad_norm": 0.5374544262886047,
      "learning_rate": 4.542786973636231e-05,
      "loss": 1.3039,
      "step": 88050
    },
    {
      "epoch": 0.2745771480753108,
      "grad_norm": 0.5560745596885681,
      "learning_rate": 4.542527252535138e-05,
      "loss": 1.2849,
      "step": 88100
    },
    {
      "epoch": 0.27473298073596647,
      "grad_norm": 0.5626310706138611,
      "learning_rate": 4.542267531434045e-05,
      "loss": 1.293,
      "step": 88150
    },
    {
      "epoch": 0.2748888133966222,
      "grad_norm": 0.6296508312225342,
      "learning_rate": 4.5420078103329524e-05,
      "loss": 1.3308,
      "step": 88200
    },
    {
      "epoch": 0.27504464605727785,
      "grad_norm": 0.614829421043396,
      "learning_rate": 4.541748089231859e-05,
      "loss": 1.28,
      "step": 88250
    },
    {
      "epoch": 0.2752004787179335,
      "grad_norm": 0.5984428524971008,
      "learning_rate": 4.541488368130767e-05,
      "loss": 1.27,
      "step": 88300
    },
    {
      "epoch": 0.27535631137858924,
      "grad_norm": 0.5038381218910217,
      "learning_rate": 4.541228647029674e-05,
      "loss": 1.2684,
      "step": 88350
    },
    {
      "epoch": 0.2755121440392449,
      "grad_norm": 0.5347458124160767,
      "learning_rate": 4.540968925928581e-05,
      "loss": 1.2767,
      "step": 88400
    },
    {
      "epoch": 0.27566797669990056,
      "grad_norm": 0.6481102705001831,
      "learning_rate": 4.540709204827489e-05,
      "loss": 1.2759,
      "step": 88450
    },
    {
      "epoch": 0.2758238093605563,
      "grad_norm": 0.495800256729126,
      "learning_rate": 4.540449483726395e-05,
      "loss": 1.3149,
      "step": 88500
    },
    {
      "epoch": 0.27597964202121195,
      "grad_norm": 0.556863009929657,
      "learning_rate": 4.5401897626253025e-05,
      "loss": 1.2925,
      "step": 88550
    },
    {
      "epoch": 0.2761354746818676,
      "grad_norm": 0.46117550134658813,
      "learning_rate": 4.53993004152421e-05,
      "loss": 1.2165,
      "step": 88600
    },
    {
      "epoch": 0.27629130734252333,
      "grad_norm": 0.4846457839012146,
      "learning_rate": 4.539670320423117e-05,
      "loss": 1.2845,
      "step": 88650
    },
    {
      "epoch": 0.276447140003179,
      "grad_norm": 0.5145203471183777,
      "learning_rate": 4.539410599322024e-05,
      "loss": 1.297,
      "step": 88700
    },
    {
      "epoch": 0.27660297266383466,
      "grad_norm": 0.4761006832122803,
      "learning_rate": 4.5391508782209315e-05,
      "loss": 1.2566,
      "step": 88750
    },
    {
      "epoch": 0.2767588053244904,
      "grad_norm": 0.5004494190216064,
      "learning_rate": 4.538891157119839e-05,
      "loss": 1.3023,
      "step": 88800
    },
    {
      "epoch": 0.27691463798514604,
      "grad_norm": 0.6486847996711731,
      "learning_rate": 4.538631436018746e-05,
      "loss": 1.3485,
      "step": 88850
    },
    {
      "epoch": 0.2770704706458017,
      "grad_norm": 0.5594698786735535,
      "learning_rate": 4.538371714917653e-05,
      "loss": 1.2646,
      "step": 88900
    },
    {
      "epoch": 0.27722630330645737,
      "grad_norm": 0.5719640254974365,
      "learning_rate": 4.53811199381656e-05,
      "loss": 1.3121,
      "step": 88950
    },
    {
      "epoch": 0.2773821359671131,
      "grad_norm": 0.7008188366889954,
      "learning_rate": 4.537852272715468e-05,
      "loss": 1.2738,
      "step": 89000
    },
    {
      "epoch": 0.27753796862776875,
      "grad_norm": 0.5592032670974731,
      "learning_rate": 4.537592551614375e-05,
      "loss": 1.3896,
      "step": 89050
    },
    {
      "epoch": 0.2776938012884244,
      "grad_norm": 0.7832217216491699,
      "learning_rate": 4.5373328305132816e-05,
      "loss": 1.3021,
      "step": 89100
    },
    {
      "epoch": 0.27784963394908013,
      "grad_norm": 0.678544282913208,
      "learning_rate": 4.537073109412189e-05,
      "loss": 1.2772,
      "step": 89150
    },
    {
      "epoch": 0.2780054666097358,
      "grad_norm": 0.5557640194892883,
      "learning_rate": 4.536813388311096e-05,
      "loss": 1.2761,
      "step": 89200
    },
    {
      "epoch": 0.27816129927039146,
      "grad_norm": 0.5160665512084961,
      "learning_rate": 4.536553667210003e-05,
      "loss": 1.3024,
      "step": 89250
    },
    {
      "epoch": 0.2783171319310472,
      "grad_norm": 0.6265513896942139,
      "learning_rate": 4.5362939461089106e-05,
      "loss": 1.2664,
      "step": 89300
    },
    {
      "epoch": 0.27847296459170284,
      "grad_norm": 0.6683763265609741,
      "learning_rate": 4.536034225007818e-05,
      "loss": 1.2745,
      "step": 89350
    },
    {
      "epoch": 0.2786287972523585,
      "grad_norm": 0.5529876351356506,
      "learning_rate": 4.535774503906725e-05,
      "loss": 1.2476,
      "step": 89400
    },
    {
      "epoch": 0.2787846299130142,
      "grad_norm": 0.6883140206336975,
      "learning_rate": 4.535514782805632e-05,
      "loss": 1.3028,
      "step": 89450
    },
    {
      "epoch": 0.2789404625736699,
      "grad_norm": 0.5445650815963745,
      "learning_rate": 4.535255061704539e-05,
      "loss": 1.2935,
      "step": 89500
    },
    {
      "epoch": 0.27909629523432555,
      "grad_norm": 0.6189934611320496,
      "learning_rate": 4.534995340603447e-05,
      "loss": 1.3264,
      "step": 89550
    },
    {
      "epoch": 0.2792521278949813,
      "grad_norm": 0.654151439666748,
      "learning_rate": 4.534735619502354e-05,
      "loss": 1.2761,
      "step": 89600
    },
    {
      "epoch": 0.27940796055563694,
      "grad_norm": 0.6435223817825317,
      "learning_rate": 4.534475898401261e-05,
      "loss": 1.2645,
      "step": 89650
    },
    {
      "epoch": 0.2795637932162926,
      "grad_norm": 0.6134451627731323,
      "learning_rate": 4.5342161773001686e-05,
      "loss": 1.2999,
      "step": 89700
    },
    {
      "epoch": 0.2797196258769483,
      "grad_norm": 0.6317881345748901,
      "learning_rate": 4.533956456199075e-05,
      "loss": 1.3003,
      "step": 89750
    },
    {
      "epoch": 0.279875458537604,
      "grad_norm": 0.6792392730712891,
      "learning_rate": 4.5336967350979824e-05,
      "loss": 1.3022,
      "step": 89800
    },
    {
      "epoch": 0.28003129119825965,
      "grad_norm": 0.5408518314361572,
      "learning_rate": 4.53343701399689e-05,
      "loss": 1.2693,
      "step": 89850
    },
    {
      "epoch": 0.28018712385891537,
      "grad_norm": 0.5584591627120972,
      "learning_rate": 4.533177292895797e-05,
      "loss": 1.2819,
      "step": 89900
    },
    {
      "epoch": 0.28034295651957103,
      "grad_norm": 0.5847387909889221,
      "learning_rate": 4.532917571794704e-05,
      "loss": 1.2752,
      "step": 89950
    },
    {
      "epoch": 0.2804987891802267,
      "grad_norm": 0.5477379560470581,
      "learning_rate": 4.5326578506936114e-05,
      "loss": 1.275,
      "step": 90000
    },
    {
      "epoch": 0.2806546218408824,
      "grad_norm": 0.5948686599731445,
      "learning_rate": 4.532398129592519e-05,
      "loss": 1.3136,
      "step": 90050
    },
    {
      "epoch": 0.2808104545015381,
      "grad_norm": 0.6228139400482178,
      "learning_rate": 4.532138408491426e-05,
      "loss": 1.2633,
      "step": 90100
    },
    {
      "epoch": 0.28096628716219374,
      "grad_norm": 0.6050494313240051,
      "learning_rate": 4.531878687390333e-05,
      "loss": 1.2395,
      "step": 90150
    },
    {
      "epoch": 0.28112211982284946,
      "grad_norm": 0.5032868981361389,
      "learning_rate": 4.53161896628924e-05,
      "loss": 1.3154,
      "step": 90200
    },
    {
      "epoch": 0.2812779524835051,
      "grad_norm": 0.637382447719574,
      "learning_rate": 4.531359245188148e-05,
      "loss": 1.2525,
      "step": 90250
    },
    {
      "epoch": 0.2814337851441608,
      "grad_norm": 0.5989871025085449,
      "learning_rate": 4.531099524087055e-05,
      "loss": 1.2406,
      "step": 90300
    },
    {
      "epoch": 0.28158961780481645,
      "grad_norm": 0.630257785320282,
      "learning_rate": 4.5308398029859615e-05,
      "loss": 1.3089,
      "step": 90350
    },
    {
      "epoch": 0.28174545046547217,
      "grad_norm": 0.5364797711372375,
      "learning_rate": 4.530580081884869e-05,
      "loss": 1.269,
      "step": 90400
    },
    {
      "epoch": 0.28190128312612783,
      "grad_norm": 0.5750184655189514,
      "learning_rate": 4.530320360783776e-05,
      "loss": 1.2894,
      "step": 90450
    },
    {
      "epoch": 0.2820571157867835,
      "grad_norm": 0.6172656416893005,
      "learning_rate": 4.530060639682683e-05,
      "loss": 1.3055,
      "step": 90500
    },
    {
      "epoch": 0.2822129484474392,
      "grad_norm": 0.5629779696464539,
      "learning_rate": 4.5298009185815905e-05,
      "loss": 1.2787,
      "step": 90550
    },
    {
      "epoch": 0.2823687811080949,
      "grad_norm": 0.6033136248588562,
      "learning_rate": 4.529541197480498e-05,
      "loss": 1.2695,
      "step": 90600
    },
    {
      "epoch": 0.28252461376875054,
      "grad_norm": 0.5732226371765137,
      "learning_rate": 4.529281476379405e-05,
      "loss": 1.2346,
      "step": 90650
    },
    {
      "epoch": 0.28268044642940626,
      "grad_norm": 0.6024385690689087,
      "learning_rate": 4.529021755278312e-05,
      "loss": 1.3147,
      "step": 90700
    },
    {
      "epoch": 0.2828362790900619,
      "grad_norm": 0.5212110877037048,
      "learning_rate": 4.528762034177219e-05,
      "loss": 1.2465,
      "step": 90750
    },
    {
      "epoch": 0.2829921117507176,
      "grad_norm": 0.6717135310173035,
      "learning_rate": 4.528502313076127e-05,
      "loss": 1.3074,
      "step": 90800
    },
    {
      "epoch": 0.2831479444113733,
      "grad_norm": 0.49579644203186035,
      "learning_rate": 4.528242591975034e-05,
      "loss": 1.2605,
      "step": 90850
    },
    {
      "epoch": 0.283303777072029,
      "grad_norm": 0.5477232336997986,
      "learning_rate": 4.5279880652959625e-05,
      "loss": 1.3298,
      "step": 90900
    },
    {
      "epoch": 0.28345960973268464,
      "grad_norm": 0.6556195616722107,
      "learning_rate": 4.527733538616892e-05,
      "loss": 1.2838,
      "step": 90950
    },
    {
      "epoch": 0.28361544239334036,
      "grad_norm": 0.5452722311019897,
      "learning_rate": 4.527473817515799e-05,
      "loss": 1.2508,
      "step": 91000
    },
    {
      "epoch": 0.283771275053996,
      "grad_norm": 0.5631448030471802,
      "learning_rate": 4.527214096414706e-05,
      "loss": 1.289,
      "step": 91050
    },
    {
      "epoch": 0.2839271077146517,
      "grad_norm": 0.5967779755592346,
      "learning_rate": 4.5269543753136135e-05,
      "loss": 1.3256,
      "step": 91100
    },
    {
      "epoch": 0.2840829403753074,
      "grad_norm": 0.5523192882537842,
      "learning_rate": 4.526694654212521e-05,
      "loss": 1.2856,
      "step": 91150
    },
    {
      "epoch": 0.28423877303596307,
      "grad_norm": 0.7037512063980103,
      "learning_rate": 4.526434933111428e-05,
      "loss": 1.2862,
      "step": 91200
    },
    {
      "epoch": 0.28439460569661873,
      "grad_norm": 0.6109411120414734,
      "learning_rate": 4.526175212010335e-05,
      "loss": 1.2457,
      "step": 91250
    },
    {
      "epoch": 0.28455043835727445,
      "grad_norm": 0.5001532435417175,
      "learning_rate": 4.5259154909092425e-05,
      "loss": 1.3115,
      "step": 91300
    },
    {
      "epoch": 0.2847062710179301,
      "grad_norm": 0.5027416944503784,
      "learning_rate": 4.525655769808149e-05,
      "loss": 1.2354,
      "step": 91350
    },
    {
      "epoch": 0.2848621036785858,
      "grad_norm": 0.5230715870857239,
      "learning_rate": 4.525396048707057e-05,
      "loss": 1.2548,
      "step": 91400
    },
    {
      "epoch": 0.2850179363392415,
      "grad_norm": 0.5539658665657043,
      "learning_rate": 4.5251363276059636e-05,
      "loss": 1.2867,
      "step": 91450
    },
    {
      "epoch": 0.28517376899989716,
      "grad_norm": 0.626167893409729,
      "learning_rate": 4.524876606504871e-05,
      "loss": 1.2671,
      "step": 91500
    },
    {
      "epoch": 0.2853296016605528,
      "grad_norm": 0.4284021854400635,
      "learning_rate": 4.524616885403779e-05,
      "loss": 1.2806,
      "step": 91550
    },
    {
      "epoch": 0.2854854343212085,
      "grad_norm": 0.8241146206855774,
      "learning_rate": 4.524357164302685e-05,
      "loss": 1.2949,
      "step": 91600
    },
    {
      "epoch": 0.2856412669818642,
      "grad_norm": 0.5927508473396301,
      "learning_rate": 4.5240974432015926e-05,
      "loss": 1.272,
      "step": 91650
    },
    {
      "epoch": 0.28579709964251987,
      "grad_norm": 0.47587311267852783,
      "learning_rate": 4.5238377221005e-05,
      "loss": 1.3051,
      "step": 91700
    },
    {
      "epoch": 0.28595293230317553,
      "grad_norm": 0.539222776889801,
      "learning_rate": 4.523578000999407e-05,
      "loss": 1.2095,
      "step": 91750
    },
    {
      "epoch": 0.28610876496383125,
      "grad_norm": 0.6524333953857422,
      "learning_rate": 4.523318279898314e-05,
      "loss": 1.3204,
      "step": 91800
    },
    {
      "epoch": 0.2862645976244869,
      "grad_norm": 0.6271911859512329,
      "learning_rate": 4.5230585587972216e-05,
      "loss": 1.281,
      "step": 91850
    },
    {
      "epoch": 0.2864204302851426,
      "grad_norm": 0.782088577747345,
      "learning_rate": 4.522798837696128e-05,
      "loss": 1.2663,
      "step": 91900
    },
    {
      "epoch": 0.2865762629457983,
      "grad_norm": 0.6578977704048157,
      "learning_rate": 4.522539116595036e-05,
      "loss": 1.2416,
      "step": 91950
    },
    {
      "epoch": 0.28673209560645396,
      "grad_norm": 0.6290979385375977,
      "learning_rate": 4.5222793954939426e-05,
      "loss": 1.2828,
      "step": 92000
    },
    {
      "epoch": 0.2868879282671096,
      "grad_norm": 0.6554409861564636,
      "learning_rate": 4.52201967439285e-05,
      "loss": 1.2942,
      "step": 92050
    },
    {
      "epoch": 0.28704376092776535,
      "grad_norm": 0.6022779941558838,
      "learning_rate": 4.521759953291758e-05,
      "loss": 1.3007,
      "step": 92100
    },
    {
      "epoch": 0.287199593588421,
      "grad_norm": 0.5650609731674194,
      "learning_rate": 4.5215002321906644e-05,
      "loss": 1.3055,
      "step": 92150
    },
    {
      "epoch": 0.2873554262490767,
      "grad_norm": 0.5236136317253113,
      "learning_rate": 4.5212405110895716e-05,
      "loss": 1.2559,
      "step": 92200
    },
    {
      "epoch": 0.2875112589097324,
      "grad_norm": 0.7750171422958374,
      "learning_rate": 4.520980789988479e-05,
      "loss": 1.3044,
      "step": 92250
    },
    {
      "epoch": 0.28766709157038806,
      "grad_norm": 0.6896830201148987,
      "learning_rate": 4.520721068887386e-05,
      "loss": 1.2657,
      "step": 92300
    },
    {
      "epoch": 0.2878229242310437,
      "grad_norm": 0.6202024221420288,
      "learning_rate": 4.5204613477862934e-05,
      "loss": 1.2863,
      "step": 92350
    },
    {
      "epoch": 0.28797875689169944,
      "grad_norm": 0.5514146089553833,
      "learning_rate": 4.5202016266852006e-05,
      "loss": 1.2834,
      "step": 92400
    },
    {
      "epoch": 0.2881345895523551,
      "grad_norm": 0.6119816899299622,
      "learning_rate": 4.519941905584108e-05,
      "loss": 1.2741,
      "step": 92450
    },
    {
      "epoch": 0.28829042221301077,
      "grad_norm": 0.5522558093070984,
      "learning_rate": 4.519682184483015e-05,
      "loss": 1.2707,
      "step": 92500
    },
    {
      "epoch": 0.2884462548736665,
      "grad_norm": 0.556108295917511,
      "learning_rate": 4.5194224633819224e-05,
      "loss": 1.252,
      "step": 92550
    },
    {
      "epoch": 0.28860208753432215,
      "grad_norm": 0.6908206343650818,
      "learning_rate": 4.519162742280829e-05,
      "loss": 1.2591,
      "step": 92600
    },
    {
      "epoch": 0.2887579201949778,
      "grad_norm": 0.7641803622245789,
      "learning_rate": 4.518903021179737e-05,
      "loss": 1.2504,
      "step": 92650
    },
    {
      "epoch": 0.28891375285563353,
      "grad_norm": 0.6841703653335571,
      "learning_rate": 4.5186433000786435e-05,
      "loss": 1.3349,
      "step": 92700
    },
    {
      "epoch": 0.2890695855162892,
      "grad_norm": 0.5560402870178223,
      "learning_rate": 4.518383578977551e-05,
      "loss": 1.3004,
      "step": 92750
    },
    {
      "epoch": 0.28922541817694486,
      "grad_norm": 0.5927939414978027,
      "learning_rate": 4.5181238578764586e-05,
      "loss": 1.2984,
      "step": 92800
    },
    {
      "epoch": 0.2893812508376006,
      "grad_norm": 0.5348142981529236,
      "learning_rate": 4.517864136775365e-05,
      "loss": 1.264,
      "step": 92850
    },
    {
      "epoch": 0.28953708349825624,
      "grad_norm": 0.6487886309623718,
      "learning_rate": 4.5176044156742725e-05,
      "loss": 1.2845,
      "step": 92900
    },
    {
      "epoch": 0.2896929161589119,
      "grad_norm": 0.5970886945724487,
      "learning_rate": 4.51734469457318e-05,
      "loss": 1.2707,
      "step": 92950
    },
    {
      "epoch": 0.28984874881956757,
      "grad_norm": 0.6040114760398865,
      "learning_rate": 4.517084973472087e-05,
      "loss": 1.3347,
      "step": 93000
    },
    {
      "epoch": 0.2900045814802233,
      "grad_norm": 0.6348373889923096,
      "learning_rate": 4.516825252370994e-05,
      "loss": 1.3272,
      "step": 93050
    },
    {
      "epoch": 0.29016041414087895,
      "grad_norm": 0.47357356548309326,
      "learning_rate": 4.5165655312699015e-05,
      "loss": 1.3007,
      "step": 93100
    },
    {
      "epoch": 0.2903162468015346,
      "grad_norm": 0.6825065016746521,
      "learning_rate": 4.516305810168808e-05,
      "loss": 1.3177,
      "step": 93150
    },
    {
      "epoch": 0.29047207946219034,
      "grad_norm": 0.5769498348236084,
      "learning_rate": 4.516046089067716e-05,
      "loss": 1.2776,
      "step": 93200
    },
    {
      "epoch": 0.290627912122846,
      "grad_norm": 0.6178246736526489,
      "learning_rate": 4.515786367966623e-05,
      "loss": 1.3004,
      "step": 93250
    },
    {
      "epoch": 0.29078374478350166,
      "grad_norm": 0.5048084259033203,
      "learning_rate": 4.51552664686553e-05,
      "loss": 1.2676,
      "step": 93300
    },
    {
      "epoch": 0.2909395774441574,
      "grad_norm": 0.5827587246894836,
      "learning_rate": 4.515266925764438e-05,
      "loss": 1.2461,
      "step": 93350
    },
    {
      "epoch": 0.29109541010481305,
      "grad_norm": 0.5935578942298889,
      "learning_rate": 4.515007204663344e-05,
      "loss": 1.3021,
      "step": 93400
    },
    {
      "epoch": 0.2912512427654687,
      "grad_norm": 0.7481949329376221,
      "learning_rate": 4.5147474835622515e-05,
      "loss": 1.3177,
      "step": 93450
    },
    {
      "epoch": 0.29140707542612443,
      "grad_norm": 0.5756901502609253,
      "learning_rate": 4.514487762461159e-05,
      "loss": 1.2701,
      "step": 93500
    },
    {
      "epoch": 0.2915629080867801,
      "grad_norm": 0.5244693160057068,
      "learning_rate": 4.514228041360066e-05,
      "loss": 1.2928,
      "step": 93550
    },
    {
      "epoch": 0.29171874074743576,
      "grad_norm": 0.5839806199073792,
      "learning_rate": 4.513968320258973e-05,
      "loss": 1.2749,
      "step": 93600
    },
    {
      "epoch": 0.2918745734080915,
      "grad_norm": 0.5975198745727539,
      "learning_rate": 4.5137085991578805e-05,
      "loss": 1.3076,
      "step": 93650
    },
    {
      "epoch": 0.29203040606874714,
      "grad_norm": 0.5947805643081665,
      "learning_rate": 4.513448878056788e-05,
      "loss": 1.2745,
      "step": 93700
    },
    {
      "epoch": 0.2921862387294028,
      "grad_norm": 0.5905247926712036,
      "learning_rate": 4.513189156955695e-05,
      "loss": 1.264,
      "step": 93750
    },
    {
      "epoch": 0.2923420713900585,
      "grad_norm": 0.5729665756225586,
      "learning_rate": 4.512934630276624e-05,
      "loss": 1.2557,
      "step": 93800
    },
    {
      "epoch": 0.2924979040507142,
      "grad_norm": 0.735503077507019,
      "learning_rate": 4.512674909175531e-05,
      "loss": 1.3062,
      "step": 93850
    },
    {
      "epoch": 0.29265373671136985,
      "grad_norm": 0.698738694190979,
      "learning_rate": 4.512415188074439e-05,
      "loss": 1.3055,
      "step": 93900
    },
    {
      "epoch": 0.29280956937202557,
      "grad_norm": 0.5992863178253174,
      "learning_rate": 4.512155466973346e-05,
      "loss": 1.2891,
      "step": 93950
    },
    {
      "epoch": 0.29296540203268123,
      "grad_norm": 0.5692920088768005,
      "learning_rate": 4.5118957458722526e-05,
      "loss": 1.316,
      "step": 94000
    },
    {
      "epoch": 0.2931212346933369,
      "grad_norm": 0.6956822276115417,
      "learning_rate": 4.51163602477116e-05,
      "loss": 1.2638,
      "step": 94050
    },
    {
      "epoch": 0.2932770673539926,
      "grad_norm": 0.5353192687034607,
      "learning_rate": 4.511376303670067e-05,
      "loss": 1.2794,
      "step": 94100
    },
    {
      "epoch": 0.2934329000146483,
      "grad_norm": 0.5957822799682617,
      "learning_rate": 4.511116582568974e-05,
      "loss": 1.2969,
      "step": 94150
    },
    {
      "epoch": 0.29358873267530394,
      "grad_norm": 0.6047754883766174,
      "learning_rate": 4.5108568614678816e-05,
      "loss": 1.2947,
      "step": 94200
    },
    {
      "epoch": 0.2937445653359596,
      "grad_norm": 0.6430733799934387,
      "learning_rate": 4.510597140366788e-05,
      "loss": 1.2821,
      "step": 94250
    },
    {
      "epoch": 0.2939003979966153,
      "grad_norm": 0.5783955454826355,
      "learning_rate": 4.510337419265696e-05,
      "loss": 1.3073,
      "step": 94300
    },
    {
      "epoch": 0.294056230657271,
      "grad_norm": 0.48991066217422485,
      "learning_rate": 4.510077698164603e-05,
      "loss": 1.2867,
      "step": 94350
    },
    {
      "epoch": 0.29421206331792665,
      "grad_norm": 0.5384417176246643,
      "learning_rate": 4.50981797706351e-05,
      "loss": 1.2805,
      "step": 94400
    },
    {
      "epoch": 0.2943678959785824,
      "grad_norm": 0.6198071241378784,
      "learning_rate": 4.509558255962418e-05,
      "loss": 1.2674,
      "step": 94450
    },
    {
      "epoch": 0.29452372863923804,
      "grad_norm": 0.7431765794754028,
      "learning_rate": 4.509298534861325e-05,
      "loss": 1.2729,
      "step": 94500
    },
    {
      "epoch": 0.2946795612998937,
      "grad_norm": 0.4990307688713074,
      "learning_rate": 4.5090388137602317e-05,
      "loss": 1.2722,
      "step": 94550
    },
    {
      "epoch": 0.2948353939605494,
      "grad_norm": 0.5612137317657471,
      "learning_rate": 4.508779092659139e-05,
      "loss": 1.2992,
      "step": 94600
    },
    {
      "epoch": 0.2949912266212051,
      "grad_norm": 0.5394738912582397,
      "learning_rate": 4.508519371558046e-05,
      "loss": 1.3391,
      "step": 94650
    },
    {
      "epoch": 0.29514705928186075,
      "grad_norm": 0.6243597865104675,
      "learning_rate": 4.5082596504569534e-05,
      "loss": 1.3518,
      "step": 94700
    },
    {
      "epoch": 0.29530289194251647,
      "grad_norm": 0.6651831865310669,
      "learning_rate": 4.507999929355861e-05,
      "loss": 1.282,
      "step": 94750
    },
    {
      "epoch": 0.29545872460317213,
      "grad_norm": 0.4946800768375397,
      "learning_rate": 4.507740208254768e-05,
      "loss": 1.2671,
      "step": 94800
    },
    {
      "epoch": 0.2956145572638278,
      "grad_norm": 0.6572282910346985,
      "learning_rate": 4.507480487153675e-05,
      "loss": 1.2826,
      "step": 94850
    },
    {
      "epoch": 0.2957703899244835,
      "grad_norm": 0.6565377116203308,
      "learning_rate": 4.5072207660525824e-05,
      "loss": 1.3116,
      "step": 94900
    },
    {
      "epoch": 0.2959262225851392,
      "grad_norm": 0.605445384979248,
      "learning_rate": 4.506961044951489e-05,
      "loss": 1.3142,
      "step": 94950
    },
    {
      "epoch": 0.29608205524579484,
      "grad_norm": 0.6622234582901001,
      "learning_rate": 4.506701323850397e-05,
      "loss": 1.2645,
      "step": 95000
    },
    {
      "epoch": 0.29623788790645056,
      "grad_norm": 0.6220176219940186,
      "learning_rate": 4.506441602749304e-05,
      "loss": 1.2616,
      "step": 95050
    },
    {
      "epoch": 0.2963937205671062,
      "grad_norm": 0.53985196352005,
      "learning_rate": 4.506181881648211e-05,
      "loss": 1.2297,
      "step": 95100
    },
    {
      "epoch": 0.2965495532277619,
      "grad_norm": 0.5711265802383423,
      "learning_rate": 4.505922160547119e-05,
      "loss": 1.2914,
      "step": 95150
    },
    {
      "epoch": 0.2967053858884176,
      "grad_norm": 0.6377158761024475,
      "learning_rate": 4.505662439446026e-05,
      "loss": 1.2751,
      "step": 95200
    },
    {
      "epoch": 0.29686121854907327,
      "grad_norm": 0.6815695762634277,
      "learning_rate": 4.5054027183449325e-05,
      "loss": 1.313,
      "step": 95250
    },
    {
      "epoch": 0.29701705120972893,
      "grad_norm": 0.6014872789382935,
      "learning_rate": 4.50514299724384e-05,
      "loss": 1.3527,
      "step": 95300
    },
    {
      "epoch": 0.29717288387038465,
      "grad_norm": 0.5888962745666504,
      "learning_rate": 4.504883276142747e-05,
      "loss": 1.2604,
      "step": 95350
    },
    {
      "epoch": 0.2973287165310403,
      "grad_norm": 0.45924296975135803,
      "learning_rate": 4.504623555041654e-05,
      "loss": 1.2927,
      "step": 95400
    },
    {
      "epoch": 0.297484549191696,
      "grad_norm": 0.6108421087265015,
      "learning_rate": 4.5043638339405615e-05,
      "loss": 1.2718,
      "step": 95450
    },
    {
      "epoch": 0.29764038185235164,
      "grad_norm": 0.6607656478881836,
      "learning_rate": 4.504104112839469e-05,
      "loss": 1.3065,
      "step": 95500
    },
    {
      "epoch": 0.29779621451300736,
      "grad_norm": 0.6234967112541199,
      "learning_rate": 4.503844391738376e-05,
      "loss": 1.3065,
      "step": 95550
    },
    {
      "epoch": 0.297952047173663,
      "grad_norm": 0.574096143245697,
      "learning_rate": 4.503584670637283e-05,
      "loss": 1.3167,
      "step": 95600
    },
    {
      "epoch": 0.2981078798343187,
      "grad_norm": 0.6495015621185303,
      "learning_rate": 4.50332494953619e-05,
      "loss": 1.2842,
      "step": 95650
    },
    {
      "epoch": 0.2982637124949744,
      "grad_norm": 0.7182378768920898,
      "learning_rate": 4.503065228435098e-05,
      "loss": 1.3215,
      "step": 95700
    },
    {
      "epoch": 0.2984195451556301,
      "grad_norm": 0.6117981672286987,
      "learning_rate": 4.502805507334005e-05,
      "loss": 1.309,
      "step": 95750
    },
    {
      "epoch": 0.29857537781628574,
      "grad_norm": 0.6057953834533691,
      "learning_rate": 4.5025457862329116e-05,
      "loss": 1.296,
      "step": 95800
    },
    {
      "epoch": 0.29873121047694146,
      "grad_norm": 0.5881677865982056,
      "learning_rate": 4.502286065131819e-05,
      "loss": 1.2827,
      "step": 95850
    },
    {
      "epoch": 0.2988870431375971,
      "grad_norm": 0.49803686141967773,
      "learning_rate": 4.502026344030727e-05,
      "loss": 1.3097,
      "step": 95900
    },
    {
      "epoch": 0.2990428757982528,
      "grad_norm": 0.7468553185462952,
      "learning_rate": 4.501766622929633e-05,
      "loss": 1.3474,
      "step": 95950
    },
    {
      "epoch": 0.2991987084589085,
      "grad_norm": 0.5677075386047363,
      "learning_rate": 4.5015069018285406e-05,
      "loss": 1.3155,
      "step": 96000
    },
    {
      "epoch": 0.29935454111956417,
      "grad_norm": 0.6365548968315125,
      "learning_rate": 4.501247180727448e-05,
      "loss": 1.2747,
      "step": 96050
    },
    {
      "epoch": 0.29951037378021983,
      "grad_norm": 0.5126882791519165,
      "learning_rate": 4.500987459626355e-05,
      "loss": 1.2608,
      "step": 96100
    },
    {
      "epoch": 0.29966620644087555,
      "grad_norm": 0.47791025042533875,
      "learning_rate": 4.500727738525262e-05,
      "loss": 1.2649,
      "step": 96150
    },
    {
      "epoch": 0.2998220391015312,
      "grad_norm": 0.6058936715126038,
      "learning_rate": 4.5004680174241696e-05,
      "loss": 1.2835,
      "step": 96200
    },
    {
      "epoch": 0.2999778717621869,
      "grad_norm": 0.5299693942070007,
      "learning_rate": 4.500208296323077e-05,
      "loss": 1.3183,
      "step": 96250
    },
    {
      "epoch": 0.3001337044228426,
      "grad_norm": 0.5560826063156128,
      "learning_rate": 4.499948575221984e-05,
      "loss": 1.258,
      "step": 96300
    },
    {
      "epoch": 0.30028953708349826,
      "grad_norm": 0.9025711417198181,
      "learning_rate": 4.4996888541208906e-05,
      "loss": 1.2292,
      "step": 96350
    },
    {
      "epoch": 0.3004453697441539,
      "grad_norm": 0.5649691224098206,
      "learning_rate": 4.499429133019798e-05,
      "loss": 1.313,
      "step": 96400
    },
    {
      "epoch": 0.30060120240480964,
      "grad_norm": 0.5626839995384216,
      "learning_rate": 4.499169411918706e-05,
      "loss": 1.2383,
      "step": 96450
    },
    {
      "epoch": 0.3007570350654653,
      "grad_norm": 0.6383341550827026,
      "learning_rate": 4.4989096908176124e-05,
      "loss": 1.2807,
      "step": 96500
    },
    {
      "epoch": 0.30091286772612097,
      "grad_norm": 0.6585282683372498,
      "learning_rate": 4.4986499697165196e-05,
      "loss": 1.2376,
      "step": 96550
    },
    {
      "epoch": 0.3010687003867767,
      "grad_norm": 0.4823295772075653,
      "learning_rate": 4.4983902486154276e-05,
      "loss": 1.3124,
      "step": 96600
    },
    {
      "epoch": 0.30122453304743235,
      "grad_norm": 0.6041480898857117,
      "learning_rate": 4.498130527514334e-05,
      "loss": 1.2722,
      "step": 96650
    },
    {
      "epoch": 0.301380365708088,
      "grad_norm": 0.7538700699806213,
      "learning_rate": 4.4978708064132414e-05,
      "loss": 1.274,
      "step": 96700
    },
    {
      "epoch": 0.30153619836874374,
      "grad_norm": 0.5654622316360474,
      "learning_rate": 4.4976110853121486e-05,
      "loss": 1.2673,
      "step": 96750
    },
    {
      "epoch": 0.3016920310293994,
      "grad_norm": 0.6189660429954529,
      "learning_rate": 4.497351364211056e-05,
      "loss": 1.255,
      "step": 96800
    },
    {
      "epoch": 0.30184786369005506,
      "grad_norm": 0.5337457060813904,
      "learning_rate": 4.497091643109963e-05,
      "loss": 1.2989,
      "step": 96850
    },
    {
      "epoch": 0.3020036963507107,
      "grad_norm": 0.7162205576896667,
      "learning_rate": 4.49683192200887e-05,
      "loss": 1.2629,
      "step": 96900
    },
    {
      "epoch": 0.30215952901136645,
      "grad_norm": 0.5486875176429749,
      "learning_rate": 4.4965722009077776e-05,
      "loss": 1.2851,
      "step": 96950
    },
    {
      "epoch": 0.3023153616720221,
      "grad_norm": 0.4924072325229645,
      "learning_rate": 4.496312479806685e-05,
      "loss": 1.2548,
      "step": 97000
    },
    {
      "epoch": 0.3024711943326778,
      "grad_norm": 0.5724454522132874,
      "learning_rate": 4.4960527587055915e-05,
      "loss": 1.3549,
      "step": 97050
    },
    {
      "epoch": 0.3026270269933335,
      "grad_norm": 0.5485723614692688,
      "learning_rate": 4.495793037604499e-05,
      "loss": 1.2893,
      "step": 97100
    },
    {
      "epoch": 0.30278285965398916,
      "grad_norm": 0.5160033702850342,
      "learning_rate": 4.4955333165034066e-05,
      "loss": 1.2484,
      "step": 97150
    },
    {
      "epoch": 0.3029386923146448,
      "grad_norm": 0.509704053401947,
      "learning_rate": 4.495273595402313e-05,
      "loss": 1.2536,
      "step": 97200
    },
    {
      "epoch": 0.30309452497530054,
      "grad_norm": 0.633838415145874,
      "learning_rate": 4.4950138743012205e-05,
      "loss": 1.3011,
      "step": 97250
    },
    {
      "epoch": 0.3032503576359562,
      "grad_norm": 0.5229220986366272,
      "learning_rate": 4.494754153200128e-05,
      "loss": 1.289,
      "step": 97300
    },
    {
      "epoch": 0.30340619029661187,
      "grad_norm": 0.6062067747116089,
      "learning_rate": 4.494494432099035e-05,
      "loss": 1.2986,
      "step": 97350
    },
    {
      "epoch": 0.3035620229572676,
      "grad_norm": 0.6893708109855652,
      "learning_rate": 4.494234710997942e-05,
      "loss": 1.2495,
      "step": 97400
    },
    {
      "epoch": 0.30371785561792325,
      "grad_norm": 0.5300588011741638,
      "learning_rate": 4.4939749898968495e-05,
      "loss": 1.2547,
      "step": 97450
    },
    {
      "epoch": 0.3038736882785789,
      "grad_norm": 0.6074531078338623,
      "learning_rate": 4.493715268795757e-05,
      "loss": 1.2912,
      "step": 97500
    },
    {
      "epoch": 0.30402952093923463,
      "grad_norm": 0.6824127435684204,
      "learning_rate": 4.493455547694664e-05,
      "loss": 1.3302,
      "step": 97550
    },
    {
      "epoch": 0.3041853535998903,
      "grad_norm": 0.6009795069694519,
      "learning_rate": 4.4931958265935705e-05,
      "loss": 1.2812,
      "step": 97600
    },
    {
      "epoch": 0.30434118626054596,
      "grad_norm": 0.7307578921318054,
      "learning_rate": 4.492936105492478e-05,
      "loss": 1.2753,
      "step": 97650
    },
    {
      "epoch": 0.3044970189212017,
      "grad_norm": 0.49199846386909485,
      "learning_rate": 4.492676384391386e-05,
      "loss": 1.2796,
      "step": 97700
    },
    {
      "epoch": 0.30465285158185734,
      "grad_norm": 0.7051723599433899,
      "learning_rate": 4.492416663290292e-05,
      "loss": 1.2831,
      "step": 97750
    },
    {
      "epoch": 0.304808684242513,
      "grad_norm": 0.6075356006622314,
      "learning_rate": 4.4921569421891995e-05,
      "loss": 1.2936,
      "step": 97800
    },
    {
      "epoch": 0.3049645169031687,
      "grad_norm": 0.6023327112197876,
      "learning_rate": 4.4918972210881075e-05,
      "loss": 1.2462,
      "step": 97850
    },
    {
      "epoch": 0.3051203495638244,
      "grad_norm": 0.7100374102592468,
      "learning_rate": 4.491637499987014e-05,
      "loss": 1.2405,
      "step": 97900
    },
    {
      "epoch": 0.30527618222448005,
      "grad_norm": 0.6376941204071045,
      "learning_rate": 4.491377778885921e-05,
      "loss": 1.278,
      "step": 97950
    },
    {
      "epoch": 0.30543201488513577,
      "grad_norm": 0.5308479070663452,
      "learning_rate": 4.4911180577848285e-05,
      "loss": 1.2849,
      "step": 98000
    },
    {
      "epoch": 0.30558784754579144,
      "grad_norm": 0.624951958656311,
      "learning_rate": 4.490858336683736e-05,
      "loss": 1.2949,
      "step": 98050
    },
    {
      "epoch": 0.3057436802064471,
      "grad_norm": 0.9100723266601562,
      "learning_rate": 4.490598615582643e-05,
      "loss": 1.2367,
      "step": 98100
    },
    {
      "epoch": 0.30589951286710276,
      "grad_norm": 0.6926414966583252,
      "learning_rate": 4.49033889448155e-05,
      "loss": 1.2849,
      "step": 98150
    },
    {
      "epoch": 0.3060553455277585,
      "grad_norm": 0.5667209625244141,
      "learning_rate": 4.4900791733804575e-05,
      "loss": 1.2844,
      "step": 98200
    },
    {
      "epoch": 0.30621117818841415,
      "grad_norm": 0.6951920390129089,
      "learning_rate": 4.489819452279365e-05,
      "loss": 1.3321,
      "step": 98250
    },
    {
      "epoch": 0.3063670108490698,
      "grad_norm": 0.6612361669540405,
      "learning_rate": 4.4895597311782714e-05,
      "loss": 1.2483,
      "step": 98300
    },
    {
      "epoch": 0.30652284350972553,
      "grad_norm": 0.5551003217697144,
      "learning_rate": 4.4893000100771786e-05,
      "loss": 1.2255,
      "step": 98350
    },
    {
      "epoch": 0.3066786761703812,
      "grad_norm": 0.5530357360839844,
      "learning_rate": 4.4890402889760865e-05,
      "loss": 1.288,
      "step": 98400
    },
    {
      "epoch": 0.30683450883103686,
      "grad_norm": 0.65899258852005,
      "learning_rate": 4.488780567874993e-05,
      "loss": 1.3239,
      "step": 98450
    },
    {
      "epoch": 0.3069903414916926,
      "grad_norm": 0.6518936157226562,
      "learning_rate": 4.4885208467739004e-05,
      "loss": 1.3192,
      "step": 98500
    },
    {
      "epoch": 0.30714617415234824,
      "grad_norm": 0.528838038444519,
      "learning_rate": 4.488261125672808e-05,
      "loss": 1.3199,
      "step": 98550
    },
    {
      "epoch": 0.3073020068130039,
      "grad_norm": 0.6013385653495789,
      "learning_rate": 4.488001404571715e-05,
      "loss": 1.2971,
      "step": 98600
    },
    {
      "epoch": 0.3074578394736596,
      "grad_norm": 0.45610323548316956,
      "learning_rate": 4.487746877892644e-05,
      "loss": 1.2643,
      "step": 98650
    },
    {
      "epoch": 0.3076136721343153,
      "grad_norm": 0.4942629635334015,
      "learning_rate": 4.487487156791551e-05,
      "loss": 1.3048,
      "step": 98700
    },
    {
      "epoch": 0.30776950479497095,
      "grad_norm": 0.5889999270439148,
      "learning_rate": 4.487227435690458e-05,
      "loss": 1.3364,
      "step": 98750
    },
    {
      "epoch": 0.30792533745562667,
      "grad_norm": 0.6268710494041443,
      "learning_rate": 4.486967714589366e-05,
      "loss": 1.288,
      "step": 98800
    },
    {
      "epoch": 0.30808117011628233,
      "grad_norm": 0.564455509185791,
      "learning_rate": 4.486707993488273e-05,
      "loss": 1.2548,
      "step": 98850
    },
    {
      "epoch": 0.308237002776938,
      "grad_norm": 0.570297360420227,
      "learning_rate": 4.4864482723871797e-05,
      "loss": 1.3104,
      "step": 98900
    },
    {
      "epoch": 0.3083928354375937,
      "grad_norm": 0.6798434853553772,
      "learning_rate": 4.4861885512860876e-05,
      "loss": 1.2626,
      "step": 98950
    },
    {
      "epoch": 0.3085486680982494,
      "grad_norm": 0.5482914447784424,
      "learning_rate": 4.485928830184994e-05,
      "loss": 1.3163,
      "step": 99000
    },
    {
      "epoch": 0.30870450075890504,
      "grad_norm": 0.6615256071090698,
      "learning_rate": 4.4856691090839014e-05,
      "loss": 1.2559,
      "step": 99050
    },
    {
      "epoch": 0.30886033341956076,
      "grad_norm": 0.7171490788459778,
      "learning_rate": 4.4854093879828087e-05,
      "loss": 1.2513,
      "step": 99100
    },
    {
      "epoch": 0.3090161660802164,
      "grad_norm": 0.5548343062400818,
      "learning_rate": 4.485149666881716e-05,
      "loss": 1.2715,
      "step": 99150
    },
    {
      "epoch": 0.3091719987408721,
      "grad_norm": 0.5043261051177979,
      "learning_rate": 4.484889945780623e-05,
      "loss": 1.2413,
      "step": 99200
    },
    {
      "epoch": 0.3093278314015278,
      "grad_norm": 0.6550219058990479,
      "learning_rate": 4.4846302246795304e-05,
      "loss": 1.2889,
      "step": 99250
    },
    {
      "epoch": 0.30948366406218347,
      "grad_norm": 0.7366300821304321,
      "learning_rate": 4.4843705035784377e-05,
      "loss": 1.2724,
      "step": 99300
    },
    {
      "epoch": 0.30963949672283914,
      "grad_norm": 0.7543854713439941,
      "learning_rate": 4.484110782477345e-05,
      "loss": 1.3197,
      "step": 99350
    },
    {
      "epoch": 0.30979532938349486,
      "grad_norm": 0.4079675078392029,
      "learning_rate": 4.483851061376252e-05,
      "loss": 1.2546,
      "step": 99400
    },
    {
      "epoch": 0.3099511620441505,
      "grad_norm": 0.7120348811149597,
      "learning_rate": 4.483591340275159e-05,
      "loss": 1.2863,
      "step": 99450
    },
    {
      "epoch": 0.3101069947048062,
      "grad_norm": 0.5074723958969116,
      "learning_rate": 4.4833316191740667e-05,
      "loss": 1.2877,
      "step": 99500
    },
    {
      "epoch": 0.31026282736546185,
      "grad_norm": 0.6494568586349487,
      "learning_rate": 4.483071898072973e-05,
      "loss": 1.2677,
      "step": 99550
    },
    {
      "epoch": 0.31041866002611757,
      "grad_norm": 0.5199990272521973,
      "learning_rate": 4.4828121769718805e-05,
      "loss": 1.3727,
      "step": 99600
    },
    {
      "epoch": 0.31057449268677323,
      "grad_norm": 0.6094517111778259,
      "learning_rate": 4.4825524558707884e-05,
      "loss": 1.3065,
      "step": 99650
    },
    {
      "epoch": 0.3107303253474289,
      "grad_norm": Infinity,
      "learning_rate": 4.482292734769695e-05,
      "loss": 1.2812,
      "step": 99700
    },
    {
      "epoch": 0.3108861580080846,
      "grad_norm": 0.4463479816913605,
      "learning_rate": 4.482038208090624e-05,
      "loss": 1.2625,
      "step": 99750
    },
    {
      "epoch": 0.3110419906687403,
      "grad_norm": 0.6140783429145813,
      "learning_rate": 4.4817784869895314e-05,
      "loss": 1.2778,
      "step": 99800
    },
    {
      "epoch": 0.31119782332939594,
      "grad_norm": 0.4912654459476471,
      "learning_rate": 4.481518765888438e-05,
      "loss": 1.2994,
      "step": 99850
    },
    {
      "epoch": 0.31135365599005166,
      "grad_norm": 1.3080778121948242,
      "learning_rate": 4.481259044787346e-05,
      "loss": 1.2766,
      "step": 99900
    },
    {
      "epoch": 0.3115094886507073,
      "grad_norm": 0.6295023560523987,
      "learning_rate": 4.480999323686253e-05,
      "loss": 1.3305,
      "step": 99950
    },
    {
      "epoch": 0.311665321311363,
      "grad_norm": 0.506354808807373,
      "learning_rate": 4.48073960258516e-05,
      "loss": 1.2667,
      "step": 100000
    },
    {
      "epoch": 0.3118211539720187,
      "grad_norm": 0.61216801404953,
      "learning_rate": 4.480479881484068e-05,
      "loss": 1.2932,
      "step": 100050
    },
    {
      "epoch": 0.31197698663267437,
      "grad_norm": 0.6324853301048279,
      "learning_rate": 4.480220160382975e-05,
      "loss": 1.335,
      "step": 100100
    },
    {
      "epoch": 0.31213281929333003,
      "grad_norm": 0.7565706968307495,
      "learning_rate": 4.4799604392818815e-05,
      "loss": 1.235,
      "step": 100150
    },
    {
      "epoch": 0.31228865195398575,
      "grad_norm": 0.7823220491409302,
      "learning_rate": 4.479700718180789e-05,
      "loss": 1.2535,
      "step": 100200
    },
    {
      "epoch": 0.3124444846146414,
      "grad_norm": 0.6159356832504272,
      "learning_rate": 4.479440997079696e-05,
      "loss": 1.2325,
      "step": 100250
    },
    {
      "epoch": 0.3126003172752971,
      "grad_norm": 0.6588977575302124,
      "learning_rate": 4.479181275978603e-05,
      "loss": 1.299,
      "step": 100300
    },
    {
      "epoch": 0.3127561499359528,
      "grad_norm": 0.5287116765975952,
      "learning_rate": 4.4789215548775105e-05,
      "loss": 1.2391,
      "step": 100350
    },
    {
      "epoch": 0.31291198259660846,
      "grad_norm": 0.6185861825942993,
      "learning_rate": 4.478661833776418e-05,
      "loss": 1.2714,
      "step": 100400
    },
    {
      "epoch": 0.3130678152572641,
      "grad_norm": 0.6512271165847778,
      "learning_rate": 4.478402112675325e-05,
      "loss": 1.3094,
      "step": 100450
    },
    {
      "epoch": 0.31322364791791985,
      "grad_norm": 0.5899868011474609,
      "learning_rate": 4.478142391574232e-05,
      "loss": 1.2594,
      "step": 100500
    },
    {
      "epoch": 0.3133794805785755,
      "grad_norm": 0.4314413070678711,
      "learning_rate": 4.477882670473139e-05,
      "loss": 1.321,
      "step": 100550
    },
    {
      "epoch": 0.3135353132392312,
      "grad_norm": 0.6853488087654114,
      "learning_rate": 4.477622949372047e-05,
      "loss": 1.2605,
      "step": 100600
    },
    {
      "epoch": 0.3136911458998869,
      "grad_norm": 0.6693912744522095,
      "learning_rate": 4.477363228270954e-05,
      "loss": 1.3061,
      "step": 100650
    },
    {
      "epoch": 0.31384697856054256,
      "grad_norm": 0.5892251133918762,
      "learning_rate": 4.4771035071698606e-05,
      "loss": 1.2265,
      "step": 100700
    },
    {
      "epoch": 0.3140028112211982,
      "grad_norm": 0.4895721673965454,
      "learning_rate": 4.476843786068768e-05,
      "loss": 1.2921,
      "step": 100750
    },
    {
      "epoch": 0.3141586438818539,
      "grad_norm": 0.6140424013137817,
      "learning_rate": 4.476584064967676e-05,
      "loss": 1.2322,
      "step": 100800
    },
    {
      "epoch": 0.3143144765425096,
      "grad_norm": 0.6539985537528992,
      "learning_rate": 4.4763243438665823e-05,
      "loss": 1.2871,
      "step": 100850
    },
    {
      "epoch": 0.31447030920316527,
      "grad_norm": 0.676758885383606,
      "learning_rate": 4.4760646227654896e-05,
      "loss": 1.2275,
      "step": 100900
    },
    {
      "epoch": 0.31462614186382093,
      "grad_norm": 0.5691264867782593,
      "learning_rate": 4.475804901664397e-05,
      "loss": 1.2549,
      "step": 100950
    },
    {
      "epoch": 0.31478197452447665,
      "grad_norm": 0.6524783968925476,
      "learning_rate": 4.475545180563304e-05,
      "loss": 1.2897,
      "step": 101000
    },
    {
      "epoch": 0.3149378071851323,
      "grad_norm": 0.6372010111808777,
      "learning_rate": 4.4752854594622113e-05,
      "loss": 1.275,
      "step": 101050
    },
    {
      "epoch": 0.315093639845788,
      "grad_norm": 0.6690057516098022,
      "learning_rate": 4.4750257383611186e-05,
      "loss": 1.2623,
      "step": 101100
    },
    {
      "epoch": 0.3152494725064437,
      "grad_norm": 0.7525289058685303,
      "learning_rate": 4.474766017260026e-05,
      "loss": 1.2886,
      "step": 101150
    },
    {
      "epoch": 0.31540530516709936,
      "grad_norm": 0.6467063426971436,
      "learning_rate": 4.474506296158933e-05,
      "loss": 1.3446,
      "step": 101200
    },
    {
      "epoch": 0.315561137827755,
      "grad_norm": 0.6268717050552368,
      "learning_rate": 4.47424657505784e-05,
      "loss": 1.2774,
      "step": 101250
    },
    {
      "epoch": 0.31571697048841074,
      "grad_norm": 0.5794708728790283,
      "learning_rate": 4.4739868539567476e-05,
      "loss": 1.2249,
      "step": 101300
    },
    {
      "epoch": 0.3158728031490664,
      "grad_norm": 0.6445797681808472,
      "learning_rate": 4.473727132855655e-05,
      "loss": 1.3303,
      "step": 101350
    },
    {
      "epoch": 0.31602863580972207,
      "grad_norm": 0.5410595536231995,
      "learning_rate": 4.4734674117545614e-05,
      "loss": 1.2741,
      "step": 101400
    },
    {
      "epoch": 0.3161844684703778,
      "grad_norm": 0.6442211270332336,
      "learning_rate": 4.473207690653469e-05,
      "loss": 1.2743,
      "step": 101450
    },
    {
      "epoch": 0.31634030113103345,
      "grad_norm": 0.671593964099884,
      "learning_rate": 4.4729479695523766e-05,
      "loss": 1.3106,
      "step": 101500
    },
    {
      "epoch": 0.3164961337916891,
      "grad_norm": 0.43838775157928467,
      "learning_rate": 4.472688248451283e-05,
      "loss": 1.3062,
      "step": 101550
    },
    {
      "epoch": 0.31665196645234484,
      "grad_norm": 0.5876198410987854,
      "learning_rate": 4.4724285273501904e-05,
      "loss": 1.2978,
      "step": 101600
    },
    {
      "epoch": 0.3168077991130005,
      "grad_norm": 0.6842820048332214,
      "learning_rate": 4.472168806249098e-05,
      "loss": 1.2916,
      "step": 101650
    },
    {
      "epoch": 0.31696363177365616,
      "grad_norm": 0.7091017365455627,
      "learning_rate": 4.471909085148005e-05,
      "loss": 1.2879,
      "step": 101700
    },
    {
      "epoch": 0.3171194644343119,
      "grad_norm": 0.6854441165924072,
      "learning_rate": 4.471649364046912e-05,
      "loss": 1.2622,
      "step": 101750
    },
    {
      "epoch": 0.31727529709496755,
      "grad_norm": 0.6092779040336609,
      "learning_rate": 4.471389642945819e-05,
      "loss": 1.3012,
      "step": 101800
    },
    {
      "epoch": 0.3174311297556232,
      "grad_norm": 0.693956732749939,
      "learning_rate": 4.471129921844727e-05,
      "loss": 1.2829,
      "step": 101850
    },
    {
      "epoch": 0.31758696241627893,
      "grad_norm": 0.606889545917511,
      "learning_rate": 4.470870200743634e-05,
      "loss": 1.2541,
      "step": 101900
    },
    {
      "epoch": 0.3177427950769346,
      "grad_norm": 0.7352508902549744,
      "learning_rate": 4.4706104796425405e-05,
      "loss": 1.2632,
      "step": 101950
    },
    {
      "epoch": 0.31789862773759026,
      "grad_norm": 0.6845191121101379,
      "learning_rate": 4.470350758541448e-05,
      "loss": 1.2175,
      "step": 102000
    },
    {
      "epoch": 0.318054460398246,
      "grad_norm": 0.540234386920929,
      "learning_rate": 4.470091037440356e-05,
      "loss": 1.3506,
      "step": 102050
    },
    {
      "epoch": 0.31821029305890164,
      "grad_norm": 0.6023526787757874,
      "learning_rate": 4.469831316339262e-05,
      "loss": 1.2446,
      "step": 102100
    },
    {
      "epoch": 0.3183661257195573,
      "grad_norm": 0.6849383115768433,
      "learning_rate": 4.4695715952381695e-05,
      "loss": 1.2755,
      "step": 102150
    },
    {
      "epoch": 0.31852195838021297,
      "grad_norm": 0.5520586371421814,
      "learning_rate": 4.469311874137077e-05,
      "loss": 1.2623,
      "step": 102200
    },
    {
      "epoch": 0.3186777910408687,
      "grad_norm": 0.6601771712303162,
      "learning_rate": 4.469052153035984e-05,
      "loss": 1.2498,
      "step": 102250
    },
    {
      "epoch": 0.31883362370152435,
      "grad_norm": 0.6500405073165894,
      "learning_rate": 4.468792431934891e-05,
      "loss": 1.293,
      "step": 102300
    },
    {
      "epoch": 0.31898945636218,
      "grad_norm": 0.5784962177276611,
      "learning_rate": 4.4685327108337985e-05,
      "loss": 1.2753,
      "step": 102350
    },
    {
      "epoch": 0.31914528902283573,
      "grad_norm": 0.5964756608009338,
      "learning_rate": 4.468272989732706e-05,
      "loss": 1.2794,
      "step": 102400
    },
    {
      "epoch": 0.3193011216834914,
      "grad_norm": 0.6511868238449097,
      "learning_rate": 4.468013268631613e-05,
      "loss": 1.3064,
      "step": 102450
    },
    {
      "epoch": 0.31945695434414706,
      "grad_norm": 0.5977102518081665,
      "learning_rate": 4.4677535475305196e-05,
      "loss": 1.321,
      "step": 102500
    },
    {
      "epoch": 0.3196127870048028,
      "grad_norm": 0.6623042821884155,
      "learning_rate": 4.4674938264294275e-05,
      "loss": 1.2813,
      "step": 102550
    },
    {
      "epoch": 0.31976861966545844,
      "grad_norm": 0.6557614803314209,
      "learning_rate": 4.467234105328335e-05,
      "loss": 1.2828,
      "step": 102600
    },
    {
      "epoch": 0.3199244523261141,
      "grad_norm": 0.5823073983192444,
      "learning_rate": 4.466974384227241e-05,
      "loss": 1.2617,
      "step": 102650
    },
    {
      "epoch": 0.3200802849867698,
      "grad_norm": 0.5394653677940369,
      "learning_rate": 4.4667146631261486e-05,
      "loss": 1.2351,
      "step": 102700
    },
    {
      "epoch": 0.3202361176474255,
      "grad_norm": 0.6467834711074829,
      "learning_rate": 4.4664549420250565e-05,
      "loss": 1.2953,
      "step": 102750
    },
    {
      "epoch": 0.32039195030808115,
      "grad_norm": 0.5045218467712402,
      "learning_rate": 4.466195220923963e-05,
      "loss": 1.3215,
      "step": 102800
    },
    {
      "epoch": 0.32054778296873687,
      "grad_norm": 0.6819407939910889,
      "learning_rate": 4.46593549982287e-05,
      "loss": 1.3086,
      "step": 102850
    },
    {
      "epoch": 0.32070361562939254,
      "grad_norm": 0.6775474548339844,
      "learning_rate": 4.4656757787217776e-05,
      "loss": 1.294,
      "step": 102900
    },
    {
      "epoch": 0.3208594482900482,
      "grad_norm": 0.5385020971298218,
      "learning_rate": 4.465416057620685e-05,
      "loss": 1.2354,
      "step": 102950
    },
    {
      "epoch": 0.3210152809507039,
      "grad_norm": 0.5733563899993896,
      "learning_rate": 4.465156336519592e-05,
      "loss": 1.276,
      "step": 103000
    },
    {
      "epoch": 0.3211711136113596,
      "grad_norm": 0.5564776659011841,
      "learning_rate": 4.464896615418499e-05,
      "loss": 1.2656,
      "step": 103050
    },
    {
      "epoch": 0.32132694627201525,
      "grad_norm": 0.5678614377975464,
      "learning_rate": 4.4646368943174066e-05,
      "loss": 1.2106,
      "step": 103100
    },
    {
      "epoch": 0.32148277893267097,
      "grad_norm": 0.6711746454238892,
      "learning_rate": 4.464377173216314e-05,
      "loss": 1.3245,
      "step": 103150
    },
    {
      "epoch": 0.32163861159332663,
      "grad_norm": 0.5655507445335388,
      "learning_rate": 4.4641174521152204e-05,
      "loss": 1.2702,
      "step": 103200
    },
    {
      "epoch": 0.3217944442539823,
      "grad_norm": 0.48463863134384155,
      "learning_rate": 4.4638577310141277e-05,
      "loss": 1.2562,
      "step": 103250
    },
    {
      "epoch": 0.321950276914638,
      "grad_norm": 0.6455929279327393,
      "learning_rate": 4.4635980099130356e-05,
      "loss": 1.2393,
      "step": 103300
    },
    {
      "epoch": 0.3221061095752937,
      "grad_norm": 0.6185289621353149,
      "learning_rate": 4.463338288811942e-05,
      "loss": 1.2708,
      "step": 103350
    },
    {
      "epoch": 0.32226194223594934,
      "grad_norm": 0.7384850978851318,
      "learning_rate": 4.4630785677108494e-05,
      "loss": 1.2548,
      "step": 103400
    },
    {
      "epoch": 0.322417774896605,
      "grad_norm": 0.6032554507255554,
      "learning_rate": 4.462818846609757e-05,
      "loss": 1.2781,
      "step": 103450
    },
    {
      "epoch": 0.3225736075572607,
      "grad_norm": 0.576097846031189,
      "learning_rate": 4.462559125508664e-05,
      "loss": 1.2734,
      "step": 103500
    },
    {
      "epoch": 0.3227294402179164,
      "grad_norm": 0.590056300163269,
      "learning_rate": 4.462299404407571e-05,
      "loss": 1.308,
      "step": 103550
    },
    {
      "epoch": 0.32288527287857205,
      "grad_norm": 0.5991587042808533,
      "learning_rate": 4.4620396833064784e-05,
      "loss": 1.2633,
      "step": 103600
    },
    {
      "epoch": 0.32304110553922777,
      "grad_norm": 0.582976758480072,
      "learning_rate": 4.4617799622053857e-05,
      "loss": 1.2648,
      "step": 103650
    },
    {
      "epoch": 0.32319693819988343,
      "grad_norm": 0.6358640789985657,
      "learning_rate": 4.461520241104293e-05,
      "loss": 1.2985,
      "step": 103700
    },
    {
      "epoch": 0.3233527708605391,
      "grad_norm": 0.45737212896347046,
      "learning_rate": 4.4612605200032e-05,
      "loss": 1.2741,
      "step": 103750
    },
    {
      "epoch": 0.3235086035211948,
      "grad_norm": 0.5955425500869751,
      "learning_rate": 4.4610007989021074e-05,
      "loss": 1.2996,
      "step": 103800
    },
    {
      "epoch": 0.3236644361818505,
      "grad_norm": 0.7190332412719727,
      "learning_rate": 4.4607410778010147e-05,
      "loss": 1.2954,
      "step": 103850
    },
    {
      "epoch": 0.32382026884250614,
      "grad_norm": 0.6888150572776794,
      "learning_rate": 4.460486551121943e-05,
      "loss": 1.2949,
      "step": 103900
    },
    {
      "epoch": 0.32397610150316186,
      "grad_norm": 0.7388259172439575,
      "learning_rate": 4.4602268300208504e-05,
      "loss": 1.3047,
      "step": 103950
    },
    {
      "epoch": 0.3241319341638175,
      "grad_norm": 0.6361538767814636,
      "learning_rate": 4.459967108919758e-05,
      "loss": 1.2491,
      "step": 104000
    },
    {
      "epoch": 0.3242877668244732,
      "grad_norm": 0.4826432168483734,
      "learning_rate": 4.459707387818665e-05,
      "loss": 1.2624,
      "step": 104050
    },
    {
      "epoch": 0.3244435994851289,
      "grad_norm": 0.52118980884552,
      "learning_rate": 4.459447666717572e-05,
      "loss": 1.2382,
      "step": 104100
    },
    {
      "epoch": 0.32459943214578457,
      "grad_norm": 0.6537537574768066,
      "learning_rate": 4.4591879456164794e-05,
      "loss": 1.2843,
      "step": 104150
    },
    {
      "epoch": 0.32475526480644024,
      "grad_norm": 0.6419819593429565,
      "learning_rate": 4.458928224515387e-05,
      "loss": 1.2881,
      "step": 104200
    },
    {
      "epoch": 0.32491109746709596,
      "grad_norm": 0.6644263863563538,
      "learning_rate": 4.458668503414294e-05,
      "loss": 1.3026,
      "step": 104250
    },
    {
      "epoch": 0.3250669301277516,
      "grad_norm": 0.5143871307373047,
      "learning_rate": 4.458408782313201e-05,
      "loss": 1.3003,
      "step": 104300
    },
    {
      "epoch": 0.3252227627884073,
      "grad_norm": 0.6009998917579651,
      "learning_rate": 4.458149061212108e-05,
      "loss": 1.2931,
      "step": 104350
    },
    {
      "epoch": 0.325378595449063,
      "grad_norm": 0.6847239136695862,
      "learning_rate": 4.457889340111016e-05,
      "loss": 1.2345,
      "step": 104400
    },
    {
      "epoch": 0.32553442810971867,
      "grad_norm": 0.7290115356445312,
      "learning_rate": 4.457629619009922e-05,
      "loss": 1.2354,
      "step": 104450
    },
    {
      "epoch": 0.32569026077037433,
      "grad_norm": 0.5662927627563477,
      "learning_rate": 4.4573698979088295e-05,
      "loss": 1.2459,
      "step": 104500
    },
    {
      "epoch": 0.32584609343103005,
      "grad_norm": 0.7260034680366516,
      "learning_rate": 4.4571101768077374e-05,
      "loss": 1.2724,
      "step": 104550
    },
    {
      "epoch": 0.3260019260916857,
      "grad_norm": 0.6172962784767151,
      "learning_rate": 4.456850455706644e-05,
      "loss": 1.2257,
      "step": 104600
    },
    {
      "epoch": 0.3261577587523414,
      "grad_norm": 0.6030847430229187,
      "learning_rate": 4.456590734605551e-05,
      "loss": 1.3001,
      "step": 104650
    },
    {
      "epoch": 0.3263135914129971,
      "grad_norm": 0.6361303329467773,
      "learning_rate": 4.4563310135044585e-05,
      "loss": 1.243,
      "step": 104700
    },
    {
      "epoch": 0.32646942407365276,
      "grad_norm": 0.7363646030426025,
      "learning_rate": 4.456071292403366e-05,
      "loss": 1.2797,
      "step": 104750
    },
    {
      "epoch": 0.3266252567343084,
      "grad_norm": 0.6007058024406433,
      "learning_rate": 4.455811571302273e-05,
      "loss": 1.2664,
      "step": 104800
    },
    {
      "epoch": 0.3267810893949641,
      "grad_norm": 0.4273405969142914,
      "learning_rate": 4.45555185020118e-05,
      "loss": 1.2426,
      "step": 104850
    },
    {
      "epoch": 0.3269369220556198,
      "grad_norm": 0.6700474619865417,
      "learning_rate": 4.4552921291000875e-05,
      "loss": 1.2711,
      "step": 104900
    },
    {
      "epoch": 0.32709275471627547,
      "grad_norm": 0.6443252563476562,
      "learning_rate": 4.455032407998995e-05,
      "loss": 1.3054,
      "step": 104950
    },
    {
      "epoch": 0.32724858737693113,
      "grad_norm": 0.7288479804992676,
      "learning_rate": 4.454772686897902e-05,
      "loss": 1.2921,
      "step": 105000
    },
    {
      "epoch": 0.32740442003758685,
      "grad_norm": 0.6198641061782837,
      "learning_rate": 4.4545129657968086e-05,
      "loss": 1.2452,
      "step": 105050
    },
    {
      "epoch": 0.3275602526982425,
      "grad_norm": 0.5289993286132812,
      "learning_rate": 4.4542532446957165e-05,
      "loss": 1.2957,
      "step": 105100
    },
    {
      "epoch": 0.3277160853588982,
      "grad_norm": 0.5066801905632019,
      "learning_rate": 4.453993523594623e-05,
      "loss": 1.2427,
      "step": 105150
    },
    {
      "epoch": 0.3278719180195539,
      "grad_norm": 0.5546957850456238,
      "learning_rate": 4.4537338024935303e-05,
      "loss": 1.2686,
      "step": 105200
    },
    {
      "epoch": 0.32802775068020956,
      "grad_norm": 0.7022430896759033,
      "learning_rate": 4.4534740813924376e-05,
      "loss": 1.2704,
      "step": 105250
    },
    {
      "epoch": 0.3281835833408652,
      "grad_norm": 0.5387314558029175,
      "learning_rate": 4.453214360291345e-05,
      "loss": 1.2655,
      "step": 105300
    },
    {
      "epoch": 0.32833941600152095,
      "grad_norm": 0.5360340476036072,
      "learning_rate": 4.452954639190252e-05,
      "loss": 1.2852,
      "step": 105350
    },
    {
      "epoch": 0.3284952486621766,
      "grad_norm": 0.7305423617362976,
      "learning_rate": 4.4526949180891593e-05,
      "loss": 1.2919,
      "step": 105400
    },
    {
      "epoch": 0.3286510813228323,
      "grad_norm": 0.5766274333000183,
      "learning_rate": 4.4524351969880666e-05,
      "loss": 1.3095,
      "step": 105450
    },
    {
      "epoch": 0.328806913983488,
      "grad_norm": 0.5716481804847717,
      "learning_rate": 4.452175475886974e-05,
      "loss": 1.3326,
      "step": 105500
    },
    {
      "epoch": 0.32896274664414366,
      "grad_norm": 0.5349916219711304,
      "learning_rate": 4.451915754785881e-05,
      "loss": 1.3473,
      "step": 105550
    },
    {
      "epoch": 0.3291185793047993,
      "grad_norm": 0.6268051862716675,
      "learning_rate": 4.451656033684788e-05,
      "loss": 1.2698,
      "step": 105600
    },
    {
      "epoch": 0.32927441196545504,
      "grad_norm": 0.5047663450241089,
      "learning_rate": 4.4513963125836956e-05,
      "loss": 1.3416,
      "step": 105650
    },
    {
      "epoch": 0.3294302446261107,
      "grad_norm": 0.859217643737793,
      "learning_rate": 4.451136591482603e-05,
      "loss": 1.2052,
      "step": 105700
    },
    {
      "epoch": 0.32958607728676637,
      "grad_norm": 0.6013326048851013,
      "learning_rate": 4.4508768703815094e-05,
      "loss": 1.2662,
      "step": 105750
    },
    {
      "epoch": 0.3297419099474221,
      "grad_norm": 0.6152858138084412,
      "learning_rate": 4.4506171492804173e-05,
      "loss": 1.2856,
      "step": 105800
    },
    {
      "epoch": 0.32989774260807775,
      "grad_norm": 0.6372882127761841,
      "learning_rate": 4.450357428179324e-05,
      "loss": 1.3086,
      "step": 105850
    },
    {
      "epoch": 0.3300535752687334,
      "grad_norm": 0.6351324319839478,
      "learning_rate": 4.450097707078231e-05,
      "loss": 1.2725,
      "step": 105900
    },
    {
      "epoch": 0.33020940792938913,
      "grad_norm": 0.611475944519043,
      "learning_rate": 4.4498379859771384e-05,
      "loss": 1.2605,
      "step": 105950
    },
    {
      "epoch": 0.3303652405900448,
      "grad_norm": 0.6757643818855286,
      "learning_rate": 4.449578264876046e-05,
      "loss": 1.3327,
      "step": 106000
    },
    {
      "epoch": 0.33052107325070046,
      "grad_norm": 0.7760528326034546,
      "learning_rate": 4.449318543774953e-05,
      "loss": 1.2705,
      "step": 106050
    },
    {
      "epoch": 0.3306769059113561,
      "grad_norm": 0.500226616859436,
      "learning_rate": 4.44905882267386e-05,
      "loss": 1.2981,
      "step": 106100
    },
    {
      "epoch": 0.33083273857201184,
      "grad_norm": 0.5212945342063904,
      "learning_rate": 4.4487991015727674e-05,
      "loss": 1.3052,
      "step": 106150
    },
    {
      "epoch": 0.3309885712326675,
      "grad_norm": 0.6872866749763489,
      "learning_rate": 4.448539380471675e-05,
      "loss": 1.2903,
      "step": 106200
    },
    {
      "epoch": 0.33114440389332317,
      "grad_norm": 0.6403462290763855,
      "learning_rate": 4.448279659370582e-05,
      "loss": 1.3017,
      "step": 106250
    },
    {
      "epoch": 0.3313002365539789,
      "grad_norm": 0.6442083120346069,
      "learning_rate": 4.4480199382694885e-05,
      "loss": 1.2589,
      "step": 106300
    },
    {
      "epoch": 0.33145606921463455,
      "grad_norm": 0.5425065159797668,
      "learning_rate": 4.4477602171683964e-05,
      "loss": 1.247,
      "step": 106350
    },
    {
      "epoch": 0.3316119018752902,
      "grad_norm": 0.5714404582977295,
      "learning_rate": 4.447500496067304e-05,
      "loss": 1.215,
      "step": 106400
    },
    {
      "epoch": 0.33176773453594594,
      "grad_norm": 0.47033190727233887,
      "learning_rate": 4.44724077496621e-05,
      "loss": 1.2679,
      "step": 106450
    },
    {
      "epoch": 0.3319235671966016,
      "grad_norm": 0.7768062949180603,
      "learning_rate": 4.4469810538651175e-05,
      "loss": 1.2735,
      "step": 106500
    },
    {
      "epoch": 0.33207939985725726,
      "grad_norm": 0.5927753448486328,
      "learning_rate": 4.446721332764025e-05,
      "loss": 1.2838,
      "step": 106550
    },
    {
      "epoch": 0.332235232517913,
      "grad_norm": 0.49736157059669495,
      "learning_rate": 4.446461611662932e-05,
      "loss": 1.2853,
      "step": 106600
    },
    {
      "epoch": 0.33239106517856865,
      "grad_norm": 0.43462467193603516,
      "learning_rate": 4.446201890561839e-05,
      "loss": 1.2605,
      "step": 106650
    },
    {
      "epoch": 0.3325468978392243,
      "grad_norm": 0.6487023234367371,
      "learning_rate": 4.4459421694607465e-05,
      "loss": 1.2473,
      "step": 106700
    },
    {
      "epoch": 0.33270273049988003,
      "grad_norm": 0.583764374256134,
      "learning_rate": 4.445682448359654e-05,
      "loss": 1.2963,
      "step": 106750
    },
    {
      "epoch": 0.3328585631605357,
      "grad_norm": 0.6755040287971497,
      "learning_rate": 4.445422727258561e-05,
      "loss": 1.2577,
      "step": 106800
    },
    {
      "epoch": 0.33301439582119136,
      "grad_norm": 0.48181986808776855,
      "learning_rate": 4.4451630061574676e-05,
      "loss": 1.321,
      "step": 106850
    },
    {
      "epoch": 0.3331702284818471,
      "grad_norm": 0.5579139590263367,
      "learning_rate": 4.4449032850563755e-05,
      "loss": 1.3087,
      "step": 106900
    },
    {
      "epoch": 0.33332606114250274,
      "grad_norm": 0.6655833721160889,
      "learning_rate": 4.444643563955283e-05,
      "loss": 1.2943,
      "step": 106950
    },
    {
      "epoch": 0.3334818938031584,
      "grad_norm": 0.6189484596252441,
      "learning_rate": 4.444389037276211e-05,
      "loss": 1.2708,
      "step": 107000
    },
    {
      "epoch": 0.3336377264638141,
      "grad_norm": 0.5205338001251221,
      "learning_rate": 4.4441293161751185e-05,
      "loss": 1.2583,
      "step": 107050
    },
    {
      "epoch": 0.3337935591244698,
      "grad_norm": 0.5519961714744568,
      "learning_rate": 4.443869595074026e-05,
      "loss": 1.3064,
      "step": 107100
    },
    {
      "epoch": 0.33394939178512545,
      "grad_norm": 0.5291520953178406,
      "learning_rate": 4.443609873972933e-05,
      "loss": 1.2822,
      "step": 107150
    },
    {
      "epoch": 0.33410522444578117,
      "grad_norm": 0.7634178996086121,
      "learning_rate": 4.44335015287184e-05,
      "loss": 1.2618,
      "step": 107200
    },
    {
      "epoch": 0.33426105710643683,
      "grad_norm": 0.6161315441131592,
      "learning_rate": 4.4430904317707475e-05,
      "loss": 1.2519,
      "step": 107250
    },
    {
      "epoch": 0.3344168897670925,
      "grad_norm": 0.6298354268074036,
      "learning_rate": 4.442830710669655e-05,
      "loss": 1.2684,
      "step": 107300
    },
    {
      "epoch": 0.33457272242774816,
      "grad_norm": 0.5324782133102417,
      "learning_rate": 4.442570989568562e-05,
      "loss": 1.2878,
      "step": 107350
    },
    {
      "epoch": 0.3347285550884039,
      "grad_norm": 0.5226105451583862,
      "learning_rate": 4.4423112684674686e-05,
      "loss": 1.2395,
      "step": 107400
    },
    {
      "epoch": 0.33488438774905954,
      "grad_norm": 0.4177846312522888,
      "learning_rate": 4.4420515473663765e-05,
      "loss": 1.2621,
      "step": 107450
    },
    {
      "epoch": 0.3350402204097152,
      "grad_norm": 0.5460736751556396,
      "learning_rate": 4.441791826265284e-05,
      "loss": 1.2955,
      "step": 107500
    },
    {
      "epoch": 0.3351960530703709,
      "grad_norm": 0.5842162370681763,
      "learning_rate": 4.4415321051641904e-05,
      "loss": 1.2474,
      "step": 107550
    },
    {
      "epoch": 0.3353518857310266,
      "grad_norm": 0.6069103479385376,
      "learning_rate": 4.4412723840630976e-05,
      "loss": 1.282,
      "step": 107600
    },
    {
      "epoch": 0.33550771839168225,
      "grad_norm": 0.5901483297348022,
      "learning_rate": 4.4410126629620055e-05,
      "loss": 1.2881,
      "step": 107650
    },
    {
      "epoch": 0.33566355105233797,
      "grad_norm": 0.6028290390968323,
      "learning_rate": 4.440752941860912e-05,
      "loss": 1.3052,
      "step": 107700
    },
    {
      "epoch": 0.33581938371299364,
      "grad_norm": 0.5455816984176636,
      "learning_rate": 4.4404932207598194e-05,
      "loss": 1.3022,
      "step": 107750
    },
    {
      "epoch": 0.3359752163736493,
      "grad_norm": 0.8271147012710571,
      "learning_rate": 4.4402334996587266e-05,
      "loss": 1.2684,
      "step": 107800
    },
    {
      "epoch": 0.336131049034305,
      "grad_norm": 0.6111274361610413,
      "learning_rate": 4.439973778557634e-05,
      "loss": 1.3189,
      "step": 107850
    },
    {
      "epoch": 0.3362868816949607,
      "grad_norm": 0.5184516310691833,
      "learning_rate": 4.439714057456541e-05,
      "loss": 1.3036,
      "step": 107900
    },
    {
      "epoch": 0.33644271435561635,
      "grad_norm": 0.5219009518623352,
      "learning_rate": 4.4394543363554484e-05,
      "loss": 1.3238,
      "step": 107950
    },
    {
      "epoch": 0.33659854701627206,
      "grad_norm": 0.5387771725654602,
      "learning_rate": 4.4391946152543556e-05,
      "loss": 1.2459,
      "step": 108000
    },
    {
      "epoch": 0.33675437967692773,
      "grad_norm": 0.5909059047698975,
      "learning_rate": 4.438934894153263e-05,
      "loss": 1.2897,
      "step": 108050
    },
    {
      "epoch": 0.3369102123375834,
      "grad_norm": 0.7278880476951599,
      "learning_rate": 4.4386751730521694e-05,
      "loss": 1.3013,
      "step": 108100
    },
    {
      "epoch": 0.3370660449982391,
      "grad_norm": 0.7954710125923157,
      "learning_rate": 4.4384154519510774e-05,
      "loss": 1.2765,
      "step": 108150
    },
    {
      "epoch": 0.3372218776588948,
      "grad_norm": 0.6399828791618347,
      "learning_rate": 4.4381557308499846e-05,
      "loss": 1.3417,
      "step": 108200
    },
    {
      "epoch": 0.33737771031955044,
      "grad_norm": 0.7876444458961487,
      "learning_rate": 4.437896009748891e-05,
      "loss": 1.2091,
      "step": 108250
    },
    {
      "epoch": 0.33753354298020616,
      "grad_norm": 0.5800461173057556,
      "learning_rate": 4.4376362886477984e-05,
      "loss": 1.3083,
      "step": 108300
    },
    {
      "epoch": 0.3376893756408618,
      "grad_norm": 0.5127671957015991,
      "learning_rate": 4.4373765675467064e-05,
      "loss": 1.2969,
      "step": 108350
    },
    {
      "epoch": 0.3378452083015175,
      "grad_norm": 0.6025092005729675,
      "learning_rate": 4.437116846445613e-05,
      "loss": 1.3245,
      "step": 108400
    },
    {
      "epoch": 0.3380010409621732,
      "grad_norm": 0.7275633811950684,
      "learning_rate": 4.43685712534452e-05,
      "loss": 1.3014,
      "step": 108450
    },
    {
      "epoch": 0.33815687362282887,
      "grad_norm": 0.5386354327201843,
      "learning_rate": 4.4365974042434274e-05,
      "loss": 1.3041,
      "step": 108500
    },
    {
      "epoch": 0.33831270628348453,
      "grad_norm": 0.685849130153656,
      "learning_rate": 4.4363428775643567e-05,
      "loss": 1.2821,
      "step": 108550
    },
    {
      "epoch": 0.33846853894414025,
      "grad_norm": 0.4916180372238159,
      "learning_rate": 4.436083156463264e-05,
      "loss": 1.3095,
      "step": 108600
    },
    {
      "epoch": 0.3386243716047959,
      "grad_norm": 0.6783302426338196,
      "learning_rate": 4.435823435362171e-05,
      "loss": 1.2911,
      "step": 108650
    },
    {
      "epoch": 0.3387802042654516,
      "grad_norm": 0.5979049801826477,
      "learning_rate": 4.435563714261078e-05,
      "loss": 1.3134,
      "step": 108700
    },
    {
      "epoch": 0.33893603692610724,
      "grad_norm": 0.5313169360160828,
      "learning_rate": 4.4353039931599857e-05,
      "loss": 1.3164,
      "step": 108750
    },
    {
      "epoch": 0.33909186958676296,
      "grad_norm": 0.45856305956840515,
      "learning_rate": 4.435044272058892e-05,
      "loss": 1.2733,
      "step": 108800
    },
    {
      "epoch": 0.3392477022474186,
      "grad_norm": 0.5142455697059631,
      "learning_rate": 4.4347845509577995e-05,
      "loss": 1.2846,
      "step": 108850
    },
    {
      "epoch": 0.3394035349080743,
      "grad_norm": 0.6858980059623718,
      "learning_rate": 4.4345248298567074e-05,
      "loss": 1.2073,
      "step": 108900
    },
    {
      "epoch": 0.33955936756873,
      "grad_norm": 0.6039164066314697,
      "learning_rate": 4.434265108755614e-05,
      "loss": 1.2883,
      "step": 108950
    },
    {
      "epoch": 0.33971520022938567,
      "grad_norm": 0.666096031665802,
      "learning_rate": 4.434005387654521e-05,
      "loss": 1.2528,
      "step": 109000
    },
    {
      "epoch": 0.33987103289004134,
      "grad_norm": 0.6132872700691223,
      "learning_rate": 4.4337456665534285e-05,
      "loss": 1.3056,
      "step": 109050
    },
    {
      "epoch": 0.34002686555069705,
      "grad_norm": 0.6795283555984497,
      "learning_rate": 4.433485945452336e-05,
      "loss": 1.2733,
      "step": 109100
    },
    {
      "epoch": 0.3401826982113527,
      "grad_norm": 0.7336065173149109,
      "learning_rate": 4.433226224351243e-05,
      "loss": 1.2569,
      "step": 109150
    },
    {
      "epoch": 0.3403385308720084,
      "grad_norm": 0.5362191200256348,
      "learning_rate": 4.43296650325015e-05,
      "loss": 1.2708,
      "step": 109200
    },
    {
      "epoch": 0.3404943635326641,
      "grad_norm": 0.5475890636444092,
      "learning_rate": 4.4327067821490575e-05,
      "loss": 1.2932,
      "step": 109250
    },
    {
      "epoch": 0.34065019619331977,
      "grad_norm": 0.5475131273269653,
      "learning_rate": 4.432447061047965e-05,
      "loss": 1.3113,
      "step": 109300
    },
    {
      "epoch": 0.34080602885397543,
      "grad_norm": 0.5205106139183044,
      "learning_rate": 4.432187339946871e-05,
      "loss": 1.272,
      "step": 109350
    },
    {
      "epoch": 0.34096186151463115,
      "grad_norm": 0.6044150590896606,
      "learning_rate": 4.4319276188457786e-05,
      "loss": 1.2927,
      "step": 109400
    },
    {
      "epoch": 0.3411176941752868,
      "grad_norm": 0.5836431980133057,
      "learning_rate": 4.4316678977446865e-05,
      "loss": 1.2664,
      "step": 109450
    },
    {
      "epoch": 0.3412735268359425,
      "grad_norm": 0.4727257788181305,
      "learning_rate": 4.431408176643593e-05,
      "loss": 1.2628,
      "step": 109500
    },
    {
      "epoch": 0.3414293594965982,
      "grad_norm": 0.7636374235153198,
      "learning_rate": 4.4311484555425e-05,
      "loss": 1.2694,
      "step": 109550
    },
    {
      "epoch": 0.34158519215725386,
      "grad_norm": 0.8061033487319946,
      "learning_rate": 4.4308887344414076e-05,
      "loss": 1.2736,
      "step": 109600
    },
    {
      "epoch": 0.3417410248179095,
      "grad_norm": 0.6514426469802856,
      "learning_rate": 4.430629013340315e-05,
      "loss": 1.2485,
      "step": 109650
    },
    {
      "epoch": 0.34189685747856524,
      "grad_norm": 0.5553919076919556,
      "learning_rate": 4.430369292239222e-05,
      "loss": 1.2701,
      "step": 109700
    },
    {
      "epoch": 0.3420526901392209,
      "grad_norm": 0.5434969067573547,
      "learning_rate": 4.430109571138129e-05,
      "loss": 1.2863,
      "step": 109750
    },
    {
      "epoch": 0.34220852279987657,
      "grad_norm": 0.6124758720397949,
      "learning_rate": 4.4298498500370366e-05,
      "loss": 1.2809,
      "step": 109800
    },
    {
      "epoch": 0.3423643554605323,
      "grad_norm": 0.6127581596374512,
      "learning_rate": 4.429590128935944e-05,
      "loss": 1.316,
      "step": 109850
    },
    {
      "epoch": 0.34252018812118795,
      "grad_norm": 0.5340418219566345,
      "learning_rate": 4.429330407834851e-05,
      "loss": 1.2707,
      "step": 109900
    },
    {
      "epoch": 0.3426760207818436,
      "grad_norm": 0.5414122939109802,
      "learning_rate": 4.4290706867337576e-05,
      "loss": 1.3204,
      "step": 109950
    },
    {
      "epoch": 0.3428318534424993,
      "grad_norm": 0.6009647846221924,
      "learning_rate": 4.4288109656326656e-05,
      "loss": 1.2812,
      "step": 110000
    },
    {
      "epoch": 0.342987686103155,
      "grad_norm": 0.5372095704078674,
      "learning_rate": 4.428551244531572e-05,
      "loss": 1.2808,
      "step": 110050
    },
    {
      "epoch": 0.34314351876381066,
      "grad_norm": 0.5249205231666565,
      "learning_rate": 4.4282915234304794e-05,
      "loss": 1.344,
      "step": 110100
    },
    {
      "epoch": 0.3432993514244663,
      "grad_norm": 0.5190884470939636,
      "learning_rate": 4.428031802329387e-05,
      "loss": 1.2713,
      "step": 110150
    },
    {
      "epoch": 0.34345518408512205,
      "grad_norm": 0.6011179089546204,
      "learning_rate": 4.427772081228294e-05,
      "loss": 1.282,
      "step": 110200
    },
    {
      "epoch": 0.3436110167457777,
      "grad_norm": 0.6341668367385864,
      "learning_rate": 4.427512360127201e-05,
      "loss": 1.2871,
      "step": 110250
    },
    {
      "epoch": 0.3437668494064334,
      "grad_norm": 0.5822368264198303,
      "learning_rate": 4.4272526390261084e-05,
      "loss": 1.3234,
      "step": 110300
    },
    {
      "epoch": 0.3439226820670891,
      "grad_norm": 0.47275039553642273,
      "learning_rate": 4.4269929179250156e-05,
      "loss": 1.2733,
      "step": 110350
    },
    {
      "epoch": 0.34407851472774476,
      "grad_norm": 0.5043335556983948,
      "learning_rate": 4.426733196823923e-05,
      "loss": 1.3332,
      "step": 110400
    },
    {
      "epoch": 0.3442343473884004,
      "grad_norm": 1.0886439085006714,
      "learning_rate": 4.42647347572283e-05,
      "loss": 1.2823,
      "step": 110450
    },
    {
      "epoch": 0.34439018004905614,
      "grad_norm": 0.7395328283309937,
      "learning_rate": 4.426213754621737e-05,
      "loss": 1.2857,
      "step": 110500
    },
    {
      "epoch": 0.3445460127097118,
      "grad_norm": 0.6749351024627686,
      "learning_rate": 4.4259540335206446e-05,
      "loss": 1.2533,
      "step": 110550
    },
    {
      "epoch": 0.34470184537036747,
      "grad_norm": 0.6646203994750977,
      "learning_rate": 4.425694312419552e-05,
      "loss": 1.2232,
      "step": 110600
    },
    {
      "epoch": 0.3448576780310232,
      "grad_norm": 0.5490636229515076,
      "learning_rate": 4.4254345913184585e-05,
      "loss": 1.2804,
      "step": 110650
    },
    {
      "epoch": 0.34501351069167885,
      "grad_norm": 0.6342117190361023,
      "learning_rate": 4.4251748702173664e-05,
      "loss": 1.2839,
      "step": 110700
    },
    {
      "epoch": 0.3451693433523345,
      "grad_norm": 0.7436380386352539,
      "learning_rate": 4.424915149116273e-05,
      "loss": 1.19,
      "step": 110750
    },
    {
      "epoch": 0.34532517601299023,
      "grad_norm": 0.42988523840904236,
      "learning_rate": 4.42465542801518e-05,
      "loss": 1.3071,
      "step": 110800
    },
    {
      "epoch": 0.3454810086736459,
      "grad_norm": 0.8467756509780884,
      "learning_rate": 4.4243957069140875e-05,
      "loss": 1.2628,
      "step": 110850
    },
    {
      "epoch": 0.34563684133430156,
      "grad_norm": 0.6491791605949402,
      "learning_rate": 4.424135985812995e-05,
      "loss": 1.3574,
      "step": 110900
    },
    {
      "epoch": 0.3457926739949573,
      "grad_norm": 0.613528847694397,
      "learning_rate": 4.423876264711902e-05,
      "loss": 1.2945,
      "step": 110950
    },
    {
      "epoch": 0.34594850665561294,
      "grad_norm": 0.5583953261375427,
      "learning_rate": 4.423616543610809e-05,
      "loss": 1.2968,
      "step": 111000
    },
    {
      "epoch": 0.3461043393162686,
      "grad_norm": 0.5787559747695923,
      "learning_rate": 4.4233568225097165e-05,
      "loss": 1.3063,
      "step": 111050
    },
    {
      "epoch": 0.3462601719769243,
      "grad_norm": 0.700124204158783,
      "learning_rate": 4.423097101408624e-05,
      "loss": 1.2793,
      "step": 111100
    },
    {
      "epoch": 0.34641600463758,
      "grad_norm": 0.47414299845695496,
      "learning_rate": 4.422837380307531e-05,
      "loss": 1.2458,
      "step": 111150
    },
    {
      "epoch": 0.34657183729823565,
      "grad_norm": 0.5962978601455688,
      "learning_rate": 4.4225776592064375e-05,
      "loss": 1.3249,
      "step": 111200
    },
    {
      "epoch": 0.34672766995889137,
      "grad_norm": 0.47730979323387146,
      "learning_rate": 4.4223179381053455e-05,
      "loss": 1.3087,
      "step": 111250
    },
    {
      "epoch": 0.34688350261954704,
      "grad_norm": 0.6633914113044739,
      "learning_rate": 4.422058217004253e-05,
      "loss": 1.2875,
      "step": 111300
    },
    {
      "epoch": 0.3470393352802027,
      "grad_norm": 0.6535377502441406,
      "learning_rate": 4.421798495903159e-05,
      "loss": 1.2876,
      "step": 111350
    },
    {
      "epoch": 0.34719516794085836,
      "grad_norm": 0.6824945211410522,
      "learning_rate": 4.421538774802067e-05,
      "loss": 1.3084,
      "step": 111400
    },
    {
      "epoch": 0.3473510006015141,
      "grad_norm": 0.6465268135070801,
      "learning_rate": 4.421279053700974e-05,
      "loss": 1.2953,
      "step": 111450
    },
    {
      "epoch": 0.34750683326216975,
      "grad_norm": 0.584234356880188,
      "learning_rate": 4.421019332599881e-05,
      "loss": 1.2418,
      "step": 111500
    },
    {
      "epoch": 0.3476626659228254,
      "grad_norm": 0.6138319969177246,
      "learning_rate": 4.420759611498788e-05,
      "loss": 1.2841,
      "step": 111550
    },
    {
      "epoch": 0.34781849858348113,
      "grad_norm": 0.5693316459655762,
      "learning_rate": 4.4204998903976955e-05,
      "loss": 1.2838,
      "step": 111600
    },
    {
      "epoch": 0.3479743312441368,
      "grad_norm": 0.597461998462677,
      "learning_rate": 4.420240169296603e-05,
      "loss": 1.2671,
      "step": 111650
    },
    {
      "epoch": 0.34813016390479246,
      "grad_norm": 0.5571076273918152,
      "learning_rate": 4.41998044819551e-05,
      "loss": 1.2601,
      "step": 111700
    },
    {
      "epoch": 0.3482859965654482,
      "grad_norm": 0.5974952578544617,
      "learning_rate": 4.4197207270944166e-05,
      "loss": 1.2886,
      "step": 111750
    },
    {
      "epoch": 0.34844182922610384,
      "grad_norm": 0.6387823820114136,
      "learning_rate": 4.4194610059933245e-05,
      "loss": 1.2737,
      "step": 111800
    },
    {
      "epoch": 0.3485976618867595,
      "grad_norm": 0.5534796118736267,
      "learning_rate": 4.419201284892232e-05,
      "loss": 1.3038,
      "step": 111850
    },
    {
      "epoch": 0.3487534945474152,
      "grad_norm": 0.555801510810852,
      "learning_rate": 4.4189415637911384e-05,
      "loss": 1.2697,
      "step": 111900
    },
    {
      "epoch": 0.3489093272080709,
      "grad_norm": 0.6210821866989136,
      "learning_rate": 4.418681842690046e-05,
      "loss": 1.3013,
      "step": 111950
    },
    {
      "epoch": 0.34906515986872655,
      "grad_norm": 0.5703189373016357,
      "learning_rate": 4.418422121588953e-05,
      "loss": 1.3087,
      "step": 112000
    },
    {
      "epoch": 0.34922099252938227,
      "grad_norm": 0.6166641116142273,
      "learning_rate": 4.41816240048786e-05,
      "loss": 1.2211,
      "step": 112050
    },
    {
      "epoch": 0.34937682519003793,
      "grad_norm": 0.6784728169441223,
      "learning_rate": 4.4179026793867674e-05,
      "loss": 1.2556,
      "step": 112100
    },
    {
      "epoch": 0.3495326578506936,
      "grad_norm": 0.5953404307365417,
      "learning_rate": 4.4176429582856746e-05,
      "loss": 1.3236,
      "step": 112150
    },
    {
      "epoch": 0.3496884905113493,
      "grad_norm": 0.6170783638954163,
      "learning_rate": 4.417383237184582e-05,
      "loss": 1.3329,
      "step": 112200
    },
    {
      "epoch": 0.349844323172005,
      "grad_norm": 0.5582447052001953,
      "learning_rate": 4.417123516083489e-05,
      "loss": 1.2717,
      "step": 112250
    },
    {
      "epoch": 0.35000015583266064,
      "grad_norm": 0.6063812971115112,
      "learning_rate": 4.4168637949823964e-05,
      "loss": 1.2804,
      "step": 112300
    },
    {
      "epoch": 0.35015598849331636,
      "grad_norm": 0.503989577293396,
      "learning_rate": 4.4166040738813036e-05,
      "loss": 1.2762,
      "step": 112350
    },
    {
      "epoch": 0.350311821153972,
      "grad_norm": 0.45014339685440063,
      "learning_rate": 4.416344352780211e-05,
      "loss": 1.3253,
      "step": 112400
    },
    {
      "epoch": 0.3504676538146277,
      "grad_norm": 0.7538781762123108,
      "learning_rate": 4.4160846316791174e-05,
      "loss": 1.3158,
      "step": 112450
    },
    {
      "epoch": 0.3506234864752834,
      "grad_norm": 0.5688425302505493,
      "learning_rate": 4.4158249105780254e-05,
      "loss": 1.3545,
      "step": 112500
    },
    {
      "epoch": 0.35077931913593907,
      "grad_norm": 0.54268878698349,
      "learning_rate": 4.4155651894769326e-05,
      "loss": 1.2406,
      "step": 112550
    },
    {
      "epoch": 0.35093515179659474,
      "grad_norm": 0.5337616205215454,
      "learning_rate": 4.415305468375839e-05,
      "loss": 1.2942,
      "step": 112600
    },
    {
      "epoch": 0.3510909844572504,
      "grad_norm": 0.5461151003837585,
      "learning_rate": 4.415045747274747e-05,
      "loss": 1.317,
      "step": 112650
    },
    {
      "epoch": 0.3512468171179061,
      "grad_norm": 0.5979509949684143,
      "learning_rate": 4.414786026173654e-05,
      "loss": 1.242,
      "step": 112700
    },
    {
      "epoch": 0.3514026497785618,
      "grad_norm": 0.5875179171562195,
      "learning_rate": 4.414526305072561e-05,
      "loss": 1.287,
      "step": 112750
    },
    {
      "epoch": 0.35155848243921745,
      "grad_norm": 0.6261317133903503,
      "learning_rate": 4.414266583971468e-05,
      "loss": 1.2777,
      "step": 112800
    },
    {
      "epoch": 0.35171431509987316,
      "grad_norm": 0.6655274629592896,
      "learning_rate": 4.4140068628703754e-05,
      "loss": 1.2566,
      "step": 112850
    },
    {
      "epoch": 0.35187014776052883,
      "grad_norm": 0.7226116061210632,
      "learning_rate": 4.413747141769283e-05,
      "loss": 1.2542,
      "step": 112900
    },
    {
      "epoch": 0.3520259804211845,
      "grad_norm": 0.626375138759613,
      "learning_rate": 4.41348742066819e-05,
      "loss": 1.33,
      "step": 112950
    },
    {
      "epoch": 0.3521818130818402,
      "grad_norm": 0.5071990489959717,
      "learning_rate": 4.4132276995670965e-05,
      "loss": 1.3108,
      "step": 113000
    },
    {
      "epoch": 0.3523376457424959,
      "grad_norm": 0.663275420665741,
      "learning_rate": 4.4129679784660044e-05,
      "loss": 1.3067,
      "step": 113050
    },
    {
      "epoch": 0.35249347840315154,
      "grad_norm": 0.6414699554443359,
      "learning_rate": 4.412708257364912e-05,
      "loss": 1.272,
      "step": 113100
    },
    {
      "epoch": 0.35264931106380726,
      "grad_norm": 0.7070514559745789,
      "learning_rate": 4.412448536263818e-05,
      "loss": 1.2785,
      "step": 113150
    },
    {
      "epoch": 0.3528051437244629,
      "grad_norm": 0.7964690923690796,
      "learning_rate": 4.412188815162726e-05,
      "loss": 1.3391,
      "step": 113200
    },
    {
      "epoch": 0.3529609763851186,
      "grad_norm": 0.5090782046318054,
      "learning_rate": 4.4119290940616334e-05,
      "loss": 1.2432,
      "step": 113250
    },
    {
      "epoch": 0.3531168090457743,
      "grad_norm": 0.6265032291412354,
      "learning_rate": 4.41166937296054e-05,
      "loss": 1.3273,
      "step": 113300
    },
    {
      "epoch": 0.35327264170642997,
      "grad_norm": 0.6059579253196716,
      "learning_rate": 4.411409651859447e-05,
      "loss": 1.3044,
      "step": 113350
    },
    {
      "epoch": 0.35342847436708563,
      "grad_norm": 0.5365706086158752,
      "learning_rate": 4.4111499307583545e-05,
      "loss": 1.2598,
      "step": 113400
    },
    {
      "epoch": 0.35358430702774135,
      "grad_norm": 0.5497106909751892,
      "learning_rate": 4.410890209657262e-05,
      "loss": 1.2923,
      "step": 113450
    },
    {
      "epoch": 0.353740139688397,
      "grad_norm": 0.4447192847728729,
      "learning_rate": 4.410630488556169e-05,
      "loss": 1.2513,
      "step": 113500
    },
    {
      "epoch": 0.3538959723490527,
      "grad_norm": 0.491627037525177,
      "learning_rate": 4.410370767455076e-05,
      "loss": 1.3367,
      "step": 113550
    },
    {
      "epoch": 0.3540518050097084,
      "grad_norm": 0.6113965511322021,
      "learning_rate": 4.4101110463539835e-05,
      "loss": 1.3132,
      "step": 113600
    },
    {
      "epoch": 0.35420763767036406,
      "grad_norm": 0.5870251655578613,
      "learning_rate": 4.409851325252891e-05,
      "loss": 1.3137,
      "step": 113650
    },
    {
      "epoch": 0.3543634703310197,
      "grad_norm": 0.6384857296943665,
      "learning_rate": 4.409591604151797e-05,
      "loss": 1.2988,
      "step": 113700
    },
    {
      "epoch": 0.35451930299167544,
      "grad_norm": 0.5833512544631958,
      "learning_rate": 4.409331883050705e-05,
      "loss": 1.2412,
      "step": 113750
    },
    {
      "epoch": 0.3546751356523311,
      "grad_norm": 0.5975962281227112,
      "learning_rate": 4.4090721619496125e-05,
      "loss": 1.2875,
      "step": 113800
    },
    {
      "epoch": 0.35483096831298677,
      "grad_norm": 0.5183025002479553,
      "learning_rate": 4.408812440848519e-05,
      "loss": 1.2596,
      "step": 113850
    },
    {
      "epoch": 0.3549868009736425,
      "grad_norm": 0.6294934153556824,
      "learning_rate": 4.408552719747427e-05,
      "loss": 1.2998,
      "step": 113900
    },
    {
      "epoch": 0.35514263363429815,
      "grad_norm": 0.5762377381324768,
      "learning_rate": 4.408292998646334e-05,
      "loss": 1.2751,
      "step": 113950
    },
    {
      "epoch": 0.3552984662949538,
      "grad_norm": 0.7035757303237915,
      "learning_rate": 4.408033277545241e-05,
      "loss": 1.3043,
      "step": 114000
    },
    {
      "epoch": 0.3554542989556095,
      "grad_norm": 0.6556268930435181,
      "learning_rate": 4.407773556444148e-05,
      "loss": 1.3201,
      "step": 114050
    },
    {
      "epoch": 0.3556101316162652,
      "grad_norm": 0.6323520541191101,
      "learning_rate": 4.407513835343055e-05,
      "loss": 1.2961,
      "step": 114100
    },
    {
      "epoch": 0.35576596427692087,
      "grad_norm": 0.6074135303497314,
      "learning_rate": 4.4072541142419626e-05,
      "loss": 1.3267,
      "step": 114150
    },
    {
      "epoch": 0.35592179693757653,
      "grad_norm": 0.5438929200172424,
      "learning_rate": 4.40699439314087e-05,
      "loss": 1.2719,
      "step": 114200
    },
    {
      "epoch": 0.35607762959823225,
      "grad_norm": 0.423168808221817,
      "learning_rate": 4.4067346720397764e-05,
      "loss": 1.2397,
      "step": 114250
    },
    {
      "epoch": 0.3562334622588879,
      "grad_norm": 0.6247608065605164,
      "learning_rate": 4.406474950938684e-05,
      "loss": 1.3051,
      "step": 114300
    },
    {
      "epoch": 0.3563892949195436,
      "grad_norm": 0.5785391330718994,
      "learning_rate": 4.4062152298375916e-05,
      "loss": 1.2429,
      "step": 114350
    },
    {
      "epoch": 0.3565451275801993,
      "grad_norm": 0.6005386710166931,
      "learning_rate": 4.405955508736498e-05,
      "loss": 1.3056,
      "step": 114400
    },
    {
      "epoch": 0.35670096024085496,
      "grad_norm": 0.6411465406417847,
      "learning_rate": 4.405695787635406e-05,
      "loss": 1.2481,
      "step": 114450
    },
    {
      "epoch": 0.3568567929015106,
      "grad_norm": 0.4334295392036438,
      "learning_rate": 4.405436066534313e-05,
      "loss": 1.2962,
      "step": 114500
    },
    {
      "epoch": 0.35701262556216634,
      "grad_norm": 0.6724950075149536,
      "learning_rate": 4.405181539855242e-05,
      "loss": 1.3091,
      "step": 114550
    },
    {
      "epoch": 0.357168458222822,
      "grad_norm": 0.6744892597198486,
      "learning_rate": 4.404921818754149e-05,
      "loss": 1.3141,
      "step": 114600
    },
    {
      "epoch": 0.35732429088347767,
      "grad_norm": 0.5155494809150696,
      "learning_rate": 4.4046620976530564e-05,
      "loss": 1.2876,
      "step": 114650
    },
    {
      "epoch": 0.3574801235441334,
      "grad_norm": 0.6542287468910217,
      "learning_rate": 4.4044023765519636e-05,
      "loss": 1.2803,
      "step": 114700
    },
    {
      "epoch": 0.35763595620478905,
      "grad_norm": 0.5757765769958496,
      "learning_rate": 4.404142655450871e-05,
      "loss": 1.3185,
      "step": 114750
    },
    {
      "epoch": 0.3577917888654447,
      "grad_norm": 0.5911329388618469,
      "learning_rate": 4.403882934349778e-05,
      "loss": 1.2467,
      "step": 114800
    },
    {
      "epoch": 0.35794762152610043,
      "grad_norm": 0.6156512498855591,
      "learning_rate": 4.4036232132486854e-05,
      "loss": 1.298,
      "step": 114850
    },
    {
      "epoch": 0.3581034541867561,
      "grad_norm": 0.5293723344802856,
      "learning_rate": 4.4033634921475926e-05,
      "loss": 1.2601,
      "step": 114900
    },
    {
      "epoch": 0.35825928684741176,
      "grad_norm": 0.699191689491272,
      "learning_rate": 4.403103771046499e-05,
      "loss": 1.2178,
      "step": 114950
    },
    {
      "epoch": 0.3584151195080675,
      "grad_norm": 0.6844967603683472,
      "learning_rate": 4.402844049945407e-05,
      "loss": 1.2727,
      "step": 115000
    },
    {
      "epoch": 0.35857095216872314,
      "grad_norm": 0.764631986618042,
      "learning_rate": 4.4025843288443144e-05,
      "loss": 1.2972,
      "step": 115050
    },
    {
      "epoch": 0.3587267848293788,
      "grad_norm": 0.5464830994606018,
      "learning_rate": 4.402324607743221e-05,
      "loss": 1.2373,
      "step": 115100
    },
    {
      "epoch": 0.35888261749003453,
      "grad_norm": 0.50187087059021,
      "learning_rate": 4.402064886642128e-05,
      "loss": 1.2393,
      "step": 115150
    },
    {
      "epoch": 0.3590384501506902,
      "grad_norm": 0.6361539959907532,
      "learning_rate": 4.401805165541036e-05,
      "loss": 1.3332,
      "step": 115200
    },
    {
      "epoch": 0.35919428281134586,
      "grad_norm": 0.5308080911636353,
      "learning_rate": 4.401545444439943e-05,
      "loss": 1.2696,
      "step": 115250
    },
    {
      "epoch": 0.3593501154720015,
      "grad_norm": 0.6689582467079163,
      "learning_rate": 4.40128572333885e-05,
      "loss": 1.3011,
      "step": 115300
    },
    {
      "epoch": 0.35950594813265724,
      "grad_norm": 0.67802494764328,
      "learning_rate": 4.401026002237757e-05,
      "loss": 1.3153,
      "step": 115350
    },
    {
      "epoch": 0.3596617807933129,
      "grad_norm": 0.6365830898284912,
      "learning_rate": 4.4007714755586864e-05,
      "loss": 1.2882,
      "step": 115400
    },
    {
      "epoch": 0.35981761345396857,
      "grad_norm": 0.65827876329422,
      "learning_rate": 4.400511754457594e-05,
      "loss": 1.2349,
      "step": 115450
    },
    {
      "epoch": 0.3599734461146243,
      "grad_norm": 0.5313448309898376,
      "learning_rate": 4.400252033356501e-05,
      "loss": 1.3228,
      "step": 115500
    },
    {
      "epoch": 0.36012927877527995,
      "grad_norm": 0.5937208533287048,
      "learning_rate": 4.3999923122554075e-05,
      "loss": 1.2749,
      "step": 115550
    },
    {
      "epoch": 0.3602851114359356,
      "grad_norm": 0.5786839723587036,
      "learning_rate": 4.3997325911543154e-05,
      "loss": 1.2365,
      "step": 115600
    },
    {
      "epoch": 0.36044094409659133,
      "grad_norm": 0.6488930583000183,
      "learning_rate": 4.399472870053222e-05,
      "loss": 1.3079,
      "step": 115650
    },
    {
      "epoch": 0.360596776757247,
      "grad_norm": 0.5983432531356812,
      "learning_rate": 4.399213148952129e-05,
      "loss": 1.3246,
      "step": 115700
    },
    {
      "epoch": 0.36075260941790266,
      "grad_norm": 0.6121058464050293,
      "learning_rate": 4.398953427851037e-05,
      "loss": 1.2505,
      "step": 115750
    },
    {
      "epoch": 0.3609084420785584,
      "grad_norm": 0.6189106702804565,
      "learning_rate": 4.398693706749944e-05,
      "loss": 1.3033,
      "step": 115800
    },
    {
      "epoch": 0.36106427473921404,
      "grad_norm": 0.6673219799995422,
      "learning_rate": 4.398433985648851e-05,
      "loss": 1.2568,
      "step": 115850
    },
    {
      "epoch": 0.3612201073998697,
      "grad_norm": 0.5182347297668457,
      "learning_rate": 4.398174264547758e-05,
      "loss": 1.2389,
      "step": 115900
    },
    {
      "epoch": 0.3613759400605254,
      "grad_norm": 0.7843739986419678,
      "learning_rate": 4.3979145434466655e-05,
      "loss": 1.3321,
      "step": 115950
    },
    {
      "epoch": 0.3615317727211811,
      "grad_norm": 0.5831396579742432,
      "learning_rate": 4.397654822345573e-05,
      "loss": 1.2879,
      "step": 116000
    },
    {
      "epoch": 0.36168760538183675,
      "grad_norm": 0.5571450591087341,
      "learning_rate": 4.39739510124448e-05,
      "loss": 1.2853,
      "step": 116050
    },
    {
      "epoch": 0.36184343804249247,
      "grad_norm": 0.7357829809188843,
      "learning_rate": 4.3971353801433866e-05,
      "loss": 1.2971,
      "step": 116100
    },
    {
      "epoch": 0.36199927070314813,
      "grad_norm": 0.44693219661712646,
      "learning_rate": 4.3968756590422945e-05,
      "loss": 1.2967,
      "step": 116150
    },
    {
      "epoch": 0.3621551033638038,
      "grad_norm": 0.5813679695129395,
      "learning_rate": 4.396615937941202e-05,
      "loss": 1.2139,
      "step": 116200
    },
    {
      "epoch": 0.3623109360244595,
      "grad_norm": 0.5317560434341431,
      "learning_rate": 4.396356216840108e-05,
      "loss": 1.3167,
      "step": 116250
    },
    {
      "epoch": 0.3624667686851152,
      "grad_norm": 0.6249122023582458,
      "learning_rate": 4.396096495739016e-05,
      "loss": 1.3457,
      "step": 116300
    },
    {
      "epoch": 0.36262260134577085,
      "grad_norm": 0.5121575593948364,
      "learning_rate": 4.395836774637923e-05,
      "loss": 1.3054,
      "step": 116350
    },
    {
      "epoch": 0.36277843400642656,
      "grad_norm": 0.6252250671386719,
      "learning_rate": 4.39557705353683e-05,
      "loss": 1.3278,
      "step": 116400
    },
    {
      "epoch": 0.36293426666708223,
      "grad_norm": 0.6190205216407776,
      "learning_rate": 4.395317332435737e-05,
      "loss": 1.2616,
      "step": 116450
    },
    {
      "epoch": 0.3630900993277379,
      "grad_norm": 0.5679930448532104,
      "learning_rate": 4.3950576113346446e-05,
      "loss": 1.2486,
      "step": 116500
    },
    {
      "epoch": 0.3632459319883936,
      "grad_norm": 0.7865418791770935,
      "learning_rate": 4.394797890233552e-05,
      "loss": 1.3073,
      "step": 116550
    },
    {
      "epoch": 0.3634017646490493,
      "grad_norm": 0.46468332409858704,
      "learning_rate": 4.394538169132459e-05,
      "loss": 1.2504,
      "step": 116600
    },
    {
      "epoch": 0.36355759730970494,
      "grad_norm": 0.5523152947425842,
      "learning_rate": 4.394278448031366e-05,
      "loss": 1.2891,
      "step": 116650
    },
    {
      "epoch": 0.3637134299703606,
      "grad_norm": 0.59577476978302,
      "learning_rate": 4.3940187269302736e-05,
      "loss": 1.2792,
      "step": 116700
    },
    {
      "epoch": 0.3638692626310163,
      "grad_norm": 0.6008528470993042,
      "learning_rate": 4.393759005829181e-05,
      "loss": 1.2992,
      "step": 116750
    },
    {
      "epoch": 0.364025095291672,
      "grad_norm": 0.5829377174377441,
      "learning_rate": 4.3934992847280874e-05,
      "loss": 1.2305,
      "step": 116800
    },
    {
      "epoch": 0.36418092795232765,
      "grad_norm": 0.59236741065979,
      "learning_rate": 4.393239563626995e-05,
      "loss": 1.2892,
      "step": 116850
    },
    {
      "epoch": 0.36433676061298337,
      "grad_norm": 0.7544500231742859,
      "learning_rate": 4.392979842525902e-05,
      "loss": 1.2666,
      "step": 116900
    },
    {
      "epoch": 0.36449259327363903,
      "grad_norm": 0.5955289602279663,
      "learning_rate": 4.392720121424809e-05,
      "loss": 1.2959,
      "step": 116950
    },
    {
      "epoch": 0.3646484259342947,
      "grad_norm": 0.5219318270683289,
      "learning_rate": 4.392460400323717e-05,
      "loss": 1.3584,
      "step": 117000
    },
    {
      "epoch": 0.3648042585949504,
      "grad_norm": 0.5848274230957031,
      "learning_rate": 4.3922006792226236e-05,
      "loss": 1.2931,
      "step": 117050
    },
    {
      "epoch": 0.3649600912556061,
      "grad_norm": 0.6389688849449158,
      "learning_rate": 4.391940958121531e-05,
      "loss": 1.2538,
      "step": 117100
    },
    {
      "epoch": 0.36511592391626174,
      "grad_norm": 0.6174463629722595,
      "learning_rate": 4.391681237020438e-05,
      "loss": 1.2445,
      "step": 117150
    },
    {
      "epoch": 0.36527175657691746,
      "grad_norm": 0.5809708833694458,
      "learning_rate": 4.3914215159193454e-05,
      "loss": 1.3051,
      "step": 117200
    },
    {
      "epoch": 0.3654275892375731,
      "grad_norm": 0.8223596811294556,
      "learning_rate": 4.3911617948182526e-05,
      "loss": 1.2596,
      "step": 117250
    },
    {
      "epoch": 0.3655834218982288,
      "grad_norm": 0.5254910588264465,
      "learning_rate": 4.39090207371716e-05,
      "loss": 1.2738,
      "step": 117300
    },
    {
      "epoch": 0.3657392545588845,
      "grad_norm": 0.7088721990585327,
      "learning_rate": 4.3906423526160665e-05,
      "loss": 1.2859,
      "step": 117350
    },
    {
      "epoch": 0.36589508721954017,
      "grad_norm": 0.5446974039077759,
      "learning_rate": 4.3903826315149744e-05,
      "loss": 1.3155,
      "step": 117400
    },
    {
      "epoch": 0.36605091988019584,
      "grad_norm": 0.571243166923523,
      "learning_rate": 4.3901281048359036e-05,
      "loss": 1.2503,
      "step": 117450
    },
    {
      "epoch": 0.36620675254085155,
      "grad_norm": 0.5430217981338501,
      "learning_rate": 4.38986838373481e-05,
      "loss": 1.2969,
      "step": 117500
    },
    {
      "epoch": 0.3663625852015072,
      "grad_norm": 0.5630930066108704,
      "learning_rate": 4.3896086626337174e-05,
      "loss": 1.2466,
      "step": 117550
    },
    {
      "epoch": 0.3665184178621629,
      "grad_norm": 0.5513562560081482,
      "learning_rate": 4.389348941532625e-05,
      "loss": 1.2718,
      "step": 117600
    },
    {
      "epoch": 0.3666742505228186,
      "grad_norm": 0.8082510828971863,
      "learning_rate": 4.389089220431532e-05,
      "loss": 1.2632,
      "step": 117650
    },
    {
      "epoch": 0.36683008318347426,
      "grad_norm": 0.6579007506370544,
      "learning_rate": 4.388829499330439e-05,
      "loss": 1.2778,
      "step": 117700
    },
    {
      "epoch": 0.36698591584412993,
      "grad_norm": 0.6802477836608887,
      "learning_rate": 4.3885697782293464e-05,
      "loss": 1.29,
      "step": 117750
    },
    {
      "epoch": 0.36714174850478565,
      "grad_norm": 0.6946637630462646,
      "learning_rate": 4.388310057128254e-05,
      "loss": 1.3303,
      "step": 117800
    },
    {
      "epoch": 0.3672975811654413,
      "grad_norm": 0.6903021931648254,
      "learning_rate": 4.388050336027161e-05,
      "loss": 1.3082,
      "step": 117850
    },
    {
      "epoch": 0.367453413826097,
      "grad_norm": 0.6730428338050842,
      "learning_rate": 4.3877906149260675e-05,
      "loss": 1.313,
      "step": 117900
    },
    {
      "epoch": 0.36760924648675264,
      "grad_norm": 0.6205770969390869,
      "learning_rate": 4.3875308938249754e-05,
      "loss": 1.2444,
      "step": 117950
    },
    {
      "epoch": 0.36776507914740836,
      "grad_norm": 0.6700164675712585,
      "learning_rate": 4.387271172723883e-05,
      "loss": 1.3525,
      "step": 118000
    },
    {
      "epoch": 0.367920911808064,
      "grad_norm": 0.6803284883499146,
      "learning_rate": 4.387011451622789e-05,
      "loss": 1.2999,
      "step": 118050
    },
    {
      "epoch": 0.3680767444687197,
      "grad_norm": 0.5600902438163757,
      "learning_rate": 4.3867517305216965e-05,
      "loss": 1.3239,
      "step": 118100
    },
    {
      "epoch": 0.3682325771293754,
      "grad_norm": 0.6041138768196106,
      "learning_rate": 4.3864920094206044e-05,
      "loss": 1.322,
      "step": 118150
    },
    {
      "epoch": 0.36838840979003107,
      "grad_norm": 0.49200376868247986,
      "learning_rate": 4.386232288319511e-05,
      "loss": 1.2495,
      "step": 118200
    },
    {
      "epoch": 0.36854424245068673,
      "grad_norm": 0.5960775017738342,
      "learning_rate": 4.385972567218418e-05,
      "loss": 1.2862,
      "step": 118250
    },
    {
      "epoch": 0.36870007511134245,
      "grad_norm": 0.6338363885879517,
      "learning_rate": 4.3857128461173255e-05,
      "loss": 1.2697,
      "step": 118300
    },
    {
      "epoch": 0.3688559077719981,
      "grad_norm": 0.6461572647094727,
      "learning_rate": 4.385453125016233e-05,
      "loss": 1.2748,
      "step": 118350
    },
    {
      "epoch": 0.3690117404326538,
      "grad_norm": 0.6654154062271118,
      "learning_rate": 4.38519340391514e-05,
      "loss": 1.2605,
      "step": 118400
    },
    {
      "epoch": 0.3691675730933095,
      "grad_norm": 0.6971449255943298,
      "learning_rate": 4.384933682814047e-05,
      "loss": 1.2647,
      "step": 118450
    },
    {
      "epoch": 0.36932340575396516,
      "grad_norm": 0.5397875308990479,
      "learning_rate": 4.3846739617129545e-05,
      "loss": 1.3016,
      "step": 118500
    },
    {
      "epoch": 0.3694792384146208,
      "grad_norm": 0.709551990032196,
      "learning_rate": 4.384414240611862e-05,
      "loss": 1.2931,
      "step": 118550
    },
    {
      "epoch": 0.36963507107527654,
      "grad_norm": 0.6097021102905273,
      "learning_rate": 4.384154519510768e-05,
      "loss": 1.2859,
      "step": 118600
    },
    {
      "epoch": 0.3697909037359322,
      "grad_norm": 0.7476877570152283,
      "learning_rate": 4.383894798409676e-05,
      "loss": 1.3617,
      "step": 118650
    },
    {
      "epoch": 0.36994673639658787,
      "grad_norm": 0.7178996205329895,
      "learning_rate": 4.3836350773085835e-05,
      "loss": 1.2421,
      "step": 118700
    },
    {
      "epoch": 0.3701025690572436,
      "grad_norm": 0.5718066096305847,
      "learning_rate": 4.38337535620749e-05,
      "loss": 1.2598,
      "step": 118750
    },
    {
      "epoch": 0.37025840171789925,
      "grad_norm": 0.5451909303665161,
      "learning_rate": 4.383115635106397e-05,
      "loss": 1.3029,
      "step": 118800
    },
    {
      "epoch": 0.3704142343785549,
      "grad_norm": 0.7210837602615356,
      "learning_rate": 4.382855914005305e-05,
      "loss": 1.2791,
      "step": 118850
    },
    {
      "epoch": 0.37057006703921064,
      "grad_norm": 0.6100269556045532,
      "learning_rate": 4.382596192904212e-05,
      "loss": 1.2856,
      "step": 118900
    },
    {
      "epoch": 0.3707258996998663,
      "grad_norm": 0.6027399301528931,
      "learning_rate": 4.382336471803119e-05,
      "loss": 1.2685,
      "step": 118950
    },
    {
      "epoch": 0.37088173236052197,
      "grad_norm": 0.6255103349685669,
      "learning_rate": 4.382076750702026e-05,
      "loss": 1.2985,
      "step": 119000
    },
    {
      "epoch": 0.3710375650211777,
      "grad_norm": 0.7824333906173706,
      "learning_rate": 4.3818170296009336e-05,
      "loss": 1.2859,
      "step": 119050
    },
    {
      "epoch": 0.37119339768183335,
      "grad_norm": 0.4481971561908722,
      "learning_rate": 4.381557308499841e-05,
      "loss": 1.2716,
      "step": 119100
    },
    {
      "epoch": 0.371349230342489,
      "grad_norm": 0.6017318367958069,
      "learning_rate": 4.3812975873987474e-05,
      "loss": 1.256,
      "step": 119150
    },
    {
      "epoch": 0.3715050630031447,
      "grad_norm": 0.5693778395652771,
      "learning_rate": 4.381037866297655e-05,
      "loss": 1.2728,
      "step": 119200
    },
    {
      "epoch": 0.3716608956638004,
      "grad_norm": 0.5932562351226807,
      "learning_rate": 4.3807781451965626e-05,
      "loss": 1.2561,
      "step": 119250
    },
    {
      "epoch": 0.37181672832445606,
      "grad_norm": 0.6757050156593323,
      "learning_rate": 4.380518424095469e-05,
      "loss": 1.2668,
      "step": 119300
    },
    {
      "epoch": 0.3719725609851117,
      "grad_norm": 0.5207232236862183,
      "learning_rate": 4.3802587029943764e-05,
      "loss": 1.3334,
      "step": 119350
    },
    {
      "epoch": 0.37212839364576744,
      "grad_norm": 0.6031019687652588,
      "learning_rate": 4.379998981893284e-05,
      "loss": 1.2379,
      "step": 119400
    },
    {
      "epoch": 0.3722842263064231,
      "grad_norm": 0.7011832594871521,
      "learning_rate": 4.379739260792191e-05,
      "loss": 1.3509,
      "step": 119450
    },
    {
      "epoch": 0.37244005896707877,
      "grad_norm": 0.6817960739135742,
      "learning_rate": 4.379479539691098e-05,
      "loss": 1.2877,
      "step": 119500
    },
    {
      "epoch": 0.3725958916277345,
      "grad_norm": 0.6280450820922852,
      "learning_rate": 4.3792198185900054e-05,
      "loss": 1.2846,
      "step": 119550
    },
    {
      "epoch": 0.37275172428839015,
      "grad_norm": 0.5418813824653625,
      "learning_rate": 4.3789600974889127e-05,
      "loss": 1.2891,
      "step": 119600
    },
    {
      "epoch": 0.3729075569490458,
      "grad_norm": 0.462857186794281,
      "learning_rate": 4.37870037638782e-05,
      "loss": 1.1889,
      "step": 119650
    },
    {
      "epoch": 0.37306338960970153,
      "grad_norm": 0.6069427728652954,
      "learning_rate": 4.378440655286727e-05,
      "loss": 1.3183,
      "step": 119700
    },
    {
      "epoch": 0.3732192222703572,
      "grad_norm": 0.6910990476608276,
      "learning_rate": 4.3781809341856344e-05,
      "loss": 1.3115,
      "step": 119750
    },
    {
      "epoch": 0.37337505493101286,
      "grad_norm": 0.6270799040794373,
      "learning_rate": 4.3779212130845417e-05,
      "loss": 1.2456,
      "step": 119800
    },
    {
      "epoch": 0.3735308875916686,
      "grad_norm": 0.5795145630836487,
      "learning_rate": 4.377661491983448e-05,
      "loss": 1.2792,
      "step": 119850
    },
    {
      "epoch": 0.37368672025232424,
      "grad_norm": 0.6099186539649963,
      "learning_rate": 4.3774069653043774e-05,
      "loss": 1.2857,
      "step": 119900
    },
    {
      "epoch": 0.3738425529129799,
      "grad_norm": 0.5823861360549927,
      "learning_rate": 4.3771472442032854e-05,
      "loss": 1.2725,
      "step": 119950
    },
    {
      "epoch": 0.3739983855736356,
      "grad_norm": 0.504576563835144,
      "learning_rate": 4.376887523102192e-05,
      "loss": 1.2349,
      "step": 120000
    },
    {
      "epoch": 0.3741542182342913,
      "grad_norm": 0.645169734954834,
      "learning_rate": 4.376627802001099e-05,
      "loss": 1.2657,
      "step": 120050
    },
    {
      "epoch": 0.37431005089494696,
      "grad_norm": 0.5409004092216492,
      "learning_rate": 4.3763680809000064e-05,
      "loss": 1.2849,
      "step": 120100
    },
    {
      "epoch": 0.3744658835556027,
      "grad_norm": 0.5702266693115234,
      "learning_rate": 4.376108359798914e-05,
      "loss": 1.2901,
      "step": 120150
    },
    {
      "epoch": 0.37462171621625834,
      "grad_norm": 0.5280563235282898,
      "learning_rate": 4.375848638697821e-05,
      "loss": 1.3132,
      "step": 120200
    },
    {
      "epoch": 0.374777548876914,
      "grad_norm": 0.4211035966873169,
      "learning_rate": 4.375588917596728e-05,
      "loss": 1.2902,
      "step": 120250
    },
    {
      "epoch": 0.3749333815375697,
      "grad_norm": 0.6293310523033142,
      "learning_rate": 4.3753291964956354e-05,
      "loss": 1.2612,
      "step": 120300
    },
    {
      "epoch": 0.3750892141982254,
      "grad_norm": 0.6913221478462219,
      "learning_rate": 4.375069475394543e-05,
      "loss": 1.2268,
      "step": 120350
    },
    {
      "epoch": 0.37524504685888105,
      "grad_norm": 0.5070938467979431,
      "learning_rate": 4.37480975429345e-05,
      "loss": 1.3402,
      "step": 120400
    },
    {
      "epoch": 0.37540087951953677,
      "grad_norm": 0.6621866822242737,
      "learning_rate": 4.3745500331923565e-05,
      "loss": 1.2531,
      "step": 120450
    },
    {
      "epoch": 0.37555671218019243,
      "grad_norm": 0.6405518054962158,
      "learning_rate": 4.3742903120912645e-05,
      "loss": 1.2344,
      "step": 120500
    },
    {
      "epoch": 0.3757125448408481,
      "grad_norm": 0.7759639620780945,
      "learning_rate": 4.374030590990171e-05,
      "loss": 1.3141,
      "step": 120550
    },
    {
      "epoch": 0.37586837750150376,
      "grad_norm": 0.4949381351470947,
      "learning_rate": 4.373770869889078e-05,
      "loss": 1.2648,
      "step": 120600
    },
    {
      "epoch": 0.3760242101621595,
      "grad_norm": 0.47031596302986145,
      "learning_rate": 4.373511148787986e-05,
      "loss": 1.3091,
      "step": 120650
    },
    {
      "epoch": 0.37618004282281514,
      "grad_norm": 0.5327876210212708,
      "learning_rate": 4.373251427686893e-05,
      "loss": 1.2798,
      "step": 120700
    },
    {
      "epoch": 0.3763358754834708,
      "grad_norm": 0.6559816002845764,
      "learning_rate": 4.3729917065858e-05,
      "loss": 1.2542,
      "step": 120750
    },
    {
      "epoch": 0.3764917081441265,
      "grad_norm": 0.5198267102241516,
      "learning_rate": 4.372731985484707e-05,
      "loss": 1.2824,
      "step": 120800
    },
    {
      "epoch": 0.3766475408047822,
      "grad_norm": 0.6602588891983032,
      "learning_rate": 4.3724722643836145e-05,
      "loss": 1.2758,
      "step": 120850
    },
    {
      "epoch": 0.37680337346543785,
      "grad_norm": 0.5450400114059448,
      "learning_rate": 4.372212543282522e-05,
      "loss": 1.2859,
      "step": 120900
    },
    {
      "epoch": 0.37695920612609357,
      "grad_norm": 0.5342373251914978,
      "learning_rate": 4.371952822181429e-05,
      "loss": 1.2868,
      "step": 120950
    },
    {
      "epoch": 0.37711503878674923,
      "grad_norm": 0.6614928245544434,
      "learning_rate": 4.371693101080336e-05,
      "loss": 1.2649,
      "step": 121000
    },
    {
      "epoch": 0.3772708714474049,
      "grad_norm": 0.5100746154785156,
      "learning_rate": 4.3714333799792435e-05,
      "loss": 1.2805,
      "step": 121050
    },
    {
      "epoch": 0.3774267041080606,
      "grad_norm": 0.5720688104629517,
      "learning_rate": 4.371173658878151e-05,
      "loss": 1.2308,
      "step": 121100
    },
    {
      "epoch": 0.3775825367687163,
      "grad_norm": 0.5470685362815857,
      "learning_rate": 4.3709139377770573e-05,
      "loss": 1.2537,
      "step": 121150
    },
    {
      "epoch": 0.37773836942937195,
      "grad_norm": 0.6411160230636597,
      "learning_rate": 4.370654216675965e-05,
      "loss": 1.3036,
      "step": 121200
    },
    {
      "epoch": 0.37789420209002766,
      "grad_norm": 0.5407906770706177,
      "learning_rate": 4.370394495574872e-05,
      "loss": 1.261,
      "step": 121250
    },
    {
      "epoch": 0.37805003475068333,
      "grad_norm": 0.5207412838935852,
      "learning_rate": 4.370134774473779e-05,
      "loss": 1.2299,
      "step": 121300
    },
    {
      "epoch": 0.378205867411339,
      "grad_norm": 0.6496469974517822,
      "learning_rate": 4.3698750533726864e-05,
      "loss": 1.272,
      "step": 121350
    },
    {
      "epoch": 0.3783617000719947,
      "grad_norm": 0.6811959147453308,
      "learning_rate": 4.3696153322715936e-05,
      "loss": 1.2595,
      "step": 121400
    },
    {
      "epoch": 0.3785175327326504,
      "grad_norm": 0.5937258005142212,
      "learning_rate": 4.369355611170501e-05,
      "loss": 1.2702,
      "step": 121450
    },
    {
      "epoch": 0.37867336539330604,
      "grad_norm": 0.4660084843635559,
      "learning_rate": 4.369095890069408e-05,
      "loss": 1.2896,
      "step": 121500
    },
    {
      "epoch": 0.37882919805396176,
      "grad_norm": 0.5648842453956604,
      "learning_rate": 4.3688361689683154e-05,
      "loss": 1.2611,
      "step": 121550
    },
    {
      "epoch": 0.3789850307146174,
      "grad_norm": 0.6689195036888123,
      "learning_rate": 4.3685764478672226e-05,
      "loss": 1.2529,
      "step": 121600
    },
    {
      "epoch": 0.3791408633752731,
      "grad_norm": 0.5344876050949097,
      "learning_rate": 4.36831672676613e-05,
      "loss": 1.313,
      "step": 121650
    },
    {
      "epoch": 0.3792966960359288,
      "grad_norm": 0.7079824209213257,
      "learning_rate": 4.3680570056650364e-05,
      "loss": 1.2696,
      "step": 121700
    },
    {
      "epoch": 0.37945252869658447,
      "grad_norm": 0.5679979920387268,
      "learning_rate": 4.3677972845639444e-05,
      "loss": 1.2678,
      "step": 121750
    },
    {
      "epoch": 0.37960836135724013,
      "grad_norm": 0.6870812177658081,
      "learning_rate": 4.367537563462851e-05,
      "loss": 1.3231,
      "step": 121800
    },
    {
      "epoch": 0.3797641940178958,
      "grad_norm": 0.6326819658279419,
      "learning_rate": 4.367277842361758e-05,
      "loss": 1.2067,
      "step": 121850
    },
    {
      "epoch": 0.3799200266785515,
      "grad_norm": 0.45683977007865906,
      "learning_rate": 4.367018121260666e-05,
      "loss": 1.2116,
      "step": 121900
    },
    {
      "epoch": 0.3800758593392072,
      "grad_norm": 0.5688557624816895,
      "learning_rate": 4.3667635945815946e-05,
      "loss": 1.2957,
      "step": 121950
    },
    {
      "epoch": 0.38023169199986284,
      "grad_norm": 0.48968246579170227,
      "learning_rate": 4.366503873480502e-05,
      "loss": 1.2996,
      "step": 122000
    },
    {
      "epoch": 0.38038752466051856,
      "grad_norm": 0.511894166469574,
      "learning_rate": 4.366244152379409e-05,
      "loss": 1.31,
      "step": 122050
    },
    {
      "epoch": 0.3805433573211742,
      "grad_norm": 0.4698556363582611,
      "learning_rate": 4.3659844312783164e-05,
      "loss": 1.2612,
      "step": 122100
    },
    {
      "epoch": 0.3806991899818299,
      "grad_norm": 0.6599114537239075,
      "learning_rate": 4.3657247101772236e-05,
      "loss": 1.2702,
      "step": 122150
    },
    {
      "epoch": 0.3808550226424856,
      "grad_norm": 0.7010509371757507,
      "learning_rate": 4.365464989076131e-05,
      "loss": 1.2794,
      "step": 122200
    },
    {
      "epoch": 0.38101085530314127,
      "grad_norm": 0.641582727432251,
      "learning_rate": 4.3652052679750375e-05,
      "loss": 1.3252,
      "step": 122250
    },
    {
      "epoch": 0.38116668796379694,
      "grad_norm": 0.5522006750106812,
      "learning_rate": 4.3649455468739454e-05,
      "loss": 1.2317,
      "step": 122300
    },
    {
      "epoch": 0.38132252062445265,
      "grad_norm": 0.601041853427887,
      "learning_rate": 4.3646858257728526e-05,
      "loss": 1.3068,
      "step": 122350
    },
    {
      "epoch": 0.3814783532851083,
      "grad_norm": 0.5748610496520996,
      "learning_rate": 4.364426104671759e-05,
      "loss": 1.2917,
      "step": 122400
    },
    {
      "epoch": 0.381634185945764,
      "grad_norm": 0.6394314169883728,
      "learning_rate": 4.3641663835706665e-05,
      "loss": 1.238,
      "step": 122450
    },
    {
      "epoch": 0.3817900186064197,
      "grad_norm": 0.5869917273521423,
      "learning_rate": 4.363906662469574e-05,
      "loss": 1.3058,
      "step": 122500
    },
    {
      "epoch": 0.38194585126707536,
      "grad_norm": 0.5693693161010742,
      "learning_rate": 4.363646941368481e-05,
      "loss": 1.2702,
      "step": 122550
    },
    {
      "epoch": 0.38210168392773103,
      "grad_norm": 0.6299892067909241,
      "learning_rate": 4.363387220267388e-05,
      "loss": 1.2833,
      "step": 122600
    },
    {
      "epoch": 0.38225751658838675,
      "grad_norm": 0.6243429780006409,
      "learning_rate": 4.3631274991662955e-05,
      "loss": 1.2625,
      "step": 122650
    },
    {
      "epoch": 0.3824133492490424,
      "grad_norm": 0.6028339862823486,
      "learning_rate": 4.362867778065203e-05,
      "loss": 1.2728,
      "step": 122700
    },
    {
      "epoch": 0.3825691819096981,
      "grad_norm": 0.5650950074195862,
      "learning_rate": 4.36260805696411e-05,
      "loss": 1.2695,
      "step": 122750
    },
    {
      "epoch": 0.3827250145703538,
      "grad_norm": 0.651763916015625,
      "learning_rate": 4.3623483358630165e-05,
      "loss": 1.2863,
      "step": 122800
    },
    {
      "epoch": 0.38288084723100946,
      "grad_norm": 0.552039384841919,
      "learning_rate": 4.3620886147619245e-05,
      "loss": 1.2844,
      "step": 122850
    },
    {
      "epoch": 0.3830366798916651,
      "grad_norm": 0.5265936255455017,
      "learning_rate": 4.361828893660832e-05,
      "loss": 1.2439,
      "step": 122900
    },
    {
      "epoch": 0.38319251255232084,
      "grad_norm": 0.5958473682403564,
      "learning_rate": 4.36157436698176e-05,
      "loss": 1.3185,
      "step": 122950
    },
    {
      "epoch": 0.3833483452129765,
      "grad_norm": 0.5359919667243958,
      "learning_rate": 4.3613146458806675e-05,
      "loss": 1.2895,
      "step": 123000
    },
    {
      "epoch": 0.38350417787363217,
      "grad_norm": 0.6377437710762024,
      "learning_rate": 4.3610549247795754e-05,
      "loss": 1.2732,
      "step": 123050
    },
    {
      "epoch": 0.3836600105342879,
      "grad_norm": 0.48535341024398804,
      "learning_rate": 4.360795203678482e-05,
      "loss": 1.2983,
      "step": 123100
    },
    {
      "epoch": 0.38381584319494355,
      "grad_norm": 0.7187165021896362,
      "learning_rate": 4.360535482577389e-05,
      "loss": 1.2741,
      "step": 123150
    },
    {
      "epoch": 0.3839716758555992,
      "grad_norm": 0.5630184412002563,
      "learning_rate": 4.3602757614762965e-05,
      "loss": 1.2574,
      "step": 123200
    },
    {
      "epoch": 0.3841275085162549,
      "grad_norm": 0.5991930961608887,
      "learning_rate": 4.360016040375204e-05,
      "loss": 1.2987,
      "step": 123250
    },
    {
      "epoch": 0.3842833411769106,
      "grad_norm": 0.6155419945716858,
      "learning_rate": 4.359756319274111e-05,
      "loss": 1.3012,
      "step": 123300
    },
    {
      "epoch": 0.38443917383756626,
      "grad_norm": 0.7111846804618835,
      "learning_rate": 4.359496598173018e-05,
      "loss": 1.3139,
      "step": 123350
    },
    {
      "epoch": 0.3845950064982219,
      "grad_norm": 0.6607616543769836,
      "learning_rate": 4.3592368770719255e-05,
      "loss": 1.2951,
      "step": 123400
    },
    {
      "epoch": 0.38475083915887764,
      "grad_norm": 0.5766223073005676,
      "learning_rate": 4.358977155970833e-05,
      "loss": 1.2826,
      "step": 123450
    },
    {
      "epoch": 0.3849066718195333,
      "grad_norm": 0.5902954936027527,
      "learning_rate": 4.358717434869739e-05,
      "loss": 1.3098,
      "step": 123500
    },
    {
      "epoch": 0.38506250448018897,
      "grad_norm": 0.5763415098190308,
      "learning_rate": 4.3584577137686466e-05,
      "loss": 1.2411,
      "step": 123550
    },
    {
      "epoch": 0.3852183371408447,
      "grad_norm": 0.4495627284049988,
      "learning_rate": 4.3581979926675545e-05,
      "loss": 1.2582,
      "step": 123600
    },
    {
      "epoch": 0.38537416980150035,
      "grad_norm": 0.6439781785011292,
      "learning_rate": 4.357938271566461e-05,
      "loss": 1.3202,
      "step": 123650
    },
    {
      "epoch": 0.385530002462156,
      "grad_norm": 0.6535604596138,
      "learning_rate": 4.357678550465368e-05,
      "loss": 1.3086,
      "step": 123700
    },
    {
      "epoch": 0.38568583512281174,
      "grad_norm": 0.71649169921875,
      "learning_rate": 4.357418829364276e-05,
      "loss": 1.2548,
      "step": 123750
    },
    {
      "epoch": 0.3858416677834674,
      "grad_norm": 0.41576188802719116,
      "learning_rate": 4.357159108263183e-05,
      "loss": 1.2808,
      "step": 123800
    },
    {
      "epoch": 0.38599750044412307,
      "grad_norm": 0.6413590908050537,
      "learning_rate": 4.35689938716209e-05,
      "loss": 1.3353,
      "step": 123850
    },
    {
      "epoch": 0.3861533331047788,
      "grad_norm": 0.5919172763824463,
      "learning_rate": 4.356639666060997e-05,
      "loss": 1.3043,
      "step": 123900
    },
    {
      "epoch": 0.38630916576543445,
      "grad_norm": 0.5729137063026428,
      "learning_rate": 4.3563799449599046e-05,
      "loss": 1.308,
      "step": 123950
    },
    {
      "epoch": 0.3864649984260901,
      "grad_norm": 0.6264764070510864,
      "learning_rate": 4.356120223858812e-05,
      "loss": 1.2463,
      "step": 124000
    },
    {
      "epoch": 0.38662083108674583,
      "grad_norm": 0.6139302849769592,
      "learning_rate": 4.3558605027577184e-05,
      "loss": 1.294,
      "step": 124050
    },
    {
      "epoch": 0.3867766637474015,
      "grad_norm": 0.5994769334793091,
      "learning_rate": 4.355600781656626e-05,
      "loss": 1.2779,
      "step": 124100
    },
    {
      "epoch": 0.38693249640805716,
      "grad_norm": 0.5168734192848206,
      "learning_rate": 4.3553410605555336e-05,
      "loss": 1.3054,
      "step": 124150
    },
    {
      "epoch": 0.3870883290687129,
      "grad_norm": 0.6389521360397339,
      "learning_rate": 4.35508133945444e-05,
      "loss": 1.3314,
      "step": 124200
    },
    {
      "epoch": 0.38724416172936854,
      "grad_norm": 0.6100038290023804,
      "learning_rate": 4.3548216183533474e-05,
      "loss": 1.3021,
      "step": 124250
    },
    {
      "epoch": 0.3873999943900242,
      "grad_norm": 0.6581131219863892,
      "learning_rate": 4.354561897252255e-05,
      "loss": 1.2684,
      "step": 124300
    },
    {
      "epoch": 0.3875558270506799,
      "grad_norm": 0.6291976571083069,
      "learning_rate": 4.354302176151162e-05,
      "loss": 1.2919,
      "step": 124350
    },
    {
      "epoch": 0.3877116597113356,
      "grad_norm": 0.6946045756340027,
      "learning_rate": 4.354042455050069e-05,
      "loss": 1.2547,
      "step": 124400
    },
    {
      "epoch": 0.38786749237199125,
      "grad_norm": 0.5476803183555603,
      "learning_rate": 4.3537827339489764e-05,
      "loss": 1.2642,
      "step": 124450
    },
    {
      "epoch": 0.3880233250326469,
      "grad_norm": 0.7108947038650513,
      "learning_rate": 4.3535230128478837e-05,
      "loss": 1.2897,
      "step": 124500
    },
    {
      "epoch": 0.38817915769330263,
      "grad_norm": 0.7129521369934082,
      "learning_rate": 4.353263291746791e-05,
      "loss": 1.2608,
      "step": 124550
    },
    {
      "epoch": 0.3883349903539583,
      "grad_norm": 0.7266551852226257,
      "learning_rate": 4.353003570645698e-05,
      "loss": 1.2907,
      "step": 124600
    },
    {
      "epoch": 0.38849082301461396,
      "grad_norm": 0.43176567554473877,
      "learning_rate": 4.3527438495446054e-05,
      "loss": 1.3234,
      "step": 124650
    },
    {
      "epoch": 0.3886466556752697,
      "grad_norm": 0.6235330104827881,
      "learning_rate": 4.3524841284435127e-05,
      "loss": 1.2725,
      "step": 124700
    },
    {
      "epoch": 0.38880248833592534,
      "grad_norm": 0.6986300349235535,
      "learning_rate": 4.352224407342419e-05,
      "loss": 1.3004,
      "step": 124750
    },
    {
      "epoch": 0.388958320996581,
      "grad_norm": 0.7112565040588379,
      "learning_rate": 4.3519646862413265e-05,
      "loss": 1.3098,
      "step": 124800
    },
    {
      "epoch": 0.3891141536572367,
      "grad_norm": 0.7244734764099121,
      "learning_rate": 4.3517049651402344e-05,
      "loss": 1.2737,
      "step": 124850
    },
    {
      "epoch": 0.3892699863178924,
      "grad_norm": 0.5485036969184875,
      "learning_rate": 4.351445244039141e-05,
      "loss": 1.2872,
      "step": 124900
    },
    {
      "epoch": 0.38942581897854806,
      "grad_norm": 0.5238649845123291,
      "learning_rate": 4.351185522938048e-05,
      "loss": 1.2984,
      "step": 124950
    },
    {
      "epoch": 0.3895816516392038,
      "grad_norm": 0.6725048422813416,
      "learning_rate": 4.350925801836956e-05,
      "loss": 1.2756,
      "step": 125000
    },
    {
      "epoch": 0.38973748429985944,
      "grad_norm": 0.5167462825775146,
      "learning_rate": 4.350666080735863e-05,
      "loss": 1.262,
      "step": 125050
    },
    {
      "epoch": 0.3898933169605151,
      "grad_norm": 0.6059038639068604,
      "learning_rate": 4.350411554056792e-05,
      "loss": 1.2494,
      "step": 125100
    },
    {
      "epoch": 0.3900491496211708,
      "grad_norm": 0.5923278331756592,
      "learning_rate": 4.350151832955699e-05,
      "loss": 1.294,
      "step": 125150
    },
    {
      "epoch": 0.3902049822818265,
      "grad_norm": 0.6561193466186523,
      "learning_rate": 4.349892111854606e-05,
      "loss": 1.2711,
      "step": 125200
    },
    {
      "epoch": 0.39036081494248215,
      "grad_norm": 0.5371524691581726,
      "learning_rate": 4.349632390753514e-05,
      "loss": 1.2718,
      "step": 125250
    },
    {
      "epoch": 0.39051664760313787,
      "grad_norm": 0.588132381439209,
      "learning_rate": 4.349372669652421e-05,
      "loss": 1.2832,
      "step": 125300
    },
    {
      "epoch": 0.39067248026379353,
      "grad_norm": 0.5634927749633789,
      "learning_rate": 4.3491129485513275e-05,
      "loss": 1.3055,
      "step": 125350
    },
    {
      "epoch": 0.3908283129244492,
      "grad_norm": 0.604904294013977,
      "learning_rate": 4.3488532274502354e-05,
      "loss": 1.261,
      "step": 125400
    },
    {
      "epoch": 0.3909841455851049,
      "grad_norm": 0.5485107898712158,
      "learning_rate": 4.348593506349142e-05,
      "loss": 1.2781,
      "step": 125450
    },
    {
      "epoch": 0.3911399782457606,
      "grad_norm": 0.7634595036506653,
      "learning_rate": 4.348333785248049e-05,
      "loss": 1.2496,
      "step": 125500
    },
    {
      "epoch": 0.39129581090641624,
      "grad_norm": 0.5259556770324707,
      "learning_rate": 4.3480740641469565e-05,
      "loss": 1.2881,
      "step": 125550
    },
    {
      "epoch": 0.39145164356707196,
      "grad_norm": 0.7208914756774902,
      "learning_rate": 4.347814343045864e-05,
      "loss": 1.2401,
      "step": 125600
    },
    {
      "epoch": 0.3916074762277276,
      "grad_norm": 0.6037072539329529,
      "learning_rate": 4.347554621944771e-05,
      "loss": 1.2674,
      "step": 125650
    },
    {
      "epoch": 0.3917633088883833,
      "grad_norm": 0.663367748260498,
      "learning_rate": 4.347294900843678e-05,
      "loss": 1.2662,
      "step": 125700
    },
    {
      "epoch": 0.391919141549039,
      "grad_norm": 0.5298296213150024,
      "learning_rate": 4.3470351797425855e-05,
      "loss": 1.2759,
      "step": 125750
    },
    {
      "epoch": 0.39207497420969467,
      "grad_norm": 0.5614224672317505,
      "learning_rate": 4.346775458641493e-05,
      "loss": 1.2953,
      "step": 125800
    },
    {
      "epoch": 0.39223080687035033,
      "grad_norm": 0.6830313205718994,
      "learning_rate": 4.3465157375404e-05,
      "loss": 1.2939,
      "step": 125850
    },
    {
      "epoch": 0.392386639531006,
      "grad_norm": 0.5731850266456604,
      "learning_rate": 4.3462560164393066e-05,
      "loss": 1.2347,
      "step": 125900
    },
    {
      "epoch": 0.3925424721916617,
      "grad_norm": 0.6664340496063232,
      "learning_rate": 4.3459962953382145e-05,
      "loss": 1.2219,
      "step": 125950
    },
    {
      "epoch": 0.3926983048523174,
      "grad_norm": 0.5234832167625427,
      "learning_rate": 4.345736574237122e-05,
      "loss": 1.2767,
      "step": 126000
    },
    {
      "epoch": 0.39285413751297305,
      "grad_norm": 0.4368324875831604,
      "learning_rate": 4.3454768531360283e-05,
      "loss": 1.2249,
      "step": 126050
    },
    {
      "epoch": 0.39300997017362876,
      "grad_norm": 0.6030871272087097,
      "learning_rate": 4.345217132034936e-05,
      "loss": 1.3125,
      "step": 126100
    },
    {
      "epoch": 0.39316580283428443,
      "grad_norm": 0.5746402740478516,
      "learning_rate": 4.344957410933843e-05,
      "loss": 1.3391,
      "step": 126150
    },
    {
      "epoch": 0.3933216354949401,
      "grad_norm": 0.5962190628051758,
      "learning_rate": 4.34469768983275e-05,
      "loss": 1.297,
      "step": 126200
    },
    {
      "epoch": 0.3934774681555958,
      "grad_norm": 0.6135668754577637,
      "learning_rate": 4.3444379687316573e-05,
      "loss": 1.3326,
      "step": 126250
    },
    {
      "epoch": 0.3936333008162515,
      "grad_norm": 0.5225206613540649,
      "learning_rate": 4.3441782476305646e-05,
      "loss": 1.2713,
      "step": 126300
    },
    {
      "epoch": 0.39378913347690714,
      "grad_norm": 0.5913875699043274,
      "learning_rate": 4.343918526529472e-05,
      "loss": 1.2815,
      "step": 126350
    },
    {
      "epoch": 0.39394496613756286,
      "grad_norm": 0.6139169335365295,
      "learning_rate": 4.343658805428379e-05,
      "loss": 1.2923,
      "step": 126400
    },
    {
      "epoch": 0.3941007987982185,
      "grad_norm": 0.7265818119049072,
      "learning_rate": 4.343399084327286e-05,
      "loss": 1.3148,
      "step": 126450
    },
    {
      "epoch": 0.3942566314588742,
      "grad_norm": 0.5251086950302124,
      "learning_rate": 4.3431393632261936e-05,
      "loss": 1.2968,
      "step": 126500
    },
    {
      "epoch": 0.3944124641195299,
      "grad_norm": 0.6282180547714233,
      "learning_rate": 4.342879642125101e-05,
      "loss": 1.2586,
      "step": 126550
    },
    {
      "epoch": 0.39456829678018557,
      "grad_norm": 0.5280331969261169,
      "learning_rate": 4.3426199210240074e-05,
      "loss": 1.2963,
      "step": 126600
    },
    {
      "epoch": 0.39472412944084123,
      "grad_norm": 0.5932570099830627,
      "learning_rate": 4.3423601999229154e-05,
      "loss": 1.2567,
      "step": 126650
    },
    {
      "epoch": 0.39487996210149695,
      "grad_norm": 0.6541065573692322,
      "learning_rate": 4.342100478821822e-05,
      "loss": 1.3495,
      "step": 126700
    },
    {
      "epoch": 0.3950357947621526,
      "grad_norm": 0.6384478211402893,
      "learning_rate": 4.341840757720729e-05,
      "loss": 1.2941,
      "step": 126750
    },
    {
      "epoch": 0.3951916274228083,
      "grad_norm": 0.667477011680603,
      "learning_rate": 4.3415810366196364e-05,
      "loss": 1.2591,
      "step": 126800
    },
    {
      "epoch": 0.395347460083464,
      "grad_norm": 0.5436590909957886,
      "learning_rate": 4.341321315518544e-05,
      "loss": 1.3064,
      "step": 126850
    },
    {
      "epoch": 0.39550329274411966,
      "grad_norm": 0.5375807881355286,
      "learning_rate": 4.341061594417451e-05,
      "loss": 1.2709,
      "step": 126900
    },
    {
      "epoch": 0.3956591254047753,
      "grad_norm": 0.5566298365592957,
      "learning_rate": 4.340801873316358e-05,
      "loss": 1.2224,
      "step": 126950
    },
    {
      "epoch": 0.39581495806543104,
      "grad_norm": 0.5604212284088135,
      "learning_rate": 4.3405421522152654e-05,
      "loss": 1.2016,
      "step": 127000
    },
    {
      "epoch": 0.3959707907260867,
      "grad_norm": 0.6087833642959595,
      "learning_rate": 4.340282431114173e-05,
      "loss": 1.2503,
      "step": 127050
    },
    {
      "epoch": 0.39612662338674237,
      "grad_norm": 0.6958162188529968,
      "learning_rate": 4.34002271001308e-05,
      "loss": 1.2776,
      "step": 127100
    },
    {
      "epoch": 0.39628245604739804,
      "grad_norm": 0.49615204334259033,
      "learning_rate": 4.3397629889119865e-05,
      "loss": 1.3104,
      "step": 127150
    },
    {
      "epoch": 0.39643828870805375,
      "grad_norm": 0.6282706260681152,
      "learning_rate": 4.3395032678108944e-05,
      "loss": 1.2581,
      "step": 127200
    },
    {
      "epoch": 0.3965941213687094,
      "grad_norm": 0.5497264266014099,
      "learning_rate": 4.339243546709802e-05,
      "loss": 1.2839,
      "step": 127250
    },
    {
      "epoch": 0.3967499540293651,
      "grad_norm": 0.5944322347640991,
      "learning_rate": 4.338983825608708e-05,
      "loss": 1.2731,
      "step": 127300
    },
    {
      "epoch": 0.3969057866900208,
      "grad_norm": 0.6286641955375671,
      "learning_rate": 4.338724104507616e-05,
      "loss": 1.2789,
      "step": 127350
    },
    {
      "epoch": 0.39706161935067646,
      "grad_norm": 0.6595600843429565,
      "learning_rate": 4.338464383406523e-05,
      "loss": 1.3424,
      "step": 127400
    },
    {
      "epoch": 0.39721745201133213,
      "grad_norm": 0.6118144989013672,
      "learning_rate": 4.33820466230543e-05,
      "loss": 1.2628,
      "step": 127450
    },
    {
      "epoch": 0.39737328467198785,
      "grad_norm": 0.5849618315696716,
      "learning_rate": 4.337944941204337e-05,
      "loss": 1.258,
      "step": 127500
    },
    {
      "epoch": 0.3975291173326435,
      "grad_norm": 0.6171559691429138,
      "learning_rate": 4.3376852201032445e-05,
      "loss": 1.2578,
      "step": 127550
    },
    {
      "epoch": 0.3976849499932992,
      "grad_norm": 0.5631725788116455,
      "learning_rate": 4.337425499002152e-05,
      "loss": 1.2645,
      "step": 127600
    },
    {
      "epoch": 0.3978407826539549,
      "grad_norm": 0.5291363596916199,
      "learning_rate": 4.337165777901059e-05,
      "loss": 1.2561,
      "step": 127650
    },
    {
      "epoch": 0.39799661531461056,
      "grad_norm": 0.5251559615135193,
      "learning_rate": 4.3369060567999656e-05,
      "loss": 1.2632,
      "step": 127700
    },
    {
      "epoch": 0.3981524479752662,
      "grad_norm": 0.6058637499809265,
      "learning_rate": 4.3366463356988735e-05,
      "loss": 1.2824,
      "step": 127750
    },
    {
      "epoch": 0.39830828063592194,
      "grad_norm": 0.613477885723114,
      "learning_rate": 4.336386614597781e-05,
      "loss": 1.2706,
      "step": 127800
    },
    {
      "epoch": 0.3984641132965776,
      "grad_norm": 0.6389579772949219,
      "learning_rate": 4.336126893496687e-05,
      "loss": 1.2742,
      "step": 127850
    },
    {
      "epoch": 0.39861994595723327,
      "grad_norm": 0.5035978555679321,
      "learning_rate": 4.335867172395595e-05,
      "loss": 1.2641,
      "step": 127900
    },
    {
      "epoch": 0.398775778617889,
      "grad_norm": 0.5365591049194336,
      "learning_rate": 4.3356074512945025e-05,
      "loss": 1.2331,
      "step": 127950
    },
    {
      "epoch": 0.39893161127854465,
      "grad_norm": 0.751268208026886,
      "learning_rate": 4.335347730193409e-05,
      "loss": 1.2795,
      "step": 128000
    },
    {
      "epoch": 0.3990874439392003,
      "grad_norm": 0.4509322941303253,
      "learning_rate": 4.335088009092316e-05,
      "loss": 1.2602,
      "step": 128050
    },
    {
      "epoch": 0.39924327659985603,
      "grad_norm": 0.5440673828125,
      "learning_rate": 4.3348282879912236e-05,
      "loss": 1.2702,
      "step": 128100
    },
    {
      "epoch": 0.3993991092605117,
      "grad_norm": 0.6015974879264832,
      "learning_rate": 4.334568566890131e-05,
      "loss": 1.293,
      "step": 128150
    },
    {
      "epoch": 0.39955494192116736,
      "grad_norm": 0.6941984295845032,
      "learning_rate": 4.334308845789038e-05,
      "loss": 1.3,
      "step": 128200
    },
    {
      "epoch": 0.3997107745818231,
      "grad_norm": 0.5325855016708374,
      "learning_rate": 4.334049124687945e-05,
      "loss": 1.2676,
      "step": 128250
    },
    {
      "epoch": 0.39986660724247874,
      "grad_norm": 0.6768778562545776,
      "learning_rate": 4.3337894035868526e-05,
      "loss": 1.3067,
      "step": 128300
    },
    {
      "epoch": 0.4000224399031344,
      "grad_norm": 0.8519375324249268,
      "learning_rate": 4.33352968248576e-05,
      "loss": 1.318,
      "step": 128350
    },
    {
      "epoch": 0.4001782725637901,
      "grad_norm": 0.5587887763977051,
      "learning_rate": 4.3332699613846664e-05,
      "loss": 1.2037,
      "step": 128400
    },
    {
      "epoch": 0.4003341052244458,
      "grad_norm": 0.6789969205856323,
      "learning_rate": 4.333010240283574e-05,
      "loss": 1.2925,
      "step": 128450
    },
    {
      "epoch": 0.40048993788510145,
      "grad_norm": 0.5345014333724976,
      "learning_rate": 4.3327505191824816e-05,
      "loss": 1.2233,
      "step": 128500
    },
    {
      "epoch": 0.4006457705457571,
      "grad_norm": 0.537188708782196,
      "learning_rate": 4.332490798081388e-05,
      "loss": 1.2356,
      "step": 128550
    },
    {
      "epoch": 0.40080160320641284,
      "grad_norm": 0.6431164145469666,
      "learning_rate": 4.332231076980296e-05,
      "loss": 1.2475,
      "step": 128600
    },
    {
      "epoch": 0.4009574358670685,
      "grad_norm": 0.5191900134086609,
      "learning_rate": 4.331971355879203e-05,
      "loss": 1.3267,
      "step": 128650
    },
    {
      "epoch": 0.40111326852772416,
      "grad_norm": 0.5654402375221252,
      "learning_rate": 4.33171163477811e-05,
      "loss": 1.3508,
      "step": 128700
    },
    {
      "epoch": 0.4012691011883799,
      "grad_norm": 0.5472760796546936,
      "learning_rate": 4.331451913677017e-05,
      "loss": 1.2488,
      "step": 128750
    },
    {
      "epoch": 0.40142493384903555,
      "grad_norm": 0.6736763715744019,
      "learning_rate": 4.3311921925759244e-05,
      "loss": 1.2802,
      "step": 128800
    },
    {
      "epoch": 0.4015807665096912,
      "grad_norm": 0.5725709795951843,
      "learning_rate": 4.3309324714748317e-05,
      "loss": 1.2928,
      "step": 128850
    },
    {
      "epoch": 0.40173659917034693,
      "grad_norm": 0.489077627658844,
      "learning_rate": 4.330672750373739e-05,
      "loss": 1.2945,
      "step": 128900
    },
    {
      "epoch": 0.4018924318310026,
      "grad_norm": 0.630953848361969,
      "learning_rate": 4.3304130292726455e-05,
      "loss": 1.2673,
      "step": 128950
    },
    {
      "epoch": 0.40204826449165826,
      "grad_norm": 0.6124792098999023,
      "learning_rate": 4.3301533081715534e-05,
      "loss": 1.2964,
      "step": 129000
    },
    {
      "epoch": 0.402204097152314,
      "grad_norm": 0.6764472723007202,
      "learning_rate": 4.3298935870704607e-05,
      "loss": 1.2858,
      "step": 129050
    },
    {
      "epoch": 0.40235992981296964,
      "grad_norm": 0.5142732858657837,
      "learning_rate": 4.329633865969367e-05,
      "loss": 1.285,
      "step": 129100
    },
    {
      "epoch": 0.4025157624736253,
      "grad_norm": 0.5934566259384155,
      "learning_rate": 4.329374144868275e-05,
      "loss": 1.3002,
      "step": 129150
    },
    {
      "epoch": 0.402671595134281,
      "grad_norm": 0.6398521065711975,
      "learning_rate": 4.3291144237671824e-05,
      "loss": 1.2911,
      "step": 129200
    },
    {
      "epoch": 0.4028274277949367,
      "grad_norm": 0.6829758882522583,
      "learning_rate": 4.328854702666089e-05,
      "loss": 1.2812,
      "step": 129250
    },
    {
      "epoch": 0.40298326045559235,
      "grad_norm": 0.6244954466819763,
      "learning_rate": 4.328594981564996e-05,
      "loss": 1.2645,
      "step": 129300
    },
    {
      "epoch": 0.40313909311624807,
      "grad_norm": 0.5079953670501709,
      "learning_rate": 4.3283352604639035e-05,
      "loss": 1.258,
      "step": 129350
    },
    {
      "epoch": 0.40329492577690373,
      "grad_norm": 0.6256757378578186,
      "learning_rate": 4.328075539362811e-05,
      "loss": 1.2934,
      "step": 129400
    },
    {
      "epoch": 0.4034507584375594,
      "grad_norm": 0.4919795095920563,
      "learning_rate": 4.327815818261718e-05,
      "loss": 1.3096,
      "step": 129450
    },
    {
      "epoch": 0.4036065910982151,
      "grad_norm": 0.5859843492507935,
      "learning_rate": 4.327561291582647e-05,
      "loss": 1.3441,
      "step": 129500
    },
    {
      "epoch": 0.4037624237588708,
      "grad_norm": 0.5797820687294006,
      "learning_rate": 4.3273015704815544e-05,
      "loss": 1.2698,
      "step": 129550
    },
    {
      "epoch": 0.40391825641952644,
      "grad_norm": 0.6369097828865051,
      "learning_rate": 4.327041849380462e-05,
      "loss": 1.2227,
      "step": 129600
    },
    {
      "epoch": 0.40407408908018216,
      "grad_norm": 0.5268089175224304,
      "learning_rate": 4.326782128279368e-05,
      "loss": 1.2585,
      "step": 129650
    },
    {
      "epoch": 0.4042299217408378,
      "grad_norm": 0.697039783000946,
      "learning_rate": 4.3265224071782755e-05,
      "loss": 1.314,
      "step": 129700
    },
    {
      "epoch": 0.4043857544014935,
      "grad_norm": 0.49122169613838196,
      "learning_rate": 4.3262626860771834e-05,
      "loss": 1.3046,
      "step": 129750
    },
    {
      "epoch": 0.40454158706214915,
      "grad_norm": 0.5374799370765686,
      "learning_rate": 4.32600296497609e-05,
      "loss": 1.2493,
      "step": 129800
    },
    {
      "epoch": 0.4046974197228049,
      "grad_norm": 0.5329189300537109,
      "learning_rate": 4.325743243874997e-05,
      "loss": 1.2781,
      "step": 129850
    },
    {
      "epoch": 0.40485325238346054,
      "grad_norm": 0.6265085339546204,
      "learning_rate": 4.325483522773905e-05,
      "loss": 1.2291,
      "step": 129900
    },
    {
      "epoch": 0.4050090850441162,
      "grad_norm": 0.48764920234680176,
      "learning_rate": 4.325223801672812e-05,
      "loss": 1.2527,
      "step": 129950
    },
    {
      "epoch": 0.4051649177047719,
      "grad_norm": 0.6196596622467041,
      "learning_rate": 4.324964080571719e-05,
      "loss": 1.293,
      "step": 130000
    },
    {
      "epoch": 0.4053207503654276,
      "grad_norm": 0.6462233662605286,
      "learning_rate": 4.324704359470626e-05,
      "loss": 1.2563,
      "step": 130050
    },
    {
      "epoch": 0.40547658302608325,
      "grad_norm": 0.5701438784599304,
      "learning_rate": 4.3244446383695335e-05,
      "loss": 1.2196,
      "step": 130100
    },
    {
      "epoch": 0.40563241568673897,
      "grad_norm": 0.6551206707954407,
      "learning_rate": 4.324184917268441e-05,
      "loss": 1.2401,
      "step": 130150
    },
    {
      "epoch": 0.40578824834739463,
      "grad_norm": 0.5403002500534058,
      "learning_rate": 4.323925196167348e-05,
      "loss": 1.217,
      "step": 130200
    },
    {
      "epoch": 0.4059440810080503,
      "grad_norm": 0.7770232558250427,
      "learning_rate": 4.323665475066255e-05,
      "loss": 1.2926,
      "step": 130250
    },
    {
      "epoch": 0.406099913668706,
      "grad_norm": 0.6480324864387512,
      "learning_rate": 4.3234057539651625e-05,
      "loss": 1.2762,
      "step": 130300
    },
    {
      "epoch": 0.4062557463293617,
      "grad_norm": 0.6065077781677246,
      "learning_rate": 4.323146032864069e-05,
      "loss": 1.2941,
      "step": 130350
    },
    {
      "epoch": 0.40641157899001734,
      "grad_norm": 0.5054750442504883,
      "learning_rate": 4.3228863117629763e-05,
      "loss": 1.2928,
      "step": 130400
    },
    {
      "epoch": 0.40656741165067306,
      "grad_norm": 0.6750600934028625,
      "learning_rate": 4.322626590661884e-05,
      "loss": 1.27,
      "step": 130450
    },
    {
      "epoch": 0.4067232443113287,
      "grad_norm": 0.6010610461235046,
      "learning_rate": 4.322366869560791e-05,
      "loss": 1.2583,
      "step": 130500
    },
    {
      "epoch": 0.4068790769719844,
      "grad_norm": 0.7199938297271729,
      "learning_rate": 4.322107148459698e-05,
      "loss": 1.2989,
      "step": 130550
    },
    {
      "epoch": 0.4070349096326401,
      "grad_norm": 0.5829344987869263,
      "learning_rate": 4.321847427358606e-05,
      "loss": 1.2375,
      "step": 130600
    },
    {
      "epoch": 0.40719074229329577,
      "grad_norm": 0.5924407839775085,
      "learning_rate": 4.3215877062575126e-05,
      "loss": 1.317,
      "step": 130650
    },
    {
      "epoch": 0.40734657495395143,
      "grad_norm": 0.7201712131500244,
      "learning_rate": 4.32132798515642e-05,
      "loss": 1.2578,
      "step": 130700
    },
    {
      "epoch": 0.40750240761460715,
      "grad_norm": 0.5803160667419434,
      "learning_rate": 4.321068264055327e-05,
      "loss": 1.2995,
      "step": 130750
    },
    {
      "epoch": 0.4076582402752628,
      "grad_norm": 0.6341825723648071,
      "learning_rate": 4.3208085429542343e-05,
      "loss": 1.3242,
      "step": 130800
    },
    {
      "epoch": 0.4078140729359185,
      "grad_norm": 0.49980130791664124,
      "learning_rate": 4.3205488218531416e-05,
      "loss": 1.2384,
      "step": 130850
    },
    {
      "epoch": 0.4079699055965742,
      "grad_norm": 0.7559208273887634,
      "learning_rate": 4.320289100752049e-05,
      "loss": 1.2741,
      "step": 130900
    },
    {
      "epoch": 0.40812573825722986,
      "grad_norm": 0.6077607870101929,
      "learning_rate": 4.3200293796509554e-05,
      "loss": 1.2546,
      "step": 130950
    },
    {
      "epoch": 0.40828157091788553,
      "grad_norm": 0.5931982398033142,
      "learning_rate": 4.3197696585498633e-05,
      "loss": 1.2207,
      "step": 131000
    },
    {
      "epoch": 0.4084374035785412,
      "grad_norm": 0.5656701326370239,
      "learning_rate": 4.31950993744877e-05,
      "loss": 1.3415,
      "step": 131050
    },
    {
      "epoch": 0.4085932362391969,
      "grad_norm": 0.6615855097770691,
      "learning_rate": 4.319250216347677e-05,
      "loss": 1.2774,
      "step": 131100
    },
    {
      "epoch": 0.4087490688998526,
      "grad_norm": 0.6351200342178345,
      "learning_rate": 4.318990495246585e-05,
      "loss": 1.2805,
      "step": 131150
    },
    {
      "epoch": 0.40890490156050824,
      "grad_norm": 0.4892980754375458,
      "learning_rate": 4.318730774145492e-05,
      "loss": 1.2725,
      "step": 131200
    },
    {
      "epoch": 0.40906073422116396,
      "grad_norm": 0.5204506516456604,
      "learning_rate": 4.318471053044399e-05,
      "loss": 1.2731,
      "step": 131250
    },
    {
      "epoch": 0.4092165668818196,
      "grad_norm": 0.7032626867294312,
      "learning_rate": 4.318211331943306e-05,
      "loss": 1.261,
      "step": 131300
    },
    {
      "epoch": 0.4093723995424753,
      "grad_norm": 0.5166312456130981,
      "learning_rate": 4.3179516108422134e-05,
      "loss": 1.3832,
      "step": 131350
    },
    {
      "epoch": 0.409528232203131,
      "grad_norm": 0.5219990611076355,
      "learning_rate": 4.317691889741121e-05,
      "loss": 1.2572,
      "step": 131400
    },
    {
      "epoch": 0.40968406486378667,
      "grad_norm": 0.6357908248901367,
      "learning_rate": 4.317432168640028e-05,
      "loss": 1.3315,
      "step": 131450
    },
    {
      "epoch": 0.40983989752444233,
      "grad_norm": 0.6401694416999817,
      "learning_rate": 4.317172447538935e-05,
      "loss": 1.237,
      "step": 131500
    },
    {
      "epoch": 0.40999573018509805,
      "grad_norm": 0.5995790958404541,
      "learning_rate": 4.3169127264378424e-05,
      "loss": 1.3008,
      "step": 131550
    },
    {
      "epoch": 0.4101515628457537,
      "grad_norm": 0.7261896133422852,
      "learning_rate": 4.316653005336749e-05,
      "loss": 1.2792,
      "step": 131600
    },
    {
      "epoch": 0.4103073955064094,
      "grad_norm": 0.5053651332855225,
      "learning_rate": 4.316393284235656e-05,
      "loss": 1.2937,
      "step": 131650
    },
    {
      "epoch": 0.4104632281670651,
      "grad_norm": 0.6622916460037231,
      "learning_rate": 4.316133563134564e-05,
      "loss": 1.3161,
      "step": 131700
    },
    {
      "epoch": 0.41061906082772076,
      "grad_norm": 0.5868291258811951,
      "learning_rate": 4.315873842033471e-05,
      "loss": 1.2692,
      "step": 131750
    },
    {
      "epoch": 0.4107748934883764,
      "grad_norm": 0.7292623519897461,
      "learning_rate": 4.3156193153544e-05,
      "loss": 1.3226,
      "step": 131800
    },
    {
      "epoch": 0.41093072614903214,
      "grad_norm": 0.6183932423591614,
      "learning_rate": 4.315359594253307e-05,
      "loss": 1.2887,
      "step": 131850
    },
    {
      "epoch": 0.4110865588096878,
      "grad_norm": 0.6388256549835205,
      "learning_rate": 4.3150998731522145e-05,
      "loss": 1.2829,
      "step": 131900
    },
    {
      "epoch": 0.41124239147034347,
      "grad_norm": 0.49520039558410645,
      "learning_rate": 4.314840152051122e-05,
      "loss": 1.3484,
      "step": 131950
    },
    {
      "epoch": 0.4113982241309992,
      "grad_norm": 0.6130410432815552,
      "learning_rate": 4.314580430950029e-05,
      "loss": 1.2427,
      "step": 132000
    },
    {
      "epoch": 0.41155405679165485,
      "grad_norm": 0.721832275390625,
      "learning_rate": 4.3143207098489355e-05,
      "loss": 1.2922,
      "step": 132050
    },
    {
      "epoch": 0.4117098894523105,
      "grad_norm": 0.6415041089057922,
      "learning_rate": 4.3140609887478435e-05,
      "loss": 1.2616,
      "step": 132100
    },
    {
      "epoch": 0.41186572211296624,
      "grad_norm": 0.5906524062156677,
      "learning_rate": 4.313801267646751e-05,
      "loss": 1.2761,
      "step": 132150
    },
    {
      "epoch": 0.4120215547736219,
      "grad_norm": 0.6394011378288269,
      "learning_rate": 4.313541546545657e-05,
      "loss": 1.273,
      "step": 132200
    },
    {
      "epoch": 0.41217738743427756,
      "grad_norm": 0.7864432334899902,
      "learning_rate": 4.313281825444565e-05,
      "loss": 1.2778,
      "step": 132250
    },
    {
      "epoch": 0.4123332200949333,
      "grad_norm": 0.6063726544380188,
      "learning_rate": 4.313022104343472e-05,
      "loss": 1.3192,
      "step": 132300
    },
    {
      "epoch": 0.41248905275558895,
      "grad_norm": 0.8228977918624878,
      "learning_rate": 4.312762383242379e-05,
      "loss": 1.2768,
      "step": 132350
    },
    {
      "epoch": 0.4126448854162446,
      "grad_norm": 0.7078390717506409,
      "learning_rate": 4.312502662141286e-05,
      "loss": 1.2472,
      "step": 132400
    },
    {
      "epoch": 0.4128007180769003,
      "grad_norm": 0.6323947906494141,
      "learning_rate": 4.3122429410401935e-05,
      "loss": 1.2948,
      "step": 132450
    },
    {
      "epoch": 0.412956550737556,
      "grad_norm": 0.6630433797836304,
      "learning_rate": 4.311983219939101e-05,
      "loss": 1.2886,
      "step": 132500
    },
    {
      "epoch": 0.41311238339821166,
      "grad_norm": 0.5654430985450745,
      "learning_rate": 4.311723498838008e-05,
      "loss": 1.2513,
      "step": 132550
    },
    {
      "epoch": 0.4132682160588673,
      "grad_norm": 0.6478428244590759,
      "learning_rate": 4.311463777736915e-05,
      "loss": 1.3347,
      "step": 132600
    },
    {
      "epoch": 0.41342404871952304,
      "grad_norm": 0.6228793859481812,
      "learning_rate": 4.3112040566358225e-05,
      "loss": 1.2784,
      "step": 132650
    },
    {
      "epoch": 0.4135798813801787,
      "grad_norm": 0.5482504367828369,
      "learning_rate": 4.31094433553473e-05,
      "loss": 1.3391,
      "step": 132700
    },
    {
      "epoch": 0.41373571404083437,
      "grad_norm": 0.5533774495124817,
      "learning_rate": 4.3106846144336364e-05,
      "loss": 1.3171,
      "step": 132750
    },
    {
      "epoch": 0.4138915467014901,
      "grad_norm": 0.5980605483055115,
      "learning_rate": 4.310424893332544e-05,
      "loss": 1.2508,
      "step": 132800
    },
    {
      "epoch": 0.41404737936214575,
      "grad_norm": 0.6519829630851746,
      "learning_rate": 4.3101651722314515e-05,
      "loss": 1.2391,
      "step": 132850
    },
    {
      "epoch": 0.4142032120228014,
      "grad_norm": 0.6122337579727173,
      "learning_rate": 4.309905451130358e-05,
      "loss": 1.2808,
      "step": 132900
    },
    {
      "epoch": 0.41435904468345713,
      "grad_norm": 0.5463085770606995,
      "learning_rate": 4.3096457300292654e-05,
      "loss": 1.2753,
      "step": 132950
    },
    {
      "epoch": 0.4145148773441128,
      "grad_norm": 0.6509996652603149,
      "learning_rate": 4.3093860089281726e-05,
      "loss": 1.2505,
      "step": 133000
    },
    {
      "epoch": 0.41467071000476846,
      "grad_norm": 0.6057698726654053,
      "learning_rate": 4.30912628782708e-05,
      "loss": 1.2641,
      "step": 133050
    },
    {
      "epoch": 0.4148265426654242,
      "grad_norm": 0.5532364249229431,
      "learning_rate": 4.308866566725987e-05,
      "loss": 1.3049,
      "step": 133100
    },
    {
      "epoch": 0.41498237532607984,
      "grad_norm": 0.6781042218208313,
      "learning_rate": 4.3086068456248944e-05,
      "loss": 1.2316,
      "step": 133150
    },
    {
      "epoch": 0.4151382079867355,
      "grad_norm": 0.6927700638771057,
      "learning_rate": 4.3083471245238016e-05,
      "loss": 1.2672,
      "step": 133200
    },
    {
      "epoch": 0.4152940406473912,
      "grad_norm": 0.5728213787078857,
      "learning_rate": 4.308087403422709e-05,
      "loss": 1.2869,
      "step": 133250
    },
    {
      "epoch": 0.4154498733080469,
      "grad_norm": 0.6179444193840027,
      "learning_rate": 4.3078276823216154e-05,
      "loss": 1.3222,
      "step": 133300
    },
    {
      "epoch": 0.41560570596870255,
      "grad_norm": 0.6959733963012695,
      "learning_rate": 4.3075679612205234e-05,
      "loss": 1.3082,
      "step": 133350
    },
    {
      "epoch": 0.4157615386293583,
      "grad_norm": 0.5714619755744934,
      "learning_rate": 4.3073082401194306e-05,
      "loss": 1.2602,
      "step": 133400
    },
    {
      "epoch": 0.41591737129001394,
      "grad_norm": 0.6184346079826355,
      "learning_rate": 4.307048519018337e-05,
      "loss": 1.3465,
      "step": 133450
    },
    {
      "epoch": 0.4160732039506696,
      "grad_norm": 0.7281902432441711,
      "learning_rate": 4.306788797917245e-05,
      "loss": 1.2647,
      "step": 133500
    },
    {
      "epoch": 0.4162290366113253,
      "grad_norm": 0.7990896105766296,
      "learning_rate": 4.3065290768161524e-05,
      "loss": 1.2664,
      "step": 133550
    },
    {
      "epoch": 0.416384869271981,
      "grad_norm": 0.5374918580055237,
      "learning_rate": 4.306269355715059e-05,
      "loss": 1.2673,
      "step": 133600
    },
    {
      "epoch": 0.41654070193263665,
      "grad_norm": 0.546167254447937,
      "learning_rate": 4.306009634613966e-05,
      "loss": 1.2635,
      "step": 133650
    },
    {
      "epoch": 0.4166965345932923,
      "grad_norm": 0.5561685562133789,
      "learning_rate": 4.3057499135128734e-05,
      "loss": 1.2513,
      "step": 133700
    },
    {
      "epoch": 0.41685236725394803,
      "grad_norm": 0.6610720157623291,
      "learning_rate": 4.305490192411781e-05,
      "loss": 1.2539,
      "step": 133750
    },
    {
      "epoch": 0.4170081999146037,
      "grad_norm": 0.4526958167552948,
      "learning_rate": 4.305230471310688e-05,
      "loss": 1.2644,
      "step": 133800
    },
    {
      "epoch": 0.41716403257525936,
      "grad_norm": 0.681488037109375,
      "learning_rate": 4.304970750209595e-05,
      "loss": 1.2808,
      "step": 133850
    },
    {
      "epoch": 0.4173198652359151,
      "grad_norm": 0.6878519654273987,
      "learning_rate": 4.3047110291085024e-05,
      "loss": 1.3418,
      "step": 133900
    },
    {
      "epoch": 0.41747569789657074,
      "grad_norm": 0.6553367376327515,
      "learning_rate": 4.30445130800741e-05,
      "loss": 1.2694,
      "step": 133950
    },
    {
      "epoch": 0.4176315305572264,
      "grad_norm": 0.7013148069381714,
      "learning_rate": 4.304191586906316e-05,
      "loss": 1.2725,
      "step": 134000
    },
    {
      "epoch": 0.4177873632178821,
      "grad_norm": 0.6055176258087158,
      "learning_rate": 4.303931865805224e-05,
      "loss": 1.3033,
      "step": 134050
    },
    {
      "epoch": 0.4179431958785378,
      "grad_norm": 0.511165201663971,
      "learning_rate": 4.3036721447041314e-05,
      "loss": 1.3175,
      "step": 134100
    },
    {
      "epoch": 0.41809902853919345,
      "grad_norm": 0.6487141847610474,
      "learning_rate": 4.303412423603038e-05,
      "loss": 1.296,
      "step": 134150
    },
    {
      "epoch": 0.41825486119984917,
      "grad_norm": 0.6904723048210144,
      "learning_rate": 4.303152702501945e-05,
      "loss": 1.2698,
      "step": 134200
    },
    {
      "epoch": 0.41841069386050483,
      "grad_norm": 0.46414878964424133,
      "learning_rate": 4.3028929814008525e-05,
      "loss": 1.2477,
      "step": 134250
    },
    {
      "epoch": 0.4185665265211605,
      "grad_norm": 0.5957569479942322,
      "learning_rate": 4.302638454721782e-05,
      "loss": 1.3308,
      "step": 134300
    },
    {
      "epoch": 0.4187223591818162,
      "grad_norm": 0.6301669478416443,
      "learning_rate": 4.302378733620689e-05,
      "loss": 1.334,
      "step": 134350
    },
    {
      "epoch": 0.4188781918424719,
      "grad_norm": 0.5405575633049011,
      "learning_rate": 4.302119012519596e-05,
      "loss": 1.3327,
      "step": 134400
    },
    {
      "epoch": 0.41903402450312754,
      "grad_norm": 0.48541060090065,
      "learning_rate": 4.3018592914185035e-05,
      "loss": 1.3085,
      "step": 134450
    },
    {
      "epoch": 0.41918985716378326,
      "grad_norm": 0.6393131613731384,
      "learning_rate": 4.301599570317411e-05,
      "loss": 1.3401,
      "step": 134500
    },
    {
      "epoch": 0.4193456898244389,
      "grad_norm": 0.5676529407501221,
      "learning_rate": 4.301339849216317e-05,
      "loss": 1.2761,
      "step": 134550
    },
    {
      "epoch": 0.4195015224850946,
      "grad_norm": 0.7045438289642334,
      "learning_rate": 4.301080128115225e-05,
      "loss": 1.2895,
      "step": 134600
    },
    {
      "epoch": 0.4196573551457503,
      "grad_norm": 0.5100283026695251,
      "learning_rate": 4.3008204070141325e-05,
      "loss": 1.2709,
      "step": 134650
    },
    {
      "epoch": 0.419813187806406,
      "grad_norm": 0.5259745121002197,
      "learning_rate": 4.300560685913039e-05,
      "loss": 1.2815,
      "step": 134700
    },
    {
      "epoch": 0.41996902046706164,
      "grad_norm": 0.5026425719261169,
      "learning_rate": 4.300300964811946e-05,
      "loss": 1.2993,
      "step": 134750
    },
    {
      "epoch": 0.42012485312771736,
      "grad_norm": 0.5190137028694153,
      "learning_rate": 4.300041243710854e-05,
      "loss": 1.3068,
      "step": 134800
    },
    {
      "epoch": 0.420280685788373,
      "grad_norm": 0.49419093132019043,
      "learning_rate": 4.299781522609761e-05,
      "loss": 1.2816,
      "step": 134850
    },
    {
      "epoch": 0.4204365184490287,
      "grad_norm": 0.5065749287605286,
      "learning_rate": 4.299521801508668e-05,
      "loss": 1.2392,
      "step": 134900
    },
    {
      "epoch": 0.4205923511096844,
      "grad_norm": 0.601936399936676,
      "learning_rate": 4.299262080407575e-05,
      "loss": 1.3378,
      "step": 134950
    },
    {
      "epoch": 0.42074818377034007,
      "grad_norm": 0.6668760776519775,
      "learning_rate": 4.2990023593064826e-05,
      "loss": 1.3019,
      "step": 135000
    },
    {
      "epoch": 0.42090401643099573,
      "grad_norm": 0.5293488502502441,
      "learning_rate": 4.29874263820539e-05,
      "loss": 1.2718,
      "step": 135050
    },
    {
      "epoch": 0.4210598490916514,
      "grad_norm": 0.6920080780982971,
      "learning_rate": 4.298482917104297e-05,
      "loss": 1.2905,
      "step": 135100
    },
    {
      "epoch": 0.4212156817523071,
      "grad_norm": 0.4742751717567444,
      "learning_rate": 4.298223196003204e-05,
      "loss": 1.2787,
      "step": 135150
    },
    {
      "epoch": 0.4213715144129628,
      "grad_norm": 0.7729480862617493,
      "learning_rate": 4.2979634749021116e-05,
      "loss": 1.2956,
      "step": 135200
    },
    {
      "epoch": 0.42152734707361844,
      "grad_norm": 0.5169295072555542,
      "learning_rate": 4.297703753801018e-05,
      "loss": 1.2994,
      "step": 135250
    },
    {
      "epoch": 0.42168317973427416,
      "grad_norm": 0.5328879356384277,
      "learning_rate": 4.2974440326999254e-05,
      "loss": 1.2976,
      "step": 135300
    },
    {
      "epoch": 0.4218390123949298,
      "grad_norm": 0.5818734765052795,
      "learning_rate": 4.297184311598833e-05,
      "loss": 1.3146,
      "step": 135350
    },
    {
      "epoch": 0.4219948450555855,
      "grad_norm": 0.622751772403717,
      "learning_rate": 4.29692459049774e-05,
      "loss": 1.2882,
      "step": 135400
    },
    {
      "epoch": 0.4221506777162412,
      "grad_norm": 0.6969478726387024,
      "learning_rate": 4.296664869396647e-05,
      "loss": 1.2768,
      "step": 135450
    },
    {
      "epoch": 0.42230651037689687,
      "grad_norm": 0.5776302814483643,
      "learning_rate": 4.296405148295555e-05,
      "loss": 1.2813,
      "step": 135500
    },
    {
      "epoch": 0.42246234303755253,
      "grad_norm": 0.5693468451499939,
      "learning_rate": 4.2961454271944616e-05,
      "loss": 1.2448,
      "step": 135550
    },
    {
      "epoch": 0.42261817569820825,
      "grad_norm": 0.6402776837348938,
      "learning_rate": 4.295885706093369e-05,
      "loss": 1.2645,
      "step": 135600
    },
    {
      "epoch": 0.4227740083588639,
      "grad_norm": 0.524029016494751,
      "learning_rate": 4.295625984992276e-05,
      "loss": 1.2896,
      "step": 135650
    },
    {
      "epoch": 0.4229298410195196,
      "grad_norm": 0.5608789324760437,
      "learning_rate": 4.2953662638911834e-05,
      "loss": 1.2815,
      "step": 135700
    },
    {
      "epoch": 0.4230856736801753,
      "grad_norm": 0.5245426297187805,
      "learning_rate": 4.2951065427900906e-05,
      "loss": 1.2936,
      "step": 135750
    },
    {
      "epoch": 0.42324150634083096,
      "grad_norm": 0.5902687311172485,
      "learning_rate": 4.294846821688998e-05,
      "loss": 1.3004,
      "step": 135800
    },
    {
      "epoch": 0.42339733900148663,
      "grad_norm": 0.6973357200622559,
      "learning_rate": 4.294587100587905e-05,
      "loss": 1.2743,
      "step": 135850
    },
    {
      "epoch": 0.42355317166214235,
      "grad_norm": 0.5286003947257996,
      "learning_rate": 4.2943273794868124e-05,
      "loss": 1.2702,
      "step": 135900
    },
    {
      "epoch": 0.423709004322798,
      "grad_norm": 0.7148835062980652,
      "learning_rate": 4.294067658385719e-05,
      "loss": 1.2779,
      "step": 135950
    },
    {
      "epoch": 0.4238648369834537,
      "grad_norm": 0.6468535661697388,
      "learning_rate": 4.293807937284626e-05,
      "loss": 1.2702,
      "step": 136000
    },
    {
      "epoch": 0.4240206696441094,
      "grad_norm": 0.4808603525161743,
      "learning_rate": 4.2935534106055554e-05,
      "loss": 1.2628,
      "step": 136050
    },
    {
      "epoch": 0.42417650230476506,
      "grad_norm": 0.5130918025970459,
      "learning_rate": 4.293293689504463e-05,
      "loss": 1.2665,
      "step": 136100
    },
    {
      "epoch": 0.4243323349654207,
      "grad_norm": 0.7057242393493652,
      "learning_rate": 4.29303396840337e-05,
      "loss": 1.2514,
      "step": 136150
    },
    {
      "epoch": 0.42448816762607644,
      "grad_norm": 0.6227570176124573,
      "learning_rate": 4.292774247302277e-05,
      "loss": 1.2773,
      "step": 136200
    },
    {
      "epoch": 0.4246440002867321,
      "grad_norm": 0.5839701294898987,
      "learning_rate": 4.2925145262011844e-05,
      "loss": 1.2843,
      "step": 136250
    },
    {
      "epoch": 0.42479983294738777,
      "grad_norm": 0.5704029202461243,
      "learning_rate": 4.292254805100092e-05,
      "loss": 1.2423,
      "step": 136300
    },
    {
      "epoch": 0.42495566560804343,
      "grad_norm": 0.5972390174865723,
      "learning_rate": 4.291995083998999e-05,
      "loss": 1.2909,
      "step": 136350
    },
    {
      "epoch": 0.42511149826869915,
      "grad_norm": 0.6971369385719299,
      "learning_rate": 4.2917353628979055e-05,
      "loss": 1.3464,
      "step": 136400
    },
    {
      "epoch": 0.4252673309293548,
      "grad_norm": 0.5785402059555054,
      "learning_rate": 4.2914756417968134e-05,
      "loss": 1.3256,
      "step": 136450
    },
    {
      "epoch": 0.4254231635900105,
      "grad_norm": 0.6358340382575989,
      "learning_rate": 4.29121592069572e-05,
      "loss": 1.2423,
      "step": 136500
    },
    {
      "epoch": 0.4255789962506662,
      "grad_norm": 0.5971900224685669,
      "learning_rate": 4.290956199594627e-05,
      "loss": 1.275,
      "step": 136550
    },
    {
      "epoch": 0.42573482891132186,
      "grad_norm": 0.5716942548751831,
      "learning_rate": 4.290696478493535e-05,
      "loss": 1.3225,
      "step": 136600
    },
    {
      "epoch": 0.4258906615719775,
      "grad_norm": 0.4922384023666382,
      "learning_rate": 4.290436757392442e-05,
      "loss": 1.2535,
      "step": 136650
    },
    {
      "epoch": 0.42604649423263324,
      "grad_norm": 0.6209067106246948,
      "learning_rate": 4.290177036291349e-05,
      "loss": 1.2895,
      "step": 136700
    },
    {
      "epoch": 0.4262023268932889,
      "grad_norm": 0.6045655608177185,
      "learning_rate": 4.289917315190256e-05,
      "loss": 1.37,
      "step": 136750
    },
    {
      "epoch": 0.42635815955394457,
      "grad_norm": 0.6353049278259277,
      "learning_rate": 4.2896575940891635e-05,
      "loss": 1.2928,
      "step": 136800
    },
    {
      "epoch": 0.4265139922146003,
      "grad_norm": 0.5744171738624573,
      "learning_rate": 4.289397872988071e-05,
      "loss": 1.1789,
      "step": 136850
    },
    {
      "epoch": 0.42666982487525595,
      "grad_norm": 0.5428194403648376,
      "learning_rate": 4.289138151886978e-05,
      "loss": 1.2515,
      "step": 136900
    },
    {
      "epoch": 0.4268256575359116,
      "grad_norm": 0.7506817579269409,
      "learning_rate": 4.288878430785885e-05,
      "loss": 1.2828,
      "step": 136950
    },
    {
      "epoch": 0.42698149019656734,
      "grad_norm": 0.426395058631897,
      "learning_rate": 4.2886187096847925e-05,
      "loss": 1.2325,
      "step": 137000
    }
  ],
  "logging_steps": 50,
  "max_steps": 962571,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.47426726985728e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
